import{_ as h,o as a,c as n,a as t,m as p,t as l,C as g,F as c,p as y,e as b,f as w,q as v}from"./chunks/framework.DrUvKbwK.js";const T={name:"PoemCard",props:{poem:{type:Object,required:!0}}},k={class:"quote-card"},x={class:"quote-author"},S={class:"quote-text"};function C(s,e,o,d,m,i){return a(),n("div",k,[t("p",x,[e[0]||(e[0]=t("span",{class:"poemseal"},"‚ù§Ô∏è",-1)),p(" "+l(o.poem.title)+" ",1),e[1]||(e[1]=t("span",{class:"poemseal"},"üêû",-1))]),t("p",S,'"'+l(o.poem.text)+'"',1)])}const q=h(T,[["render",C],["__scopeId","data-v-1db1eb74"]]),A=JSON.parse(`[{"id":"40968","text":"A corner reflector is a retroreflector consisting of three mutually perpendicular, intersecting flat surfaces, which reflects waves directly towards the source, but translated. The three intersecting surfaces often have square shapes. Radar corner reflectors made of metal are used to reflect radio waves from radar sets. Optical corner reflectors, called corner cubes or cube corners, made of three-sided glass prisms, are used in surveying and laser ranging. Principle Working principle of a corner reflector The incoming ray is reflected three times, once by each surface, which results in a reversal of direction. To see this, the three corresponding normal vectors of the corner's perpendicular sides can be considered to form a basis (a rectangular coordinate system) (x, y, z) in which to represent the direction of an arbitrary incoming ray, [a, b, c]. When the ray reflects from the first side, say x, the ray's x component, a, is reversed to ‚àía while the y and z components are unchanged, resulting in a direction of [‚àía, b, c]. Similarly, when reflected from side y and finally from side z, the b and c components are reversed. Therefore, the ray direction goes from [a, b, c] to [‚àía, b, c] to [‚àía, ‚àíb, c] to [‚àía, ‚àíb, ‚àíc], and it leaves the corner reflector with all three components of direction exactly reversed. The distance travelled, relative to a plane normal to the direction of the rays, is also equal for any ray entering the reflector, regardless of the location where it first reflects. Animation showing the reflected rays in a corner of a cube (corner reflector principle). In radar Radar corner reflectors are designed to reflect the microwave radio waves emitted by radar sets back toward the radar antenna. This causes them to show a strong \\"return\\" on radar screens. A simple corner reflector consists of three conducting sheet metal or screen surfaces at 90¬∞ angles to each other, attached to one another at the edges, forming a \\"corner\\". These reflect radio waves coming from in front of them back parallel to the incoming beam. To create a corner reflector that will reflect radar waves coming from any direction, 8 corner reflectors are placed back-to-back in an octahedron (diamond) shape. The reflecting surfaces must be larger than several wavelengths of the radio waves to function. In maritime navigation they are placed on bridge abutments, buoys, ships and, especially, lifeboats, to ensure that these show up strongly on ship radar screens. Corner reflectors are placed on the vessel's masts at a height of at least 4.6 meters (15 feet) above sea level (giving them an approximate minimum horizon distance of 8 kilometers or 4.5 nautical miles). Marine radar uses X-band microwaves with wavelengths of 2.5 - 3.75 cm, so small reflectors less than 30 cm across are used. In aircraft navigation, corner reflectors are installed on rural runways, to make them show up on aircraft radar. In optics Corner cube reflector Apollo 15 Lunar Laser Ranging RetroReflector (LRRR) installed on the Moon In optics, corner reflectors typically consist of three mirrors or reflective prism faces which return an incident light beam in the opposite direction. In surveying, retroreflector prisms are commonly used as targets for long-range electronic distance measurement using a total station. Five arrays of optical corner reflectors have been placed on the Moon for use by Lunar Laser Ranging experiments observing a laser's time-of-flight to measure the Moon's orbit more precisely than was possible before. The three largest were placed by NASA as part of the Apollo program, and the Soviet Union built two smaller ones into the Lunokhod rovers. Automobile and bicycle tail lights are molded with arrays of small corner reflectors, with different sections oriented for viewing from different angles. Reflective paint for visibility at night usually contains retroreflective spherical beads. Thin plastic with microscopic corner reflector structures can be used as tape, on signs, or sewn or molded onto clothing. Other examples Corner reflectors can also occur accidentally. Tower blocks with balconies are often accidental corner reflectors for sound and return a distinctive echo to an observer making a sharp noise, such as a hand clap, nearby. Similarly, in radar interpretation, an object that has multiple reflections from smooth surfaces produces a radar return of greater magnitude than might be expected from the physical size of the object. This effect was put to use on the ADM-20 Quail, a small missile which had the same radar cross section as a B-52. See also  References * * External links *Corner Reflector Antennas *Corner Reflector for WiFi Category:Mirrors Category:Radar ","title":"Corner reflector"},{"id":"40969","text":"Cosmic noise and galactic radio noise is random noise that originates outside the Earth's atmosphere. It can be detected and heard in radio receivers. Cosmic noise characteristics are similar to those of thermal noise. Cosmic noise is experienced at frequencies above about 15 MHz when highly directional antennas are pointed toward the sun or to certain other regions of the sky such as the center of the Milky Way Galaxy. Celestial objects like quasars, super dense objects that lie far from Earth, emit electromagnetic waves in its full spectrum including radio waves. We can also hear the fall of a meteorite in a radio receiver; the falling object burns from friction with the Earth's atmosphere, ionizing surrounding gases and producing radio waves. Cosmic microwave background radiation (CMBR) from outer space, discovered by Arno Penzias and Robert Wilson, who later won the Nobel Prize for this discovery, is also a form of cosmic noise. CMBR is thought to be a relic of the Big Bang, and pervades the space almost homogeneously over the entire celestial sphere. The bandwidth of the CMBR is wide, though the peak is in the microwave range. See also *Intergalactic space *Interplanetary space *Interstellar medium *Radio astronomy  References  * Category:Astronomical radio sources Category:Noise ","title":"Cosmic noise"},{"id":"40970","text":"A Costas loop is a phase-locked loop (PLL) based circuit which is used for carrier frequency recovery from suppressed-carrier modulation signals (e.g. double-sideband suppressed carrier signals) and phase modulation signals (e.g. BPSK, QPSK). It was invented by John P. Costas at General Electric in the 1950s. Its invention was described as having had \\"a profound effect on modern digital communications\\". The primary application of Costas loops is in wireless receivers. Its advantage over other PLL-based detectors is that at small deviations the Costas loop error voltage is \\\\sin(2(\\\\theta_i-\\\\theta_f)) as compared to \\\\sin(\\\\theta_i-\\\\theta_f). This translates to double the sensitivity and also makes the Costas loop uniquely suited for tracking Doppler-shifted carriers especially in OFDM and GPS receivers.  Classical implementation  Costas loop working in the locked state. In the classical implementation of a Costas loop, a local voltage-controlled oscillator (VCO) provides quadrature outputs, one to each of two phase detectors, e.g., product detectors. The same phase of the input signal is also applied to both phase detectors and the output of each phase detector is passed through a low-pass filter. The outputs of these low-pass filters are inputs to another phase detector, the output of which passes through noise-reduction filter before being used to control the voltage-controlled oscillator. The overall loop response is controlled by the two individual low-pass filters that precede the third phase detector while the third low-pass filter serves a trivial role in terms of gain and phase margin. The above figure of a Costas loop is drawn under the condition of the \\"locked\\" state, where the VCO frequency and the incoming carrier frequency have become the same as a result of the Costas loop process. The figure does not represent the \\"unlocked\\" state.  Mathematical models  = In the time domain = Time domain model of BPSK Costas loop In the simplest case m^2(t) = 1. Therefore, m^2(t) = 1 does not affect the input of noise-reduction filter. Carrier and voltage-controlled oscillator (VCO) signals are periodic oscillations f_{ref,vco}(\\\\theta_{ref,vco}(t)) with high- frequencies \\\\dot\\\\theta_{ref,vco}(t). Block \\\\bigotimes is an analog multiplier. From the mathematical point of view, a linear filter can be described by a system of linear differential equations :\\\\begin{array}{ll} \\\\dot x = Ax + b u_{d}(t),& u_{LF} = c^*x. \\\\end{array} Here, A is a constant matrix, x(t) is a state vector of filter, b and c are constant vectors. The model of a VCO is usually assumed to be linear : \\\\begin{array}{ll} \\\\dot\\\\theta_{vco}(t) = \\\\omega^{free}_{vco} + K_{vco} u_{LF}(t),& t \\\\in [0,T], \\\\end{array} where \\\\omega^{free}_{vco} is a free-running frequency of voltage-controlled oscillator and K_{vco} is an oscillator gain. Similarly, it is possible to consider various nonlinear models of VCO. Suppose that the frequency of master generator is constant \\\\dot\\\\theta_{ref}(t) \\\\equiv \\\\omega_{ref}. Equation of VCO and equation of filter yield : \\\\begin{array}{ll} \\\\dot{x} = Ax + bf_{ref}(\\\\theta_{ref}(t))f_{vco}(\\\\theta_{vco}(t)),& \\\\dot\\\\theta_{vco} = \\\\omega^{free}_{vco} + K_{vco}c^*x. \\\\end{array} The system is non-autonomous and rather difficult for investigation. = In phase-frequency domain = Equivalent phase-frequency domain model of Costas loop VCO input for phase- frequency domain model of Costas loop In the simplest case, when : \\\\begin{align} f_{ref}\\\\big(\\\\theta_{ref}(t)\\\\big) = \\\\cos\\\\big(\\\\omega_{ref} t\\\\big),\\\\ f_{vco}\\\\big(\\\\theta_{vco}(t)\\\\big) &= \\\\sin\\\\big(\\\\theta_{vco}(t)\\\\big)  f_{ref}\\\\big(\\\\theta_{ref}(t)\\\\big)^2 f_{vco}\\\\left(\\\\theta_{vco}(t)\\\\right) f_{vco}\\\\left(\\\\theta_{vco}(t) - \\\\frac{\\\\pi}{2}\\\\right) &= -\\\\frac{1}{8}\\\\Big( 2\\\\sin(2\\\\theta_{vco}(t)) + \\\\sin(2\\\\theta_{vco}(t) - 2\\\\omega_{ref} t) + \\\\sin(2\\\\theta_{vco}(t) + 2\\\\omega_{ref} t) \\\\Big) \\\\end{align} the standard engineering assumption is that the filter removes the upper sideband with frequency from the input but leaves the lower sideband without change. Thus it is assumed that VCO input is \\\\varphi(\\\\theta_{ref}(t) - \\\\theta_{vco}(t)) = \\\\frac{1}{8}\\\\sin(2\\\\omega_{ref} t - 2\\\\theta_{vco}(t)). This makes a Costas loop equivalent to a phase-locked loop with phase detector characteristic \\\\varphi(\\\\theta) corresponding to the particular waveforms f_{ref}(\\\\theta) and f_{vco}(\\\\theta) of input and VCO signals. It can be proved that filter outputs in time domain and phase-frequency domain are almost equal. Thus it is possible to study more simple autonomous system of differential equations :\\\\begin{align} \\\\dot{x} &= Ax + b\\\\varphi(\\\\Delta\\\\theta),  \\\\Delta\\\\dot{\\\\theta} &= \\\\omega_{vco}^{free} - \\\\omega_{ref} + K_{vco}c^*x,  \\\\Delta\\\\theta &= \\\\theta_{vco} - \\\\theta_{ref}. \\\\end{align}. The Krylov‚ÄìBogoliubov averaging method allows one to prove that solutions of non-autonomous and autonomous equations are close under some assumptions. Thus the block-scheme of Costas Loop in the time space can be asymptotically changed to the block-scheme on the level of phase-frequency relations. The passage to analysis of autonomous dynamical model of Costas loop (in place of the non-autonomous one) allows one to overcome the difficulties, related with modeling Costas loop in time domain where one has to simultaneously observe very fast time scale of the input signals and slow time scale of signal's phase. This idea makes it possible to calculate core performance characteristics - hold-in, pull-in, and lock-in ranges. Frequency acquisition { style=\\"float:center; margin:auto\\" Costas loop before synchronization Costas loop after synchronization } { style=\\"float:center; margin:auto\\" Carrier and VCO signals before synchronization VCO input during synchronization Carrier and VCO signals after synchronization } The classical Costas loop will work towards making the phase difference between the carrier and the VCO become a small, ideally zero, value. states, \\"The local oscillator must be maintained at proper phase so that the audio output contributions of the upper and lower sidebands reinforce one another. If the oscillator phase is 90¬∞ away from the optimum value a null in audio output will result which is typical of detectors of this type. The actual method of phase control will be explained shortly, but for the purpose of this discussion maintenance of correct oscillator phase shall be assumed.\\"Using a loop filter with an integrator allows a steady-state phase error of zero. See . The small phase difference implies that frequency lock has been achieved.  QPSK Costas loop  Classical Costas loop can be adapted to QPSK modulation for higher data rates . Classical QPSK Costas loop The input QPSK signal is as follows : m_1(t)\\\\cos\\\\left(\\\\omega_\\\\text{ref} t\\\\right) + m_2(t)\\\\sin\\\\left(\\\\omega_\\\\text{ref} t\\\\right), m_1(t) = \\\\pm 1, m_2(t) = \\\\pm 1. Inputs of low-pass filters LPF1 and LPF2 are :\\\\begin{align} \\\\varphi_1(t) &= \\\\cos\\\\left(\\\\theta_\\\\text{vco}\\\\right)\\\\left(m_1(t)\\\\cos\\\\left(\\\\omega_\\\\text{ref} t\\\\right) + m_2(t)\\\\sin\\\\left(\\\\omega_\\\\text{ref} t\\\\right)\\\\right),  \\\\varphi_2(t) &= \\\\sin\\\\left(\\\\theta_\\\\text{vco}\\\\right)\\\\left(m_1(t)\\\\cos\\\\left(\\\\omega_\\\\text{ref} t\\\\right) + m_2(t)\\\\sin\\\\left(\\\\omega_\\\\text{ref} t\\\\right)\\\\right). \\\\end{align} After synchronization outputs of LPF1 Q(t) and LPF2 I(t) are used to get demodulated data (m_1(t) and m_2(t)). To adjust frequency of VCO to reference frequency signals Q(t) and I(t) goes through limiters and cross-multiplied: :u_d(t) = I(t)\\\\sgn(Q(t)) - Q(t)\\\\sgn(I(t)). After that signal u_d(t) is filtered by Loop filter and forms tuning signal for VCO u_\\\\text{LF}(t) similar to BPSK Costas loop. Thus, QPSK Costas can be described by system of ODEs :\\\\begin{align} \\\\dot{x}_1 &= A_\\\\text{LPF} x_1 + b_\\\\text{LPF}\\\\varphi_1(t), \\\\dot{x}_2 &= A_\\\\text{LPF} x_2 + b_\\\\text{LPF}\\\\varphi_2(t), \\\\dot{x} &= A_\\\\text{LF} x + b_\\\\text{LF}\\\\left(c_\\\\text{LPF}^* x_1\\\\sgn\\\\left(c_\\\\text{LPF}^* x_2\\\\right) - c_\\\\text{LPF}^* x_2\\\\sgn\\\\left(c_\\\\text{LPF}^* x_1\\\\right)\\\\right), \\\\dot{\\\\theta}_\\\\text{vco} &= \\\\omega_\\\\text{vco}^\\\\text{free} + K_\\\\text{VCO}\\\\left(c^*_\\\\text{LF} x + h\\\\left(c_\\\\text{LPF}^* x_1\\\\sgn\\\\left(c_\\\\text{LPF}^* x_2\\\\right) - c_\\\\text{LPF}^* x_2\\\\sgn\\\\left(c_\\\\text{LPF}^* x_1\\\\right)\\\\right)\\\\right). \\\\end{align} Here A_\\\\text{LPF}, b_\\\\text{LPF}, c_\\\\text{LPF} \\\\- parameters of LPF1 and LPF2 and A_\\\\text{LF}, b_\\\\text{LF}, c_\\\\text{LF}, h_\\\\text{LF} \\\\- parameters of loop filter. References * Category:Electronic oscillators Category:Communication circuits ","title":"Costas loop"},{"id":"40972","text":"Rotating coupling An improvised flexible coupling made of car tire pieces connects the drive shafts of an engine and a water pump. This one is used to cancel out misalignment and vibrations. A coupling is a device used to connect two shafts together at their ends for the purpose of transmitting power. The primary purpose of couplings is to join two pieces of rotating equipment while permitting some degree of misalignment or end movement or both. In a more general context, a coupling can also be a mechanical device that serves to connect the ends of adjacent parts or objects. Couplings do not normally allow disconnection of shafts during operation, however there are torque limiting couplings which can slip or disconnect when some torque limit is exceeded. Selection, installation and maintenance of couplings can lead to reduced maintenance time and maintenance cost. Uses Shaft couplings are used in machinery for several purposes. A primary function is to transfer power from one end to another end (ex: motor transfer power to pump through coupling). Other common uses: * To alter the vibration characteristics of rotating units *To connect driving and the driven part *To introduce protection * To reduce the transmission of shock loads from one shaft to another *To slip when overload occurs Types Clamped or compression rigid couplings come in two parts and fit together around the shafts to form a sleeve. They offer more flexibility than sleeved models, and can be used on shafts that are fixed in place. They generally are large enough so that screws can pass all the way through the coupling and into the second half to ensure a secure hold. Flanged rigid couplings are designed for heavy loads or industrial equipment. They consist of short sleeves surrounded by a perpendicular flange. One coupling is placed on each shaft so the two flanges line up face to face. A series of screws or bolts can then be installed in the flanges to hold them together. Because of their size and durability, flanged units can be used to bring shafts into alignment before they are joined together. = Examples of rigid couplings = Rigid couplings are used when precise shaft alignment is required; shaft misalignment will affect the coupling's performance as well as its life.  Beam coupling  A beam coupling A beam coupling, also known as helical coupling, is a flexible coupling for transmitting torque between two shafts while allowing for angular misalignment, parallel offset and even axial motion, of one shaft relative to the other. This design utilizes a single piece of material and becomes flexible by removal of material along a spiral path resulting in a curved flexible beam of helical shape. Since it is made from a single piece of material, the Beam Style coupling does not exhibit the backlash found in some multi-piece couplings. Another advantage of being an all machined coupling is the possibility to incorporate features into the final product while still keep the single piece integrity. Changes to the lead of the helical beam provide changes to misalignment capabilities as well as other performance characteristics such as torque capacity and torsional stiffness. It is even possible to have multiple starts within the same helix. The material used to manufacture the beam coupling also affects its performance and suitability for specific applications such as food, medical and aerospace. Materials are typically aluminum alloy and stainless steel, but they can also be made in acetal, maraging steel and titanium. The most common applications are attaching rotary encoders to shafts and motion control for robotics. File:Special Beam Couplings with attachments.jpgA beam coupling with optional features machined into it File:Helical U-Joint (Beam Style Coupling) - Angular Misalignment.jpgIncreasing number of coils allows for greater angular misalignment = Bellows coupling = Metal bellows low backlash  Bushed pin coupling  Bush pin type flange coupling This is used for slightly imperfect alignment of the two shafts. This is modified form of the protected type flange coupling. This type of coupling has pins and it works with coupling bolts. The rubber or leather bushes are used over the pins. The coupling has two halves dissimilar in construction. The pins are rigidly fastened by nuts to one of the flange and kept loose on the other flange. This coupling is used to connect shafts which have a small parallel misalignment, angular misalignment or axial misalignment. In this coupling the rubber bushing absorbs shocks and vibration during its operations. This type of coupling is mostly used to couple electric motors and machines. Constant velocity There are various types of constant-velocity (CV) couplings: Rzeppa joint, Double cardan joint, and Thompson coupling. Clamp or split- muff coupling In this coupling, the muff or sleeve is made into two halves parts of the cast iron and they are joined together by means of mild steel studs or bolts. The advantages of this coupling is that assembling or disassembling of the coupling is possible without changing the position of the shaft. This coupling is used for heavy power transmission at moderate speed.  Diaphragm  Diaphragm couplings transmit torque from the outside diameter of a flexible plate to the inside diameter, across the spool or spacer piece, and then from inside to outside diameter. The deforming of a plate or series of plates from I.D. to O.D accomplishes the misalignment. Disc Disc couplings transmit torque from a driving to a driven bolt tangentially on a common bolt circle. Torque is transmitted between the bolts through a series of thin, stainless steel discs assembled in a pack. Misalignment is accomplished by deforming of the material between the bolts.  Donut coupling  Elastic An elastic coupling (for connecting a windsurfing sail rig to the board). An elastic coupling transmits torque or other load by means of an elastic component. One example is the coupling used to join a windsurfing rig (sail, mast, and components) to the sailboard. In windsurfing terminology it is usually called a \\"universal joint\\", but modern designs are usually based on a strong flexible material, and better technically described as an elastic coupling. They can be tendon or hourglass- shaped, and are constructed of a strong and durable elastic material. In this application, the coupling does not transmit torque, but instead transmits sail-power to the board, creating thrust (some portion of sail-power is also transmitted through the rider's body).  Elastomeric coupling  Flexible Flexible couplings are usually used to transmit torque from one shaft to another when the two shafts are slightly misaligned. They can accommodate varying degrees of misalignment up to 1.5¬∞ and some parallel misalignment. They can also be used for vibration damping or noise reduction. In rotating shaft applications a flexible coupling can protect the driving and driven shaft components (such as bearings) from the harmful effects of conditions such as misaligned shafts, vibration, shock loads, and thermal expansion of the shafts or other components. Fluid Gear A gear coupling A gear coupling is a mechanical device for transmitting torque between two shafts that are not collinear. It consists of a flexible joint fixed to each shaft. The two joints are connected by a third shaft, called the spindle. Each joint consists of a 1:1 gear ratio internal/external gear pair. The tooth flanks and outer diameter of the external gear are crowned to allow for angular displacement between the two gears. Mechanically, the gears are equivalent to rotating splines with modified profiles. They are called gears because of the relatively large size of the teeth. Gear couplings and universal joints are used in similar applications. Gear couplings have higher torque densities than universal joints designed to fit a given space while universal joints induce lower vibrations. The limit on torque density in universal joints is due to the limited cross sections of the cross and yoke. The gear teeth in a gear coupling have high backlash to allow for angular misalignment. The excess backlash can contribute to vibration. Gear couplings are generally limited to angular misalignments, i.e., the angle of the spindle relative to the axes of the connected shafts, of 4‚Äì5¬∞. Universal joints are capable of higher misalignments. Single joint gear couplings are also used to connect two nominally coaxial shafts. In this application the device is called a gear-type flexible, or flexible coupling. The single joint allows for minor misalignments such as installation errors and changes in shaft alignment due to operating conditions. These types of gear couplings are generally limited to angular misalignments of 1/4‚Äì1/2¬∞.  Geislinger coupling  Giubo ( sometimes misspelled as guibo) , also known as a flex disc, or Boschi joint Grid A grid coupling is composed of two shaft hubs, a metallic grid spring, and a split cover kit. Torque is transmitted between the two coupling shaft hubs through the metallic grid spring element. Like metallic gear and disc couplings, grid couplings have a high torque density. A benefit of grid couplings, over either gear or disc couplings, is the ability their grid coupling spring elements have to absorb and spread peak load impact energy over time. This reduces the magnitude of peak loads and offers some vibration dampening capability. A negative of the grid coupling design is that it generally is very limited in its ability to accommodate the misalignment. Hirth Hirth joints use tapered teeth on two shaft ends meshed together to transmit torque. Hydrodynamic coupling (fluid coupling)   Jaw coupling (or Spider or Lovejoy coupling)  Magnetic coupling A [magnetic] coupling uses magnetic forces to transmit the power from one shaft to another without any contact. This allows for full medium separation. Therefore can provide the ability to hermetically separate two areas whilst continuing to transmit mechanical power from one to the other making these couplings ideal for applications where prevention of cross contamination is essential.  Schmidt coupling   Oldham  Animated Oldham coupler An Oldham coupling has three discs, one coupled to the input, one coupled to the output, and a middle disc that is joined to the first two by tongue and groove. The tongue and groove on one side is perpendicular to the tongue and groove on the other. The middle disc rotates around its center at the same speed as the input and output shafts. Its center traces a circular orbit, twice per rotation, around the midpoint between input and output shafts. Often springs are used to reduce backlash of the mechanism. An advantage to this type of coupling, as compared to two universal joints, is its compact size. The coupler is named for John Oldham who invented it in Ireland, in 1821, to solve a problem in a paddle steamer design. Image:Klauenkupplung 1.jpgOldham coupler, assembled Image:Klauenkupplung 3.jpgOldham coupler, disassembled Sleeve, box, or muff coupling A sleeve coupling consists of a pipe whose bore is finished to the required tolerance based on the shaft size. Based on the usage of the coupling a keyway is made in the bore in order to transmit the torque by means of the key. Two threaded holes are provided in order to lock the coupling in position. Sleeve couplings are also known as box Couplings. In this case shaft ends are coupled together and abutted against each other which are enveloped by muff or sleeve. A gib head sunk keys hold the two shafts and sleeve together (this is the simplest type of the coupling) It is made from the cast iron and very simple to design and manufacture. It consists of a hollow pipe whose inner diameter is same as diameter of the shafts. The hollow pipe is fitted over a two or more ends of the shafts with the help of the taper sunk key. A key and sleeve are useful to transmit power from one shaft to another shaft.  Tapered shaft lock  A tapered lock is a form of keyless shaft locking device that does not require any material to be removed from the shaft. The basic idea is similar to a clamp coupling but the moment of rotation is closer to the center of the shaft. An alternative coupling device to the traditional parallel key, the tapered lock removes the possibility of play due to worn keyways. It is more robust than using a key because maintenance only requires one tool and the self-centering balanced rotation means it lasts longer than a keyed joint would, but the downside is that it costs more.  Twin spring coupling  A flexible coupling made from two counterwound springs with a ball bearing in the center, which allows torque transfer from input to output shaft. Requires no lubrication to consistently run as it has no internal components.  Rag joint  Rag joints are commonly used on automotive steering linkages and drive trains. When used on a drive train they are sometimes known as giubos.  Universal joint  Requirements of good shaft alignment / good coupling set-up *easy to connect or disconnect the coupling. *does allow some misalignment between the two adjacent shaft rotation axes. *no projecting parts *goal should be to minimise the remaining misalignment in running operation so as to maximise power transmission and to maximise machine runtime (coupling, bearing and sealing's lifetime). *It is recommended to use manufacturer's alignment target values to set up the machine train to a defined non-zero alignment, due to the fact that later, when the machine is at operation temperature, the alignment condition is perfect Coupling maintenance and failure Coupling maintenance requires a regularly scheduled inspection of each coupling. It consists of: * Performing visual inspections, *checking for signs of wear or fatigue *cleaning couplings regularly * Checking and changing lubricant regularly if the coupling is lubricated. This maintenance is required annually for most couplings and more frequently for couplings in adverse environments or in demanding operating conditions. * Documenting the maintenance performed on each coupling, along with the date. Even with proper maintenance, however, couplings can fail. Underlying reasons for failure, other than maintenance, include: * Improper installation * Poor coupling selection * Operation beyond design capabilities. The only way to improve coupling life is to understand what caused the failure and to correct it prior to installing a new coupling. Some external signs that indicate potential coupling failure include: * Abnormal noise, such as screeching, squealing or chattering * Excessive vibration or wobble * Failed seals indicated by lubricant leakage or contamination. Checking the coupling balance Couplings are normally balanced at the factory prior to being shipped, but they occasionally go out of balance in operation. Balancing can be difficult and expensive, and is normally done only when operating tolerances are such that the effort and the expense are justified. The amount of coupling unbalance that can be tolerated by any system is dictated by the characteristics of the specific connected machines and can be determined by detailed analysis or experience. References External links *Biography of Oldham at Cornell University *Yutaka Nishiyama, From Oldham's Coupling to Air Conditioners Category:Mechanisms (engineering) Category:Hardware (mechanical) ","title":"Coupling"},{"id":"40973","text":"Cover or covers may refer to:  Packaging, science and technology  * A covering, usually - but not necessarily - one that completely closes the object ** Cover (philately), generic term for envelope or package ** Housing (engineering), an exterior case or enclosure used to protect an interior mechanism ** Lid (container) ** Media covers *** Album cover, the front of the packaging of a commercially released audio recording product *** Book cover or magazine cover *** CD and DVD cover, CD and DVD packaging *** Cover art, images and text on media covers ** Seal (mechanical), a device that helps join systems or mechanisms together by preventing leakage ** Smartphone cover, a mobile phone accessory that protects a mobile phone * Concrete cover, in engineering, distance between reinforcement and the outer surface of element * Sedimentary cover, in geology, overlies a basement or crystalline basement  People  * Cover (surname) ** Franklin Cover (1928‚Äì2006), American actor ** Robert Cover (1943‚Äì1986), American law professor, scholar, and activist ** Thomas M. Cover (1938‚Äì2012), American scientist Arts, entertainment, and media =Music=  Albums  * Cover (Tom Verlaine album), 1984 * Cover (Joan as Policewoman album), 2009 * Covered (Cold Chisel album), 2011 * Covered (Macy Gray album), 2012 * Covered (Robert Glasper album, born 1978), 2015 album by Robert Glasper * Covers (Beni album), 2012 * Covers (Joey Cape album), by Joey Cape * Covers (Regine Velasquez album), 2004 * Covers (Placebo album), 2003 * Covers (Show of Hands album), 2000 * Covers (James Taylor album), 2008 * Covers (Fayray album), 2005 * Covers (Deftones album), 2011 * Covers, an album by Break of Reality  Extended plays  * Covers (A Camp EP), 2009 * Covers (Franz Ferdinand EP), 2009 * Covers (Get Cape. Wear Cape. Fly EP), 2009 * Covers (The Autumns EP), 2001 * Covers (Young Statues EP), 2012 Other uses in music * Cover, an understudy in opera * Cover band, a musical band that performs mostly cover versions * Cover version, a new version of a previously released song =Other uses in arts, entertainment, and media= * Cover (film), a 2007 film directed by Bill Duke * Covers (film), an upcoming comedy film directed by Nisha Ganatra * Cover system, a system of protection in video games * Cover Magazine (Arts Publication), a New York City arts monthly publication * Cover Corp., parent organization for VTuber idol company Hololive Production  Business  * Cover (finance), repurchasing a short order made on the stock/equity, forex or futures markets * Cover (law), a remedy for the breach of a contract for the receipt of goods * Cover charge, an entry fee * Cover (hospitality) * First day cover (\\"FDC\\" also called a first day of issue), a postage stamp on a cover, postal card or stamped envelope franked on the first day of issue  Deception and concealment  * Cover (telecommunications), a communications concealment technique * Cover, something fake used in a cover-up * Non-official cover, the identity assume by an operative who takes a covert role in an organization without official ties to the government * Official cover, the identity assumed by an operative who takes a position in an organization with diplomatic ties  Mathematics  * Cover (algebra), the concept of an algebraic structure that maps onto another structure in structure-preserving fashion * Cover (topology), the mathematical concept of a collection of sets whose union contains each set as a subset * Cover, in database theory, an equivalent set of constraints * Cover, a pair in the covering relation of a partially ordered set, or the greater element in such a pair * Covering group (universal / double), a covering space with group structure, common in theoretical physics * Covering space, in the theory of Riemann surfaces and topology * Good cover (algebraic topology), an open topological cover such that all open sets in the cover and all intersections of finitely many open sets are contractible Military * Cover (military), anything which is capable of physically protecting an individual from enemy fire * Cover: Uniform, a military term for any type of uniform hat, as in: ** Campaign cover or campaign hat, a broad- brimmed felt or straw hat, with a high crown, pinched symmetrically at the four corners ** Utility cover also known as the utility cap and eight-pointed cover, the United States Marine Corps cap, worn with their utility uniform  Sports  * Cover (cricket), a region of the field with respect to the batsman in cricket * Cover 2, a class of defensive play in American football * To cover, in sports betting a favorite to win by more than the game's point spread  Other uses  * Cover, or covers, the top layer of bedding * Cover, to mate animals, e.g., a stallion covers a mare * Cover, the seating capacity for one person in a restaurant * Slipcover, protective cover that may be slipped off and on a piece of upholstered furniture  See also   Casing (disambiguation) * Couverture (disambiguation) * Cover girl (disambiguation) * Cover Me (disambiguation) * Cover Story (disambiguation) * Cover story (disambiguation) * Cover Up (disambiguation) * Cover Your Tracks (disambiguation) * Coverage (disambiguation) * Covering (disambiguation) * Enclosure (disambiguation) * Faceplate (disambiguation) * Uncover (disambiguation) * Under the Covers (disambiguation) * Undercover * Uncovered (disambiguation) * Wrap (disambiguation) * Wraparound (disambiguation) ","title":"Cover"},{"id":"40974","text":"Critical angle can refer to: *Critical angle (optics); the angle of incidence above which total internal reflection occurs *Critical angle of attack, in aerodynamics; the angle of attack which produces the maximum lift coefficient *Critical angle of repose, in engineering; the steepest angle of descent of a slope when the material is on the verge of sliding. ","title":"Critical angle"},{"id":"40975","text":"In telecommunication, the term critical frequency has the following meanings: * In radio propagation by way of the ionosphere, the limiting frequency at or below which a wave component is reflected by, and above which it penetrates through, an ionospheric layer. * At near vertical incidence, the limiting frequency at or below which incidence, the wave component is reflected by, and above which it penetrates through, an ionospheric layer. Critical Frequency changes with time of day, atmospheric conditions and angle of fire of the radio waves by antenna. The existence of the critical frequency is the result of electron limitation, i.e., the inadequacy of the existing number of free electrons to support reflection at higher frequencies. In signal processing the critical frequency it is also another name for the Nyquist frequency. Critical frequency is the highest magnitude of frequency above which the waves penetrate the ionosphere and below which the waves are reflected back from the ionosphere. It is denoted by \\"fc\\". Its value is not fixed and it depends upon the electron density of the ionosphere.  Equations  = Critical Frequency as a Function of Electron Density = Critical frequency can be computed with the electron density given by: f_\\\\text{c} = 9\\\\sqrt{N_\\\\text{max}} where Nmax is maximum electron density per m3 and fc is in Hz. = Critical Frequency as a Function of Maximum Usable Frequency Formula = Critical frequency can be computed by: f_\\\\text{c} = MUF/sec\\\\theta where MUF is maximum usable frequency and \\\\theta is the angle of incidence  Relationship with Plasma Frequency  The dependence of critical frequency with respect with electron density can be related through plasma oscillation concept particularly the 'Cold' Electrons mechanism. \\\\omega_{\\\\mathrm{pe}} = \\\\sqrt{\\\\frac{n_\\\\mathrm{e} e^{2}}{m^*\\\\varepsilon_0}}, \\\\left[\\\\mathrm{rad/s}\\\\right] Using the electron charge e=1.602\\\\cdot 10^{-19} Coulombs, electron mass m^*=9.10938356\\\\cdot 10^{-31} kilograms and permittivity of free space \\\\epsilon_o=8.854187817\\\\cdot 10^{-12}A^2s^4m^{-3}kg^{-1}gives, \\\\omega_{\\\\mathrm{pe}} = 2\\\\pi f=56.415 \\\\sqrt{n_e} and solving for the frequency, f_\\\\text{c} = 8.979\\\\sqrt{N_\\\\text{max}} \\\\approx 9\\\\sqrt{N_\\\\text{max}}  Relationship with Index of Refraction  The index of refraction has the formula n=\\\\frac{c}{v}which shows dependence in wavelength. The result that the force due to the polarization field in an ionized gas of low concentration is canceled by the effect of collisions between ions and electrons is re‚Äêestablished in a simple manner that clearly displays the physical basis for the effect. Because of this cancellation the Sellmeyer formula, determines the relation between the electron number density, N, and the index of refraction, n, in the ionosphere when collisions are neglected. n^2-1=\\\\frac{-Ne^2}{\\\\epsilon_o m \\\\omega^2}. Using the default values for electron charge e, permittivity of free space and electron mass \\\\epsilon_o, and changing angular velocity \\\\omegawith respect to frequency fthis yields to n^2-1=\\\\frac{3182.607N}{(2\\\\pi f)^2} and solving for the refraction index n, n=\\\\sqrt{1-\\\\frac{80.616N}{f^2}} \\\\approx \\\\sqrt{1-\\\\frac{81N}{f^2}}  Critical Frequency and F layer of the Ionosphere  * All long-distance HF Radio Communications use HF Radio signals that are obliquely incident on the ionosphere, If the HF frequency is above Critical Frequency, the radio signals are passing through the ionosphere at an angle instead of head-on. * The Critical Frequency is changing continuously and the F layer of the Ionosphere is mostly responsible for the reflection of radio waves back to Earth, * The other layers(D) interact in other ways - absorption of frequency and during the day, the D Layers forms, and the F layer splits into F1 and F2 layers. * Because of changing the Ionosphere during day and night, during daytime higher frequency bands under critical Frequency work best, but during nighttime the lower frequency bands work best. * The D layer is present during the day and it is a good absorber of radio waves, increasing losses, Higher frequencies are absorbed less, so higher frequencies tends to perform better during daytime. * The actual F2-Layer Critical Frequency Map link which refreshes every five minutes can be seen in this website http://www.spacew.com/www/fof2.html * The Ionosphere and the Practical Maximum Usable Frequencies (MUFs) Map link which refreshes every five minutes can be seen in this website http://www.sws.bom.gov.au/HF_Systems/6/9/1 See also * High Frequency * High Frequency Active Auroral Research Program * High Frequency Internet Protocol * Low frequency * Radio propagation * Space weather References Category:Telecommunication theory ","title":"Critical frequency"},{"id":"40976","text":"Crosstalk refers to any signal or circuit unintentionally affecting another signal or circuit. Crosstalk may also refer to: in science, computing * Crosstalk (biology) * Crosstalk Mk.4, a communications application for PCs. in literature, culture, entertainment * Xiangsheng, also translated as \\"crosstalk\\", a traditional Chinese comedic monologue or dialogue * Crosstalk (novel), a 2016 novel by American science fiction author Connie Willis * Crosstalk (film), a 1982 science fiction thriller film * Cross Talk, a 1980 album by the Pretty Things * Crosstalk: American Speech Music, a compilation album by the produced by Mendi + Keith Obadike * CrossTalk (TV series), a television program on the Russian-based international broadcaster RT * Cross Talk, a defunct radio show hosted by Indian RJ Balaji ","title":"Crosstalk (disambiguation)"},{"id":"40978","text":"In telecommunication, a cryptochannel is a complete system of crypto- communications between two or more holders. It includes: (a) the cryptographic aids prescribed; (b) the holders thereof; (c) the indicators or other means of identification; (d) the area or areas in which effective; (e) the special purpose, if any, for which provided; and (f) pertinent notes as to distribution, usage, etc. A cryptochannel is analogous to a radio circuit. See also *Cryptosystem *Secure channel References * * Category:Cryptography Category:Military communications ","title":"Cryptochannel"},{"id":"40979","title":"Crystal oscillator"},{"id":"40980","text":"Curve-fitting compaction is data compaction accomplished by replacing data to be stored or transmitted with an analytical expression. Examples of curve- fitting compaction consisting of discretization and then interpolation are: * Breaking of a continuous curve into a series of straight line segments and specifying the slope, intercept, and range for each segment * Using a mathematical expression, such as a polynomial or a trigonometric function, and a single point on the corresponding curve instead of storing or transmitting the entire graphic curve or a series of points on it. References Category:Curves Category:Interpolation Category:Data compression ","title":"Curve-fitting compaction"},{"id":"40981","text":"In telecommunications, the term customer office terminal has the following meanings: *1. Termination equipment that (a) is located on the customer premises and (b) performs a function that may be integrated into the common carrier equipment. Note: An example of a customer office terminal is a stand- alone multiplexer located on the customer premises. *2. The digital loop carrier (DLC) multiplexing function that is near the exchange termination (ET) when provided by a stand-alone multiplexer. Note: This function may be integrated into the ET. References Category:Telecommunications equipment ","title":"Customer office terminal"},{"id":"40982","text":"In telecommunications, a customer-premises equipment or customer-provided equipment (CPE) is any terminal and associated equipment located at a subscriber's premises and connected with a carrier's telecommunication circuit at the demarcation point (\\"demarc\\"). The demarc is a point established in a building or complex to separate customer equipment from the equipment located in either the distribution infrastructure or central office of the communications service provider. CPE generally refers to devices such as telephones, routers, network switches, residential gateways (RG), set-top boxes, fixed mobile convergence products, home networking adapters and Internet access gateways that enable consumers to access providers' communication services and distribute them in a residence or enterprise with a local area network (LAN). A CPE can be an active equipment, as the ones mentioned above, or passive equipment such as analogue telephone adapters (ATA) or xDSL-splitters. This includes key telephone systems and most private branch exchanges. Excluded from the CPE category are overvoltage protection equipment and pay telephones. Other types of materials that are necessary for the delivery of the telecommunication service, but are not defined as equipment, such as manuals and cable packages, and cable adapters are instead referred to as CPE-peripherals. CPE can refer to devices purchased by the subscriber, or to those provided by the operator or service provider.  History  The two phrases, \\"customer-premises equipment\\" and \\"customer- provided equipment\\", reflect the history of this equipment. Under the Bell System monopoly in the United States (post Communications Act of 1934), the Bell System owned the telephones, and one could not attach privately owned or supplied devices to the network, or to the station apparatus. Telephones were located on customers' premises, hence, customer-premises equipment. In the U.S. Federal Communications Commission (FCC) proceeding the Second Computer Inquiry, the FCC ruled that telecommunications carriers could no longer bundle CPE with telecommunications service, uncoupling the market power of the telecommunications service monopoly from the CPE market, and creating a competitive CPE market. With the gradual breakup of the Bell monopoly, starting with Hush-A-Phone v. United States [1956], which allowed some non- Bell owned equipment to be connected to the network (a process called interconnection), equipment on customers' premises became increasingly owned by customers. Indeed, subscribers were eventually permitted to purchase telephones ‚Äì hence, customer-provided equipment. In the pay-TV industry many operators and service providers offer subscribers a set-top box with which to receive video services, in return for a monthly fee. As offerings have evolved to include multiple services [voice and data] operators have increasingly given consumers the opportunity to rent or buy additional devices like access modems, internet gateways and video extenders that enable them to access multiple services, and distribute them to a range of consumer electronics devices in the home. Technology evolution  =Hybrid devices= The growth of multiple-service operators, offering triple or quad-play services, required the development of hybrid CPE to make it easy for subscribers to access voice, video and data services. The development of this technology was led by Pay TV operators looking for a way to deliver video services via both traditional broadcast and broadband IP networks. Spain's Telefonica was the first operator to launch a hybrid broadcast and broadband TV service in 2003 with its Movistar TV DTT/IPTV offering,About . DVB. Retrieved on 2014-03-12. while Polish satellite operator 'n' was the first to offer its subscribers a Three- way hybrid (or Tri-brid) broadcast and broadband TV service,ADB takes ‚Äòn‚Äô hybrid. Broadbandtvnews.com (12 September 2009). Retrieved on 2014-03-12. which launched in 2009 =Set-back box= The term set-back box is used in the digital TV industry to describe a piece of consumer hardware that enables them to access both linear broadcast and internet-based video content, plus a range of interactive services like Electronic Programme Guides (EPG), Pay Per View (PPV) and video on demand (VOD) as well as internet browsing, and view them on a large screen television set. Unlike standard set-top boxes, which sit on top of or below the TV, a set-back box has a smaller form factor to enable it to be mounted to the rear of the display panel flat panel TV, hiding it from view. =Residential gateway= A residential gateway is a networking device used to connect devices in the home to the Internet or other wide area network (WAN). It is an umbrella term, used to cover multi-function networking appliances used in homes, which may combine a DSL modem or cable modem, a network switch, a consumer-grade router, and a wireless access point. In the past, such functions were provided by separate devices, but in recent years technological convergence has enabled multiple functions to be merged into a single device. One of the first home gateway devices to be launched was selected by Telecom Italia to enable the operator to offer triple play services in 2002 . Along with a SIP VoIP handset for making voice calls, it enabled subscribers to access voice, video and data services over a 10MB symmetrical ADSL fiber connection. =Virtual gateway= The virtual gateway concept enables consumers to access video and data services and distribute them around their homes using software rather than hardware. The first virtual gateway was introduced in 2010 by Advanced Digital Broadcast at the IBC exhibition in Amsterdam.>> News >> Electronics. ResearchInChina (16 September 2010). Retrieved on 2014-03-12.News tagged ADB at DIGITIMES. Digitimes.com (16 September 2010). Retrieved on 2014-03-12. The ADB Virtual Gateway uses software that resides within the middleware and is based on open standards, including DLNA home networking and the DTCP-IP standard, to ensure that all content, including paid-for encrypted content like Pay TV services, can only be accessed by secure CE devices.Newswires  VideoNet . V-net.tv. Retrieved on 2014-03-12.  Broadband  A subscriber unit, or SU is a broadband radio that is installed at a business or residential location to connect to an access point to send/receive high speed data wired or wirelessly. Devices commonly referred to as a subscriber unit include cable modems, access gateways, home networking adapters and mobile phones.  WAN  CPE may also refer to any devices that terminate a WAN circuit, such as an ISDN, E-carrier/T-carrier, DSL, or metro Ethernet. This includes any customer-owned hardware at the customer's site: routers, firewalls, network switches, PBXs, VoIP gateways, sometimes CSU/DSU and modems. Application areas *Connected home *Pay TV *Over- the-top video services *Broadband *Voice over IP *Fixed‚Äìmobile convergence [FMC]  Other uses  *Cellular carriers may sometimes internally refer to cellular phones a customer has purchased without a subsidy or from a third party as \\"customer provided equipment.\\" *It is also notable that the fully qualified domain name and the PTR record of DSL and cable lines connected to a residence will often contain 'cpe'.  See also  *Demarcation point *Interconnection *On-premises wiring *Terminal equipment  References  =Sources= * Category:Telephony equipment ","title":"Customer-premises equipment"},{"id":"40983","text":"In telecommunication, a customer service unit (CSU) is a device that provides an accessing arrangement at a user location to either switched or point-to- point, data-conditioned circuits at a specifically established data signaling rate. A CSU provides local loop equalization, transient protection, isolation, and central office loop-back testing capability. References Category:Local loop ","title":"Customer service unit"},{"id":"40985","text":"In telecommunications, a cutback technique is a destructive technique for determining certain optical fiber transmission characteristics, such as attenuation and bandwidth. Procedure The measurement technique consists of: #performing the desired measurements on a long length of the fiber under test, #cutting the fiber under test at a point near the launching end, #repeating the measurements on the short length of fiber, and #subtracting the results obtained on the short length to determine the results for the residual long length. The cut should be made to retain 1 meter or more of the fiber, in order to establish equilibrium mode distribution conditions for the second measurement. In a multimode fiber, the lack of an equilibrium mode distribution could introduce errors in the measurement due to output coupling effects. In a single-mode fiber, measuring a shorter cutback fiber could result in significant transmission of cladding modes (light carried in the cladding rather than the core of the optical fiber), distorting the measurement. The errors introduced will result in conservative results (i.e., higher transmission losses and lower bandwidths) than would be realized under equilibrium conditions.  Benefits  The benefit of this technique is that it allows measurement of the fiber characteristics without introducing errors due to variation in the launch conditions. For example, the coupling efficiency of the light source is kept consistent between the initial and the cutback measurements. Several characteristics may be determined using the same test fiber.  Attenuation measurement  Since the attenuation is defined as proportional to the logarithm of the ratio between P(x) and P(y), where P is the power at point x and y respectively. Using the cutback technique, the power transmitted through a fiber of known length is measured and compared with the same measurement for the same fiber cut to a length of 2m approximately.  Related techniques  A variation of the cutback technique is the substitution method, in which measurements are made on a full length of fiber, and then on a short length of fiber having the same characteristics (core size, numerical aperture), with the results from the short length being subtracted to give the results for the full length. References External links *Optical Fiber Measurements Category:Fiber optics ","title":"Cutback technique"},{"id":"40986","text":"Magnitude transfer function of a bandpass filter with lower 3 dB cutoff frequency f1 and upper 3 dB cutoff frequency f2 A Bode plot of the Butterworth filter's frequency response, with corner frequency labeled. (The slope ‚àí20 dB per decade also equals ‚àí6 dB per octave.) In physics and electrical engineering, a cutoff frequency, corner frequency, or break frequency is a boundary in a system's frequency response at which energy flowing through the system begins to be reduced (attenuated or reflected) rather than passing through. Typically in electronic systems such as filters and communication channels, cutoff frequency applies to an edge in a lowpass, highpass, bandpass, or band-stop characteristic ‚Äì a frequency characterizing a boundary between a passband and a stopband. It is sometimes taken to be the point in the filter response where a transition band and passband meet, for example, as defined by a half-power point (a frequency for which the output of the circuit is ‚àí3 dB of the nominal passband value). Alternatively, a stopband corner frequency may be specified as a point where a transition band and a stopband meet: a frequency for which the attenuation is larger than the required stopband attenuation, which for example may be 30 dB or 100 dB. In the case of a waveguide or an antenna, the cutoff frequencies correspond to the lower and upper cutoff wavelengths. Electronics In electronics, cutoff frequency or corner frequency is the frequency either above or below which the power output of a circuit, such as a line, amplifier, or electronic filter has fallen to a given proportion of the power in the passband. Most frequently this proportion is one half the passband power, also referred to as the 3 dB point since a fall of 3 dB corresponds approximately to half power. As a voltage ratio this is a fall to \\\\scriptstyle \\\\sqrt{1/2} \\\\ \\\\approx \\\\ 0.707 of the passband voltage. Other ratios besides the 3 dB point may also be relevant, for example see Chebyshev Filters below. =Single-pole transfer function example= The transfer function for the simplest low-pass filter, :H(s) = \\\\frac {1}{1+\\\\alpha s}, has a single pole at . The magnitude of this function in the plane is :\\\\left  H(j\\\\omega) \\\\right  = \\\\left  \\\\frac {1}{1+\\\\alpha j \\\\omega} \\\\right  =\\\\sqrt{ \\\\frac {1}{1 + \\\\alpha^2\\\\omega^2}}. At cutoff :\\\\left  H(j\\\\omega_ \\\\mathrm c) \\\\right  = \\\\frac {1}{\\\\sqrt{2}} = \\\\sqrt{ \\\\frac {1}{1 + \\\\alpha^2\\\\omega_\\\\mathrm c ^2}}. Hence, the cutoff frequency is given by :\\\\omega_ \\\\mathrm c = \\\\frac {1}{\\\\alpha}. Where is the s-plane variable, is angular frequency and is the imaginary unit. =Chebyshev filters= Sometimes other ratios are more convenient than the 3 dB point. For instance, in the case of the Chebyshev filter it is usual to define the cutoff frequency as the point after the last peak in the frequency response at which the level has fallen to the design value of the passband ripple. The amount of ripple in this class of filter can be set by the designer to any desired value, hence the ratio used could be any value.Mathaei, Young, Jones Microwave Filters, Impedance-Matching Networks, and Coupling Structures, pp.85-86, McGraw-Hill 1964. Radio communications In radio communication, skywave communication is a technique in which radio waves are transmitted at an angle into the sky and reflected back to Earth by layers of charged particles in the ionosphere. In this context, the term cutoff frequency refers to the maximum usable frequency means the frequency above which a radio wave fails to reflect off the ionosphere at the incidence angle required for transmission between two specified points by reflection from the layer. Waveguides The cutoff frequency of an electromagnetic waveguide is the lowest frequency for which a mode will propagate in it. In fiber optics, it is more common to consider the cutoff wavelength, the maximum wavelength that will propagate in an optical fiber or waveguide. The cutoff frequency is found with the characteristic equation of the Helmholtz equation for electromagnetic waves, which is derived from the electromagnetic wave equation by setting the longitudinal wave number equal to zero and solving for the frequency. Thus, any exciting frequency lower than the cutoff frequency will attenuate, rather than propagate. The following derivation assumes lossless walls. The value of c, the speed of light, should be taken to be the group velocity of light in whatever material fills the waveguide. For a rectangular waveguide, the cutoff frequency is : \\\\omega_{c} = c \\\\sqrt{\\\\left(\\\\frac{n \\\\pi}{a}\\\\right)^2 + \\\\left(\\\\frac{m \\\\pi}{b}\\\\right) ^2}, where the integers n,m \\\\ge 0 are the mode numbers, and a and b the lengths of the sides of the rectangle. For TE modes, n,m \\\\ge 0 (but n = m = 0 is not allowed), while for TM modes n, m \\\\ge 1 . The cutoff frequency of the TM01 mode (next higher from dominant mode TE11) in a waveguide of circular cross-section (the transverse-magnetic mode with no angular dependence and lowest radial dependence) is given by : \\\\omega_{c} = c \\\\frac{\\\\chi_{01}}{r} = c \\\\frac{2.4048}{r}, where r is the radius of the waveguide, and \\\\chi_{01} is the first root of J_{0}(r), the Bessel function of the first kind of order 1. The dominant mode TE11 cutoff frequency is given by : \\\\omega_{c} = c \\\\frac{\\\\chi_{11}}{r} = c \\\\frac{1.8412}{r} I. C. Hunter, Theory and Design of Microwave Filters, p.214 IET, 2001 . However, the dominant mode cutoff frequency can be reduced by the introduction of baffle inside the circular cross-section waveguide.A. Y. Modi and C. A. Balanis, \\"PEC-PMC Baffle Inside Circular Cross Section Waveguide for Reduction of Cut-Off Frequency,\\" in IEEE Microwave and Wireless Components Letters, vol. 26, no. 3, pp. 171-173, March 2016. For a single-mode optical fiber, the cutoff wavelength is the wavelength at which the normalized frequency is approximately equal to 2.405. =Mathematical analysis= The starting point is the wave equation (which is derived from the Maxwell equations), : \\\\left( abla^2-\\\\frac{1}{c^2}\\\\frac{\\\\partial^2}{\\\\partial{t}^2}\\\\right)\\\\psi(\\\\mathbf{r},t)=0, which becomes a Helmholtz equation by considering only functions of the form : \\\\psi(x,y,z,t) = \\\\psi(x,y,z)e^{i \\\\omega t}. Substituting and evaluating the time derivative gives : \\\\left( abla^2 + \\\\frac{\\\\omega^2}{c^2}\\\\right) \\\\psi(x,y,z) = 0. The function \\\\psi here refers to whichever field (the electric field or the magnetic field) has no vector component in the longitudinal direction - the \\"transverse\\" field. It is a property of all the eigenmodes of the electromagnetic waveguide that at least one of the two fields is transverse. The z axis is defined to be along the axis of the waveguide. The \\"longitudinal\\" derivative in the Laplacian can further be reduced by considering only functions of the form : \\\\psi(x,y,z,t) = \\\\psi(x,y)e^{i \\\\left(\\\\omega t - k_{z} z \\\\right)}, where k_z is the longitudinal wavenumber, resulting in : ( abla_{T}^2 - k_{z}^2 + \\\\frac{\\\\omega^2}{c^2}) \\\\psi(x,y,z) = 0, where subscript T indicates a 2-dimensional transverse Laplacian. The final step depends on the geometry of the waveguide. The easiest geometry to solve is the rectangular waveguide. In that case, the remainder of the Laplacian can be evaluated to its characteristic equation by considering solutions of the form : \\\\psi(x,y,z,t) = \\\\psi_{0}e^{i \\\\left(\\\\omega t - k_{z} z - k_{x} x - k_{y} y\\\\right)}. Thus for the rectangular guide the Laplacian is evaluated, and we arrive at : \\\\frac{\\\\omega^2}{c^2} = k_x^2 + k_y^2 + k_z^2 The transverse wavenumbers can be specified from the standing wave boundary conditions for a rectangular geometry crossection with dimensions a and b: : k_{x} = \\\\frac{n \\\\pi}{a}, : k_{y} = \\\\frac{m \\\\pi}{b}, where n and m are the two integers representing a specific eigenmode. Performing the final substitution, we obtain : \\\\frac{\\\\omega^2}{c^2} = \\\\left(\\\\frac{n \\\\pi}{a}\\\\right)^2 + \\\\left(\\\\frac{m \\\\pi}{b}\\\\right)^2 + k_{z}^2, which is the dispersion relation in the rectangular waveguide. The cutoff frequency \\\\omega_{c} is the critical frequency between propagation and attenuation, which corresponds to the frequency at which the longitudinal wavenumber k_{z} is zero. It is given by : \\\\omega_{c} = c \\\\sqrt{\\\\left(\\\\frac{n \\\\pi}{a}\\\\right)^2 + \\\\left(\\\\frac{m \\\\pi}{b}\\\\right)^2} The wave equations are also valid below the cutoff frequency, where the longitudinal wave number is imaginary. In this case, the field decays exponentially along the waveguide axis and the wave is thus evanescent.  See also  *Full width at half maximum *High-pass filter *Miller effect *Spatial cutoff frequency (in optical systems) *Time constant  References  *  External links  *Calculation of the center frequency with geometric mean and comparison to the arithmetic mean solution *Conversion of cutoff frequency fc and time constant œÑ *Mathematical definition of and information about the Bessel functions Category:Filter theory ","title":"Cutoff frequency"},{"id":"40989","text":"IXYS Litelink CPC5621A The term data access arrangement (DAA) has the following meanings: #In public switched telephone networks, a single item or group of items at the customer side of the network interface for data transmission purposes, including all equipment that may affect the characteristics of the interface. #A data circuit-terminating equipment (DCE) supplied or approved by a common carrier that permits a DCE or data terminal equipment (DTE) to be attached to the common carrier network. Data access arrangements are an integral part of all modems built for the public telephone network. In view of mixed voice and data access, DAAs are more generally referred to as direct access arrangements.  Requirement for DAAs  While DAA now describes an integral component of a device that connects to the telephone network, during the 60s and 70s it described a separate device mandated by the Bell System, connected between the telephone line and non-Bell equipment, typically a modem. Following the Carterfone decision, which required Bell to allow customers to attach any non-harmful equipment to their network, Bell mandated that subscribers use DAAs - purchased exclusively from Western Electric - to ensure the network was protected. These devices were not required for Bell-provided equipment, only equipment made by independent manufacturers. At the time, some subscribers believed that the DAA was a scheme by AT&T; to penalize and discourage use of non-Bell modems and recover lost profits from hardware sales, and the FCC began investigations into the legality of the practice. Subscribers also became frustrated when Bell failed to deliver DAAs in a timely fashion after the ruling, leading to the use of unauthorized third-party DAAs. There were two main varieties of DAA described by AT&T;: manual and automatic. A manual DAA required a call to be initiated (or answered) as normal, at which point it could then be connected to the third-party device, while an automatic DAA allowed an attached device to be connected without human intervention, important for receiving modem use. In 1975 the FCC implemented Part 68 of the FCC Rules, which granted permission for direct connection of any equipment to the telephone network given compliance with specific electrical requirements. This technically eliminated the need for DAAs, although the first modem that didn't require a separate DAA was not marketed until 1977. References * External links * Wireline DAA - introductory slides by 3am Systems * Direct-Access Arrangements Are Crucial To Successful Embedded-Modem Designs - in-depth article by Jeff Sorensen Category:Local loop ","title":"Data access arrangement"},{"id":"40990","text":"In telecommunications, computing, and information architecture, a data bank or databank is a repository of information on one or more subjects ‚Äì a database ‚Äì that is organized in a way that facilitates local or remote information retrieval and is able to process many continual queries over a long period of time. A data bank may be either centralized or decentralized, though most usage of this term refers to centralized storage and retrieval of information, by way of analogy to a monetary bank. The data in a data bank can be anything from scientific information like global temperature readings, and governmental information like census statistics, to financial-system records like credit card transactions, or the inventory available from various suppliers. Data bank may also refer to an organization primarily concerned with the construction and maintenance of such a database. The term databank is also obsolete (1960s through 1970s) computer jargon for database itself, and is frequently used in that sense in materials written in that period.  See also  * Star Wars Databank * Protein Data Bank * National Trauma Data Bank * Memory bank * International Tree-Ring Data Bank * Hazardous Substances Data Bank * Electron microscopy data bank * Dortmund Data Bank * Casio Databank * Conformational dynamics data bank * Databank Systems Limited a former New Zealand banking agency Sources * *The American Heritage Dictionary of the English Language, Fourth Edition. Houghton Mifflin, 2000. External links Category:Data management ","title":"Data bank"},{"id":"40991","text":"In telecommunication, data compaction is the reduction of the number of data elements, bandwidth, cost, and time for the generation, transmission, and storage of data without loss of information by eliminating unnecessary redundancy, removing irrelevancy, or using special coding. Examples of data compaction methods are the use of fixed-tolerance bands, variable-tolerance bands, slope-keypoints, sample changes, curve patterns, curve fitting, variable-precision coding, frequency analysis, and probability analysis. Simply squeezing noncompacted data into a smaller space, for example by increasing packing density by transferring images from newsprint to microfilm or by transferring data on punched cards onto magnetic tape, is not data compaction.  Everyday examples  The use of acronyms in texting is an everyday example. The number of bits required to transmit and store \\"WYSIWYG\\" (What You See Is What You Get) is reduced from its expanded equivalent (7 characters vs 28). The representation of Mersenne primes is another example. The largest known is over 17 million digits long but it is represented as M57885161 in a much more compacted form.  See also  * brevity code * commercial code (communications) * data compression References Category:Telecommunications techniques Category:Data compression ","title":"Data compaction"},{"id":"40992","text":"In metadata, the term data element is an atomic unit of data that has precise meaning or precise semantics. A data element has: # An identification such as a data element name # A clear data element definition # One or more representation terms # Optional enumerated values Code (metadata) # A list of synonyms to data elements in other metadata registries Synonym ring Data elements usage can be discovered by inspection of software applications or application data files through a process of manual or automated Application Discovery and Understanding. Once data elements are discovered they can be registered in a metadata registry. In telecommunication, the term data element has the following components: #A named unit of data that, in some contexts, is considered indivisible and in other contexts may consist of data items. #A named identifier of each of the entities and their attributes that are represented in a database. #A basic unit of information built on standard structures having a unique meaning and distinct units or values. #In electronic record-keeping, a combination of characters or bytes referring to one separate item of information, such as name, address, or age. In the areas of databases and data systems more generally a data element is a concept forming part of a data model. As an element of data representation, a collection of data elements forms a data structure.Beynon-Davies P. (2004). Database Systems 3rd Edition. Palgrave, Basingstoke, UK  In practice  In practice, data elements (fields, columns, attributes, etc.) are sometimes \\"overloaded\\", meaning a given data element will have multiple potential meanings. While a known bad practice, overloading is nevertheless a very real factor or barrier to understanding what a system is doing. See also * Application Discovery and Understanding * Data element definition * Data dictionary * Data hierarchy * ISO/IEC 11179 metadata registry specification * Metadata * Representation term * Universal Data Element Framework * Data collection system References * *  External links  * Association for Enterprise Integration * Federal XML Developer's Guide * ISO/IEC 11179 Standards (see ISO/IEC 11179-3:2003 clause 3.3.36) Category:Metadata Category:Enterprise application integration ","title":"Data element"},{"id":"40993","text":"In telecommunications, a data forwarder is a device that *(a) receives data from one data link and retransmits data representing the same information, using proper format and link protocols, to another data link. and *(b) may forward data between **(a) links that are identical, i.e., TADIL B to TADIL B, **(b) links that are similar, i.e., TADIL A to TADIL B, or **(c) links that are dissimilar, i.e., TADIL A to TADIL J. References Category:Telecommunications equipment ","title":"Data forwarder"},{"id":"40995","text":"Data integrity is the maintenance of, and the assurance of, the accuracy and consistency of data over its entire life-cycle, and is a critical aspect to the design, implementation and usage of any system which stores, processes, or retrieves data. The term is broad in scope and may have widely different meanings depending on the specific context even under the same general umbrella of computing. It is at times used as a proxy term for data quality,What is Data Integrity? Learn How to Ensure Database Data Integrity via Checks, Tests, & Best Practices while data validation is a pre-requisite for data integrity.What is Data Integrity? Data Protection 101 Data integrity is the opposite of data corruption.From the book: Uberveillance and the Social Implications of Microchip Implants: Emerging Page 40 The overall intent of any data integrity technique is the same: ensure data is recorded exactly as intended (such as a database correctly rejecting mutually exclusive possibilities), and upon later retrieval, ensure the data is the same as it was when it was originally recorded. In short, data integrity aims to prevent unintentional changes to information. Data integrity is not to be confused with data security, the discipline of protecting data from unauthorized parties. Any unintended changes to data as the result of a storage, retrieval or processing operation, including malicious intent, unexpected hardware failure, and human error, is failure of data integrity. If the changes are the result of unauthorized access, it may also be a failure of data security. Depending on the data involved this could manifest itself as benign as a single pixel in an image appearing a different color than was originally recorded, to the loss of vacation pictures or a business-critical database, to even catastrophic loss of human life in a life-critical system. Integrity types =Physical integrity= Physical integrity deals with challenges associated with correctly storing and fetching the data itself. Challenges with physical integrity may include electromechanical faults, design flaws, material fatigue, corrosion, power outages, natural disasters, and other special environmental hazards such as ionizing radiation, extreme temperatures, pressures and g-forces. Ensuring physical integrity includes methods such as redundant hardware, an uninterruptible power supply, certain types of RAID arrays, radiation hardened chips, error-correcting memory, use of a clustered file system, using file systems that employ block level checksums such as ZFS, storage arrays that compute parity calculations such as exclusive or or use a cryptographic hash function and even having a watchdog timer on critical subsystems. Physical integrity often makes extensive use of error detecting algorithms known as error-correcting codes. Human-induced data integrity errors are often detected through the use of simpler checks and algorithms, such as the Damm algorithm or Luhn algorithm. These are used to maintain data integrity after manual transcription from one computer system to another by a human intermediary (e.g. credit card or bank routing numbers). Computer-induced transcription errors can be detected through hash functions. In production systems, these techniques are used together to ensure various degrees of data integrity. For example, a computer file system may be configured on a fault-tolerant RAID array, but might not provide block-level checksums to detect and prevent silent data corruption. As another example, a database management system might be compliant with the ACID properties, but the RAID controller or hard disk drive's internal write cache might not be. =Logical integrity= This type of integrity is concerned with the correctness or rationality of a piece of data, given a particular context. This includes topics such as referential integrity and entity integrity in a relational database or correctly ignoring impossible sensor data in robotic systems. These concerns involve ensuring that the data \\"makes sense\\" given its environment. Challenges include software bugs, design flaws, and human errors. Common methods of ensuring logical integrity include things such as check constraints, foreign key constraints, program assertions, and other run-time sanity checks. Both physical and logical integrity often share many common challenges such as human errors and design flaws, and both must appropriately deal with concurrent requests to record and retrieve data, the latter of which is entirely a subject on its own.  Databases  Data integrity contains guidelines for data retention, specifying or guaranteeing the length of time data can be retained in a particular database. To achieve data integrity, these rules are consistently and routinely applied to all data entering the system, and any relaxation of enforcement could cause errors in the data. Implementing checks on the data as close as possible to the source of input (such as human data entry), causes less erroneous data to enter the system. Strict enforcement of data integrity rules results in lower error rates, and time saved troubleshooting and tracing erroneous data and the errors it causes to algorithms. Data integrity also includes rules defining the relations a piece of data can have, to other pieces of data, such as a Customer record being allowed to link to purchased Products, but not to unrelated data such as Corporate Assets. Data integrity often includes checks and correction for invalid data, based on a fixed schema or a predefined set of rules. An example being textual data entered where a date-time value is required. Rules for data derivation are also applicable, specifying how a data value is derived based on algorithm, contributors and conditions. It also specifies the conditions on how the data value could be re-derived. = Types of integrity constraints = Data integrity is normally enforced in a database system by a series of integrity constraints or rules. Three types of integrity constraints are an inherent part of the relational data model: entity integrity, referential integrity and domain integrity. * Entity integrity concerns the concept of a primary key. Entity integrity is an integrity rule which states that every table must have a primary key and that the column or columns chosen to be the primary key should be unique and not null. * Referential integrity concerns the concept of a foreign key. The referential integrity rule states that any foreign-key value can only be in one of two states. The usual state of affairs is that the foreign-key value refers to a primary key value of some table in the database. Occasionally, and this will depend on the rules of the data owner, a foreign-key value can be null. In this case, we are explicitly saying that either there is no relationship between the objects represented in the database or that this relationship is unknown. * Domain integrity specifies that all columns in a relational database must be declared upon a defined domain. The primary unit of data in the relational data model is the data item. Such data items are said to be non-decomposable or atomic. A domain is a set of values of the same type. Domains are therefore pools of values from which actual values appearing in the columns of a table are drawn. * User- defined integrity refers to a set of rules specified by a user, which do not belong to the entity, domain and referential integrity categories. If a database supports these features, it is the responsibility of the database to ensure data integrity as well as the consistency model for the data storage and retrieval. If a database does not support these features, it is the responsibility of the applications to ensure data integrity while the database supports the consistency model for the data storage and retrieval. Having a single, well-controlled, and well-defined data-integrity system increases * stability (one centralized system performs all data integrity operations) * performance (all data integrity operations are performed in the same tier as the consistency model) * re-usability (all applications benefit from a single centralized data integrity system) * maintainability (one centralized system for all data integrity administration). Modern databases support these features (see Comparison of relational database management systems), and it has become the de facto responsibility of the database to ensure data integrity. Companies, and indeed many database systems, offer products and services to migrate legacy systems to modern databases. = Examples = An example of a data-integrity mechanism is the parent-and-child relationship of related records. If a parent record owns one or more related child records all of the referential integrity processes are handled by the database itself, which automatically ensures the accuracy and integrity of the data so that no child record can exist without a parent (also called being orphaned) and that no parent loses their child records. It also ensures that no parent record can be deleted while the parent record owns any child records. All of this is handled at the database level and does not require coding integrity checks into each application.  File systems  Various research results show that neither widespread filesystems (including UFS, Ext, XFS, JFS and NTFS) nor hardware RAID solutions provide sufficient protection against data integrity problems. Some filesystems (including Btrfs and ZFS) provide internal data and metadata checksumming that is used for detecting silent data corruption and improving data integrity. If a corruption is detected that way and internal RAID mechanisms provided by those filesystems are also used, such filesystems can additionally reconstruct corrupted data in a transparent way. This approach allows improved data integrity protection covering the entire data paths, which is usually known as end-to-end data protection. Data integrity as applied to various industries * The U.S. Food and Drug Administration has created draft guidance on data integrity for the pharmaceutical manufacturers required to adhere to U.S. Code of Federal Regulations 21 CFR Parts 210‚Äì212. Outside the U.S., similar data integrity guidance has been issued by the United Kingdom (2015), Switzerland (2016), and Australia (2017). * Various standards for the manufacture of medical devices address data integrity either directly or indirectly, including ISO 13485, ISO 14155, and ISO 5840. * In early 2017, the Financial Industry Regulatory Authority (FINRA), noting data integrity problems with automated trading and money movement surveillance systems, stated it would make \\"the development of a data integrity program to monitor the accuracy of the submitted data\\" a priority. In early 2018, FINRA said it would expand its approach on data integrity to firms' \\"technology change management policies and procedures\\" and Treasury securities reviews. * Other sectors such as mining and product manufacturing are increasingly focusing on the importance of data integrity in associated automation and production monitoring assets. * Cloud storage providers have long faced significant challenges ensuring the integrity or provenance of customer data and tracking violations.  See also  * End-to-end data integrity * Message authentication * National Information Systems Security Glossary * Single version of the truth  References   Further reading  * * Category:Data quality Category:Transaction processing ","title":"Data integrity"},{"id":"40996","text":"A data link is the means of connecting one location to another for the purpose of transmitting and receiving digital information (data communication). It can also refer to a set of electronics assemblies, consisting of a transmitter and a receiver (two pieces of data terminal equipment) and the interconnecting data telecommunication circuit. These are governed by a link protocol enabling digital data to be transferred from a data source to a data sink. There are at least three types of basic data-link configurations that can be conceived of and used: * Simplex communications, most commonly meaning all communications in one direction only. * Half-duplex communications, meaning communications in both directions, but not both ways simultaneously. * Duplex communications, communications in both directions simultaneously. In civil aviation, a data- link system (known as Controller Pilot Data Link Communications) is used to send information between aircraft and air traffic controllers when an aircraft is too far from the ATC to make voice radio communication and radar observations possible. Such systems are used for aircraft crossing the Atlantic and Pacific oceans. One such system, used by Nav Canada and NATS over the North Atlantic, uses a five-digit data link sequence number confirmed between air traffic control and the pilots of the aircraft before the aircraft proceeds to cross the ocean. This system uses the aircraft's flight management computer to send location, speed and altitude information about the aircraft to the ATC. ATC can then send messages to the aircraft regarding any necessary change of course. In unmanned aircraft, land vehicles, boats, and spacecraft, a two-way (full-duplex or half-duplex) data-link is used to send control signals, and to receive telemetry. See also * ACARS * Deep Space Network * Space probe * Tactical Data Links * Terminal (telecommunication) * Timex Datalink * Unmanned Aircraft System Sources * * Category:Data transmission ","title":"Data link"},{"id":"40997","text":"A data service unit, sometimes called a digital service unit, is a piece of telecommunications circuit terminating equipment that transforms digital data between telephone company lines and local equipment. The device converts bipolar digital signals coming ultimately from a digital circuit and directly from a Channel service unit (CSU), into a format (e.g. RS- 530) compatible with the piece of data terminal equipment (DTE) (e.g. a router) to which the data is sent. The DSU also performs a similar process in reverse for data heading from the DTE toward the circuit. The telecommunications service a DSU supports can be a point-to-point or multipoint operation in a digital data network. Form and purpose A DSU is a two or more port device; one port is called the WAN (Wide Area Network) port and the other is called a DTE port. The purpose of the DSU is to transfer serial data synchronously between the WAN port and the DTE ports. If more than one DTE port is used, the DSU assigns the DTE data according to time slots (channels) on the WAN side. On the WAN side, the DSU, via a CSU, interfaces with a digital carrier such as DS1 or DS3 or a low speed Digital Data Service. On the DTE side, the DSU provides control lines, timing lines and appropriate physical and electrical interface. To maintain the synchronous relationship between the ports, the DSU manages timing by slaving ports to the bit rate of another or to its internal clock. Typically, the DTE port provides timing to the data terminal equipment while the WAN port dictates the rate. DSUs usually include some maintenance capabilities. At minimum, they can loop data back at either the WAN or DTE ports, or at both. When only one port is looped back, the data received at that port is simultaneously sent back toward the port and passed in normal fashion to the other port. Most DSUs also allow various data patterns to be generated and monitored to measure error rate of the communication link. A DSU may be a separate piece of equipment, or may be combined in a CSU/DSU. References Category:Telecommunications equipment ","title":"Data service unit"},{"id":"40998","title":"Data signaling rate"},{"id":"40999","text":"In telecommunication, a data transmission circuit is the transmission media and the intervening equipment used for the data transfer between data terminal equipment (DTEs). A data transmission circuit includes any required signal conversion equipment. A data transmission circuit may transfer information in (a) one direction only, (b) either direction but one way at a time, or (c) both directions simultaneously. See duplex (telecommunications). See also * Telecommunication circuit References Category:Data transmission ","title":"Data transmission circuit"},{"id":"41000","text":"In communications messages, a date-time group (DTG) is a set of characters, usually in a prescribed format, used to express the year, the month, the day of the month, the hour of the day, the minute of the hour, and the time zone, if different from Coordinated Universal Time (UTC). The order in which these elements are presented may vary. The DTG is usually placed in the header of the message. One example is \\" (UTC)\\". The DTG may indicate either the date and time a message was dispatched by a transmitting station or the date and time it was handed into a transmission facility by a user or originator for dispatch. The DTG may be used as a message identifier if it is unique for each message.  Military Date Time Group  A form of DTG is used in the US Military's message traffic (a form of Automated Message Handling System). In US military messages and communications (e.g., on maps showing troop movements) the format is DD HHMMZ MON YY. Although occasionally seen with spaces, it can also be written as a single string of characters. Example 1: represents (Jul) 09 16:30 Jul 2011 (UTC). Example 2: represents (UTC).  See also *Calendar date *ISO 8601  References  *TM 20-205, the Dictionary of United States Army Terms (1944) *ACP 121(I) p 3‚Äì7 External links Category:Calendars ","title":"Date-time group"},{"id":"41001","text":"1955 DB Panhard HBR competition DB Panhard Le Mans Luxe DB (until 1947 known as Deutsch-Bonnet) was a French automobile maker between 1938 and 1961, based in Champigny-sur-Marne near Paris. The firm was founded by Charles Deutsch and Ren√© Bonnet, an offshoot of the Deutsch family's existing coachbuilding shop which had been taken over by Bonnet in 1932.Borgeson, p. 55 Immediately before the war the partners concentrated on making light-weight racing cars, but a few years after the war, starting with the presentation of a Panhard based cabriolet at the 1950 Paris Motor Show, the company also began to produce small road-going sports cars. By 1952 the company no longer had its own stand at the Paris Motor Show, but one of their cars appeared as a star attraction on the large Panhard stand, reflecting the level of cooperation between the two businesses. The company was defunct by 1961, as Deutsch and Bonnet's differing design philosophies hamstrung further cooperation. The number of DB's built is not certain; estimates of up to 2,000 cars are mentionedBorgeson, p. 54 but more conservative numbers are closer to one thousand. Light-weight engineering The business produced light sports cars, originally in steel or aluminium but subsequently with fibreglass bodies mainly powered by Panhard flat-twin engines, most commonly of 610, 744, or 848 cc. Deutsch was a \\"theoretical engineer who had a natural instinct for aerodynamics,\\" while Bonnet was a more \\"pragmatic mechanical engineer\\". The fibreglass bodies covered a tubular central beam chassis made from steel, with front wheel drive and four wheel independent suspension directly lifted from the Panhard donors. Until 1952 all DBs had been intended for competition purposes only. Racing origins 1949 and 1950 Bonnet had been promised a works drive in an Amilcar P√©gase in the 1936 French Grand Prix for sports cars, but when this failed to materialise they set about building their own racer.Borgeson, p. 56 The 1938 alloy-bodied DB1 roadster was a special, built using the remains of a Citro√´n Traction Avant 11CV. The construction took seventeen months.Borgeson, p. 57 A series of numbered successors followed. The close-roofed 1.5-litre DB2's career was hindered by the war and was sold later, without Deutsch ever using it.Borgeson, p. 58 The DB3 was a monocoque project developed during the war, but was never built, as the improved pontoon-bodied DB4 took preference. With a central beam chassis with a forked cradle for the 1.5 litre Traction 7A-based engine (originally intended for the DB2) it was finished in July 1945, with most of the work having been carried out in secret during the occupation. The very similar 2-litre DB5 was finished soon thereafter. Their two specials both placed in the first postwar race in France, in Paris in 1945, being the only post-war cars entered. An open- wheeled DB7 appeared in 1947 (preceded by the heavy and large DB6 which saw very little action), after which the Automobiles Deutsch & Bonnet was officially formed. 1950 DB Racer 500 Neither single-seater DB was at all successful, but they did show Deutsch - who had hitherto preferred dependable standard units - that a tuned engine would become necessary. DB thus moved into the performance parts market, developing and offering a four-speed conversion for Citro√´ns and an overhead camshaft head - developed with the aid of engine specialists Maurice Sainturat and Dante Giacosa. The DB8 appeared in 1948, and won two concours d'√©legances before partaking in any competitions.Borgeson, p. 59 Their early cars were all built using Citro√´n parts, but supply was troublesome and DB soon moved on to using Panhard technology. This relationship came about as Deutsch was an officer of independent racer's club AGACI. When this organization decided to begin a Mouvement Racer 500, modelled on the British Formula 3, Deutsch offered club members the design of a racing car using a Panhard 500 engine. One member asked to have DB build such a car, and after it made a star appearance at the 1949 Paris Salon Panhard was happy to support the construction of about fifteen more. The formula expired in 1951, with the DB Panhard 500 never competitive abroad. DB was very active in competition, especially in Le Mans 24 Hours and other long distance racing. Nearly all DBs, even the road cars, were designed with competition foremost in mind. In 1952, a DB Speedster was entered in the 12 Hours of Sebring and won its class handsomely, beginning its career in the United States market. Steve Lansing and Ward Morehouse were the drivers. At the 1954 Le Mans DB entered five cars and were also involved with Panhards \\"Monopole\\" racers. Ren√© Bonnet himself, together with racing legend √âlie Bayol, finished tenth overall and best of the DBs. The other Panhard- engined also finished (in 16th), while three Renault-engined central-seater DB designs all failed to complete the race. The Renault-engined designs had been created as a concession to pressure from DB's customers, but they did very badly in the race, in part because of a shortage of preparation time for what was an unknown entity to Deutsch and Bonnet. In either case, DB proceeded to focus on Panhard designs exclusively. Road cars The 1949 DB8 was bodied by Antem of Belgium and shown at the 1949 Paris Salon. While a handsome (winning two concours d'√©legances) and modern design, Citro√´n refused to allow the provision of parts for series production. After DB began to depend on Panhard for engines, Antem was again commissioned to make a cabriolet with the intent to build a small series of street cars. long, the car weighed and used the Dyna's 750 cc flat-two and much of the suspension and drivetrain. As with most DBs, it had a central frame with two outliers. An 850 cc version was also offered, a model which could reach 140 rather than the 125‚Äì130 km/h of the smaller one. Naturally, Panhard developed a racing barquette version (called the Tank) of the Antem cabriolet. These competed at Le Mans 1951 as well as several other races. About twenty Antem cabriolets were built in 1951, but DB chose to let it die in favor of a coup√© version of the same (\\"Coach\\" in French). A few DB-Antem Coach were built, mostly for competition. These had bodywork designed by Deutsch, and again mainly relied on Dyna underpinnings and a central steel-tube frame.Borgeson, p. 63 The steel-bodied, Frua-designed 1952 \\"Mille Miles\\" (celebrating class victories at the Mille Miglia) was a mini-GT with a 65 hp Panhard two-cylinder. It was somewhat expensive, and at the 1953 Paris Salon a Chausson-designed DB Coach in fibreglass, although it did not enter production until 1954. The HBR 4/5 model (1954‚Äì1959) was the partners' most successful project to date, with several hundred of the little cars produced between 1954 and 1959. This was followed by the Le Mans convertible and hardtop, which was shown in 1959 and built by DB until 1962, and continued until 1964 by Ren√© Bonnet. About 660 of the Mille Miles/Coach/HBR were built, and 232 DB Le Mans (not including the Bonnet-built cars). Later versions could be equipped with engines of 1 and 1.3 litres, and superchargers were also available. No two cars may have been alike, as they were built according to customer specifications from a wide range of options. More racing success Deutsch's very efficient and influential aerodynamic designs allowed DB race cars to reach impressive top speeds despite the small Panhard flat-twin engine. DB's received class victories at Le Mans (three times), Sebring (twice), and Mille Miglia (four times). DB even managed an outright win in the handicapped 1954 Tourist Trophy sports car race, with Laureau and Armagnac driving. DB always showed strongly in the \\"Index of Performance\\", a category especially suitable for DB's small-engined, aerodynamic little racers. The Index of Performance is perhaps best known at the Le Mans 24 hours competition, but the category also existed at many French automobile races of the era, such as the Tour de France. DBs were also successful in American SCCA racing, where they racked up an impressive number of victories in the H-sports category. Disagreement and the end of the partnership Deutsch and Bonnet disagreed whether they should build cars of front-wheel drive or mid-engined design. There was also disagreement on which engines to use. Charles Deutsch, wanting to stick to Panhard engines, left DB in 1961 to found his own firm (CD). Bonnet founded Automobiles Ren√© Bonnet, producing cars powered by Renault engines: this business was later to become part of Matra Automobiles. Deutsch ended up an engineering consultant. Works cited * References External links *http://sports.racer.net/chassis/db/index.htm *https://web.archive.org/web/20090823015812/http://www.velocetoday.com/archives/90 *http://vea.qc.ca/vea/marques1/db.htm *Deutsch Bonnet at Citroenet *http://dbrb.free.fr Category:Defunct motor vehicle manufacturers of France Category:Sports car manufacturers ","title":"DB (car)"},{"id":"41002","text":"400px A weighting filter is used to emphasize or suppress some aspects of a phenomenon compared to others, for measurement or other purposes.  Audio applications  In each field of audio measurement, special units are used to indicate a weighted measurement as opposed to a basic physical measurement of energy level. For sound, the unit is the phon (1 kHz equivalent level). = Loudness measurements = In the measurement of loudness, for example, an A-weighting filter is commonly used to emphasize frequencies around 3‚Äì6 kHz where the human ear is most sensitive, while attenuating very high and very low frequencies to which the ear is insensitive. The aim is to ensure that measured loudness corresponds well with subjectively perceived loudness. A-weighting is only really valid for relatively quiet sounds and for pure tones as it is based on the 40-phon Fletcher‚ÄìMunson equal-loudness contour. The B and C curves were intended for louder sounds (though they are less used) while the D curve is used in assessing loud aircraft noise (IEC 537). = Telecommunications = In the field of telecommunications, weighting filters are widely used in the measurement of electrical noise on telephone circuits, and in the assessment of noise as perceived through the acoustic response of different types of instrument (handset). Other noise-weighting curves have existed, e.g. DIN standards. The term psophometric weighting, though referring in principle to any weighting curve intended for noise measurement, is often used to refer to a particular weighting curve, used in telephony for narrow- bandwidth voiceband speech circuits. = Environmental noise measurement = A-weighted decibels are abbreviated dB(A) or dBA. When acoustic (calibrated microphone) measurements are being referred to, then the units used will be dB SPL (sound pressure level) referenced to 20 micropascals = 0 dB SPL. Caution: dBa, sometimes dBrn adjusted, is NOT a synonym for dBA.Federal Standard 1037, Glossary of Telecommunication Terms, entry dBa: https://www.its.bldrdoc.gov/fs-1037/dir-010/_1471.htm The A-weighting curve has been widely adopted for environmental noise measurement, and is standard in many sound level meters (see ITU-R 468 weighting for a further explanation). A-weighting is also in common use for assessing potential hearing damage caused by loud noise, though this seems to be based on the widespread availability of sound level meters incorporating A-Weighting rather than on any good experimental evidence to suggest that such use is valid. The distance of the measuring microphone from a sound source is often \\"forgotten\\", when SPL measurements are quoted, making the data useless. In the case of environmental or aircraft noise, distance need not be quoted as it is the level at the point of measurement that is needed, but when measuring refrigerators and similar appliances the distance should be stated; where not stated it is usually one metre (1 m). An extra complication here is the effect of a reverberant room, and so noise measurement on appliances should state \\"at 1 m in an open field\\" or \\"at 1 m in anechoic chamber\\". Measurements made outdoors will approximate well to anechoic conditions. A-weighted SPL measurements of noise level are increasingly to be found on sales literature for domestic appliances such as refrigerators and freezers, and computer fans. Although the threshold of hearing is typically around 0 dB SPL, this is in fact very quiet indeed, and appliances are more likely to have noise levels of 30 to 40 dB SPL. = Audio reproduction and broadcasting equipment = 400px Human sensitivity to noise in the region of 6 kHz became particularly apparent in the late 1960s with the introduction of compact cassette recorders and Dolby-B noise reduction. A-weighted noise measurements were found to give misleading results because they did not give sufficient prominence to the 6 kHz region where the noise reduction was having greatest effect, and sometimes one piece of equipment would even measure worse than another and yet sound better, because of differing spectral content. ITU-R 468 noise weighting was therefore developed to more accurately reflect the subjective loudness of all types of noise, as opposed to tones. This curve, which came out of work done by the BBC Research Department, and was standardised by the CCIR and later adopted by many other standards bodies (IEC, BSI/) and, , is maintained by the ITU. Noise measurements using this weighting typically also use a quasi-peak detector law rather than slow averaging. This also helps to quantify the audibility of bursty noise, ticks and pops that might go undetected with a slow rms measurement. ITU-R 468 noise weighting with quasi-peak detection is widely used in Europe, especially in telecommunications, and in broadcasting particularly after it was adopted by the Dolby corporation who realised its superior validity for their purposes. Its advantages over A-weighting seem to be less well appreciated in the USA and in consumer electronics, where the use of A-weighting predominates‚Äîprobably because A-weighting produces a 9 to 12 dB \\"better\\" specification, see specsmanship. It is commonly used by broadcasters in Britain, Europe, and former countries of the British Empire such as Australia and South Africa. Though the noise level of 16-bit audio systems (such as CD players) is commonly quoted (on the basis of calculations that take no account of subjective effect) as ‚àí96 dB relative to FS (full scale), the best 468-weighted results are in the region of ‚àí68 dB relative to Alignment Level (commonly defined as 18 dB below FS) i.e. ‚àí86 dB relative to FS. The use of weighting curves is in no way to be regarded as 'cheating', provided that the proper curve is used. Nothing of relevance is being 'hidden', and even when, for example, hum is present at 50 or 100 Hz at a level above the quoted (weighted) noise floor this is of no importance because our ears are very insensitive to low frequencies at low levels, so it will not be heard. A-weighting is often used to compare and qualify ADCs, for instance, because it more accurately represents the way noise shaping hides dither noise in the ultrasonic range.  Other applications of weighting  In the measurement of gamma rays or other ionising radiation, a radiation monitor or dosimeter will commonly use a filter to attenuate those energy levels or wavelengths that cause the least damage to the human body, while letting through those that do the most damage, so that any source of radiation may be measured in terms of its true danger rather than just its 'strength'. The sievert is a unit of weighted radiation dose for ionising radiation, which supersedes the older unit the REM (roentgen equivalent man). Weighting is also applied to the measurement of sunlight when assessing the risk of skin damage through sunburn, since different wavelengths have different biological effects. Common examples are the SPF of sunscreen, and the UV index. Another use of weighting is in television, where the red, green and blue components of the signal are weighted according to their perceived brightness. This ensures compatibility with black and white receivers, and also benefits noise performance and allows separation into meaningful luminance and chrominance signals for transmission.  See also  *Weighting *Weighting curve *Sone *Phon *ITU-R 468 noise weighting *Psophometric weighting *Equal-loudness contour *Noise pollution *Noise regulation References  External links  *Noise measurement briefing *Calculator for A,C,U, and AU weighting values *A-weighting filter circuit for audio measurements *AES pro audio reference definition of \\"weighting filters\\" *What is a decibel? *Weighting filter according DIN EN 61672-1 2003-10 (DIN-IEC 651) Calculation: frequency f to dBA and dBC Category:Audio engineering ","title":"Weighting filter"},{"id":"41004","text":"The symbol dBrn or dB(rn) is an abbreviation for decibels above reference noise. Weighted noise power in dB is referred to 1.0 picowatt. Thus, 0 dBrn = -90 dBm. Use of 144 line, 144-receiver, or C-message weighting, or flat weighting, can be indicated in parentheses. With C-message weighting, a one- milliwatt, 1000 Hz tone will read +90 dBrn, but the same power as white noise, randomly distributed over a 3 kHz band will read approximately +88.5 dBrn, because of the frequency weighting. With 144 weightings, a one milliwatt, 1000 Hz white noise tone will also read +90 dBrn, but the same 3 kHz power will only read +82 dBrn, because of the different frequency weighting. References Category:Mechanics Category:Units of measurement Category:Logarithmic scales of measurement ","title":"DBrn"},{"id":"41005","text":"Terminal adapter for X.21 DCE and DTE network. Telefonnetz refers to a telephone network; EIA-232 is also called RS-232, the serial communication standard. A data circuit-terminating equipment (DCE) is a device that sits between the data terminal equipment (DTE) and a data transmission circuit. It is also called data communication(s) equipment and data carrier equipment. Usually, the DTE device is the terminal (or computer), and the DCE is a modem. In a data station, the DCE performs functions such as signal conversion, coding, and line clocking and may be a part of the DTE or intermediate equipment. Interfacing equipment may be required to couple the data terminal equipment (DTE) into a transmission circuit or channel and from a transmission circuit or channel into the DTE. Usage Although the terms are most commonly used with RS-232, several data communication standards define different types of interfaces between a DCE and a DTE. The DCE is a device that communicates with a DTE device in these standards. Standards that use this nomenclature include: * Federal Standard 1037C, MIL-STD-188 * RS-232 * Certain ITU-T standards in the V series (notably V.24 and V.35) * Certain ITU-T standards in the X series (notably X.21 and X.25) A general rule is that DCE devices provide the clock signal (internal clocking) and the DTE device synchronizes on the provided clock (external clocking). D-sub connectors follow another rule for pin assignment. DTE devices usually transmit on pin connector number 2 and receive on pin connector number 3. DCE devices are just the opposite: pin connector number 2 receives and pin connector number 3 transmits the signals. When two devices, that are both DTE or both DCE, must be connected together without a modem or a similar media translator between them, a crossover cable must be used, e.g. a null modem for RS-232 or an Ethernet crossover cable. See also *Networking hardware  References   External links  * Data Terminating Equipment or Data Circuit-Terminating Equipment speeds, IBM Category:Data transmission Category:Telecommunications equipment ","title":"Data circuit-terminating equipment"},{"id":"41008","text":"Degradation may refer to: Science * Degradation (geology), lowering of a fluvial surface by erosion * Degradation (telecommunications), of an electronic signal * Biodegradation of organic substances by living organisms * Environmental degradation in ecology * Land degradation, a process in which the value of the biophysical environment is affected by a combination of human-induced processes acting upon the land * Polymer degradation, as plastics age Other * Elegant degradation, gradual rather than sudden * Graceful degradation, in a fault-tolerant system * Degradation (knighthood), revocation of knighthood * Cashiering, whereby a military officer is dismissed for misconduct * Reduction in rank, whereby a military officer is reduced to a lower rank for misconduct * Degradation, the former ceremony of defrocking a disgraced priest * Degradation, a song by the Violent Femmes, from Add It Up (1981‚Äì1993) See also * D√©grad√©, 2015 Palestinian film ","title":"Degradation"},{"id":"41009","text":"The degree of isochronous distortion, in data transmission, is the ratio of the absolute value of the maximum measured difference between the actual and the theoretical intervals separating any two significant instants of modulation (or demodulation), to the unit interval. These instants are not necessarily consecutive. This value is usually expressed as a percentage. The result of the measurement should be qualified by an indication if the period, usually limited, of the observation. For a prolonged modulation (or demodulation), it will be appropriate to consider the probability that an assigned value of the degree of distortion will be exceeded. References Category:Data transmission ","title":"Degree of isochronous distortion"},{"id":"41010","text":"In telecommunication, the term degree of start-stop distortion has the following meanings: # In asynchronous serial communication data transmission, the ratio of (a) the absolute value of the maximum measured difference between the actual and theoretical intervals separating any significant instant of modulation (or demodulation) from the significant instant of the start element immediately preceding it to (b) the unit interval. # The highest absolute value of individual distortion affecting the significant instants of a start- stop modulation. The degree of distortion of a start-stop modulation (or demodulation) is usually expressed as a percentage. Distinction can be made between the degree of late (positive) distortion and the degree of early (negative) distortion. References Category:Telecommunications engineering Category:Data transmission ","title":"Degree of start-stop distortion"},{"id":"41012","text":"Delay (from Latin: dilatio) may refer to:  Arts, entertainment, and media  * Delay 1968, a 1981 album by German experimental rock band Can * The Delay, a 2012 Uruguayan film  People  * B. H. DeLay (1891‚Äì1923), American aviator and actor * Dorothy DeLay (1917‚Äì2002), American violin instructor * Florence Delay (born 1941), French academician and actor * Jan Delay (born 1976), German musician * Jean Delay (1907‚Äì1987), French psychiatrist, neurologist, and writer * Paul deLay (1952‚Äì2007), American blues musician * Tom DeLay (born 1947), American politician * Vladislav Delay (born 1976), Finnish musician  Science and technology  =Computing and telecommunication= * Delay (audio effect), a technology for producing delayed playback of an audio signal * Delay (programming), a programming language construct for delaying evaluation of an expression * Analog delay line, used to delay a signal * Broadcast delay, a practice of time-shifting transmissions * Delay differential equation which describes or governs the dynamics of a time-delay system in terms of its values at previous times * Delay encoding, a radio transmission technique * Delay line (disambiguation) * Delay line memory, a type of random access memory * Delay line oscillator, a form of electronic oscillator that uses a delay line as its principal timing element * Delay slot, a computer instruction slot that gets executed without the effects of a preceding instruction * Delay-gradient congestion control, a class of network congestion control algorithms, which react to the differences in round-trip delay time (RTT) * Delay-locked loop (DLL), is a digital electronic circuit similar to a phase-locked loop (PLL) * Digital delay generator or digital-to-time converter, a piece of electronic test equipment that provides precise delays for triggering, syncing, delaying and gating events * End-to-end delay, or one-way delay (OWD), the time taken for a packet to be transmitted across a network from source to destination * Group delay and phase delay, time delay of the amplitude envelopes of the various sinusoidal components of a signal * Network delay, the delay of an IP packet within an IP network * Propagation delay, a measurement of the time for a signal to reach its destination * Queuing delay or queueing delay, the time a job waits in a queue until it can be executed * Satellite delay, the noticeable latency which occurs due to the speed of light, when sending data to and from satellites * Transmission delay, store-and-forward delay or packetization delay, the network delay caused by the data-rate of the link =Other uses in science and technology= * Bi- directional delay line, a numerical analysis technique used in computer simulation for solving ordinary differential equations by converting them to hyperbolic equations * Delay composition, delay charge or delay train, a pyrotechnic chemical mixture used to delay the firing of an explosion (delay- action bomb) * Delayed gratification, the ability to resist the temptation for an immediate reward and wait for a later reward * Shapiro time delay, a test used to confirm general relativity * Speech delay, also known as alalia, refers to a delay in the development or use of the mechanisms that produce speech Sports * Delay (game), an official decision to stop a sporting event after commencement * Delay of game, an action in a sports game in which a player or team deliberately stalls the game Other uses *Delaying payment of a debt, a crime in the United Kingdom, under the Theft Act 1978  See also  * Delay line (disambiguation) * Echo * Laches (equity), unreasonable delay in pursuing a legal action * Lag, a term used when a real-time application fails to respond in a timely fashion * Latency (disambiguation) * Procrastination * Response time (disambiguation) * Sound * Speed * Time * Time dilation, relativistic effect between two events occurring in different reference frames or gravitational fields ","title":"Delay"},{"id":"41014","text":"Delay line may refer to: * Propagation delay, the length of time taken for something to reach its destination * Analog delay line, used to delay a signal * Bi-directional delay line, a numerical analysis technique used in computer simulation for solving ordinary differential equations by converting them to hyperbolic equations * Digital delay line, a sequential logic element * Delay line memory, a form of computer memory used on some of the earliest digital computers ","title":"Delay line"},{"id":"41015","text":"Principle of the delta PWM. The output signal (blue) is compared with the limits (green). The limits (green) correspond to the reference signal (red), offset by a given value. Every time the output signal reaches one of the limits, the PWM signal changes state. A delta modulation (DM or Œî-modulation) is an analog-to-digital and digital-to-analog signal conversion technique used for transmission of voice information where quality is not of primary importance. DM is the simplest form of differential pulse-code modulation (DPCM) where the difference between successive samples are encoded into n-bit data streams. In delta modulation, the transmitted data are reduced to a 1-bit data stream. Its main features are: * The analog signal is approximated with a series of segments. * Each segment of the approximated signal is compared to the preceding bits and the successive bits are determined by this comparison. * Only the change of information is sent, that is, only an increase or decrease of the signal amplitude from the previous sample is sent whereas a no-change condition causes the modulated signal to remain at the same 0 or 1 state of the previous sample. To achieve high signal-to-noise ratio, delta modulation must use oversampling techniques, that is, the analog signal is sampled at a rate several times higher than the Nyquist rate. Derived forms of delta modulation are continuously variable slope delta modulation, delta-sigma modulation, and differential modulation. Differential pulse-code modulation is the superset of DM. Principle Rather than quantizing the absolute value of the input analog waveform, delta modulation quantizes the difference between the current and the previous step, as shown in the block diagram in Fig. 1\\\\. Fig. 1 ‚Äì Block diagram of a Œî-modulator/demodulator The modulator is made by a quantizer which converts the difference between the input signal and the average of the previous steps. In its simplest form, the quantizer can be realized with a comparator referenced to 0 (two levels quantizer), whose output is 1 or 0 if the input signal is positive or negative. It is also a bit-quantizer as it quantizes only a bit at a time. The demodulator is simply an integrator (like the one in the feedback loop) whose output rises or falls with each 1 or 0 received. The integrator itself constitutes a low-pass filter. Transfer characteristics The transfer characteristics of a delta modulated system follows a signum function, as it quantizes only two levels and also one-bit at a time. The two sources of noise in delta modulation are \\"slope overload\\", when step size is too small to track the original waveform, and \\"granularity\\", when step size is too large. But a 1971 study shows that slope overload is less objectionable compared to granularity than one might expect based solely on SNR measures. N. S. Jayant and A. E. Rosenberg. \\"The Preference of Slope Overload to Granularity in the Delta Modulation of Speech\\". The Bell System Technical Journal, Volume 50, no. 10, December 1971. original Google cached HTML version Output signal power In delta modulation there is a restriction on the amplitude of the input signal, because if the transmitted signal has a large derivative (abrupt changes) then the modulated signal can not follow the input signal and slope overload occurs. E.g. if the input signal is m(t)={A\\\\cos (\\\\omega t)}, the modulated signal (derivative of the input signal) which is transmitted by the modulator is \\\\dot{m}(t)_{max}=\\\\omega A, whereas the condition to avoid slope overload is \\\\dot{m}(t)_{max}=\\\\omega A<\\\\sigma f_s. So the maximum amplitude of the input signal can be A_{max}={\\\\sigma f_s \\\\over \\\\omega}, where fs is the sampling frequency and œâ is the frequency of the input signal and œÉ is step size in quantization. So Amax is the maximum amplitude that DM can transmit without causing the slope overload and the power of transmitted signal depends on the maximum amplitude. Bit-rate If the communication channel is of limited bandwidth, there is the possibility of interference in either DM or PCM. Hence, 'DM' and 'PCM' operate at same bit-rate which is equal to N times the sampling frequency. Adaptive delta modulation Adaptive delta modulation (ADM) was first published by Dr. John E. Abate (AT&T; Bell Laboratories Fellow) in his doctoral thesis at NJ Institute Of Technology in 1968. ADM was later selected as the standard for all NASA communications between mission control and space-craft. Adaptive delta modulation or Continuously variable slope delta modulation (CVSD) is a modification of DM in which the step size is not fixed. Rather, when several consecutive bits have the same direction value, the encoder and decoder assume that slope overload is occurring, and the step size becomes progressively larger. Otherwise, the step size becomes gradually smaller over time. ADM reduces slope error, at the expense of increasing quantizing error. This error can be reduced by using a low-pass filter. ADM provides robust performance in the presence of bit errors meaning error detection and correction are not typically used in an ADM radio design, it is this very useful technique that allows for adaptive-delta- modulation. Applications Contemporary applications of Delta Modulation includes, but is not limited to, recreating legacy synthesizer waveforms. With the increasing availability of FPGAs and game-related ASICs, sample rates are easily controlled so as to avoid slope overload and granularity issues. For example, the C64DTV used a 32 MHz sample rate, providing ample dynamic range to recreate the SID output to acceptable levels.Olsen, Mikkel Holm. 2011 November 16. Accessed 2013 June 29. http://symlink.dk/nostalgia/dtv/dtvsid/ SBS Application 24 kbps delta modulation Delta Modulation was used by Satellite Business Systems or SBS for its voice ports to provide long distance phone service to large domestic corporations with a significant inter- corporation communications need (such as IBM). This system was in service throughout the 1980s. The voice ports used digitally implemented 24 kbit/s delta modulation with Voice Activity Compression (VAC) and echo suppressors to control the half second echo path through the satellite. They performed formal listening tests to verify the 24 kbit/s delta modulator achieved full voice quality with no discernible degradation as compared to a high quality phone line or the standard 64 kbit/s Œº-law companded PCM. This provided an eight to three improvement in satellite channel capacity. IBM developed the Satellite Communications Controller and the voice port functions. The original proposal in 1974, used a state-of-the-art 24 kbit/s delta modulator with a single integrator and a Shindler Compander modified for gain error recovery. This proved to have less than full phone line speech quality. In 1977, one engineer with two assistants in the IBM Research Triangle Park, NC laboratory was assigned to improve the quality. The final implementation replaced the integrator with a Predictor implemented with a two pole complex pair low-pass filter designed to approximate the long term average speech spectrum. The theory was that ideally the integrator should be a predictor designed to match the signal spectrum. A nearly perfect Shindler Compander replaced the modified version. It was found the modified compander resulted in a less than perfect step size at most signal levels and the fast gain error recovery increased the noise as determined by actual listening tests as compared to simple signal to noise measurements. The final compander achieved a very mild gain error recovery due to the natural truncation rounding error caused by twelve bit arithmetic. The complete function of delta modulation, VAC and Echo Control for six ports was implemented in a single digital integrated circuit chip with twelve bit arithmetic. A single digital-to-analog converter (DAC) was shared by all six ports providing voltage compare functions for the modulators and feeding sample and hold circuits for the demodulator outputs. A single card held the chip, DAC and all the analog circuits for the phone line interface including transformers. See also * Adaptive differential pulse-code modulation * Analog-to-digital converter (ADC) * Codec * Pulse-code modulation * Pulse-density modulation ** Delta-sigma modulation ** Direct Stream Digital Sources * * External links * Delta Modulator Category:Digital signal processing ","title":"Delta modulation"},{"id":"41016","text":"In telecommunication, a demand assignment is a method which several users share access to a communication channel on a real-time basis, i.e., a user needing to communicate with another user on the same network requests the required circuit, uses it, and when the call is finished, the circuit is released, making the circuit available to other users. Demand assignment is similar to conventional telephone switching, in which common trunks are provided for many users, on a demand basis, through a limited-size trunk group. See also *Time-assignment speech interpolation References * Category:Teletraffic ","title":"Demand assignment"},{"id":"41017","text":"In telecommunication, electronics and the electrical power industry, the term demand factor is used to refer to the fractional amount of some quantity being used relative to the maximum amount that could be used by the same system. The demand factor is always less than or equal to one. As the amount of demand is a time dependent quantity so is the demand factor. : f_\\\\text{Demand}(t) = \\\\frac{\\\\text{Demand}}{\\\\text{Maximum possible demand}} The demand factor is often implicitly averaged over time when the time period of demand is understood by the context.  Electrical engineering  In electrical engineering the demand factor is taken as a time independent quantity where the numerator is taken as the maximum demand in the specified time period instead of the averaged or instantaneous demand. : f_\\\\text{Demand} = \\\\frac{\\\\text{Maximum load in given time period}}{\\\\text{Maximum possible load}} This is the peak in the load profile divided by the full load of the device. Example: If a residence has equipment which could draw 6,000 W when all equipment was drawing a full load, drew a maximum of 3,000 W in a specified time, then the demand factor = 3,000 W / 6,000 W = 0.5 This quantity is relevant when trying to establish the amount of load for which a system should be rated. In the above example, it would be unlikely that the system would be rated to 6,000 W, even though there may be a slight possibility that this amount of power can be drawn. This is closely related to the load factor which is the average load divided by the peak load in a specified time period. : f_\\\\text{Load} = \\\\frac{\\\\text{Average load}}{\\\\text{Maximum load in given time period}}  See also  * Capacity factor * List of energy storage projects * Load factor (electrical) * Diversity factor * Utilization factor  References  * Category:Power engineering ","title":"Demand factor"},{"id":"41018","text":"In telecommunication, the term demand load can have the following meanings: * In general, the total power required by a facility. The demand load is the sum of the operational load (including any tactical load) and nonoperational demand loads. It is determined by applying the proper demand factor to each of the connected loads and a diversity factor to the sum total. * At a communications center, the power required by all automatic switching, synchronous, and terminal equipment (operated simultaneously on-line or in standby), control and keying equipment, plus lighting, ventilation, and air- conditioning equipment required to maintain full continuity of communications. * The power required for ventilating equipment, shop lighting, and other support items that may be operated simultaneously with the technical load. * The sum of the technical demand and nontechnical demand loads of an operating facility. References Category:Telecommunications engineering ","title":"Demand load"},{"id":"41019","text":"In telecommunication, desensitation is the reduction of desired signal gain as a result of receiver reaction to an undesired signal. The gain reduction is generally due to overload of some portion of the receiver (e.g., the automatic gain control circuitry) resulting in suppression of the desired signal because the receiver will no longer respond linearly to incremental changes in input voltage. Category:Telecommunications engineering ","title":"Desensitation"},{"id":"41020","text":"Design objective (DO): In communications systems, a desired performance characteristic for communications circuits and equipment that is based on engineering analyses, but (a) is not considered feasible to mandate in a standard, or (b) has not been tested. DOs are used because applicable systems standards are not in existence. Examples of reasons for designating a performance characteristic as a DO rather than as a standard are (a) it may be bordering on an advancement in the state of the art, (b) the requirement may not have been fully confirmed by measurement or experience with operating circuits, and (c) it may not have been demonstrated that the requirement can be met considering other constraints, such as cost and size. A DO is sometimes established in a standard for developmental consideration. A DO may also specify a performance characteristic used in the preparation of specifications for development or procurement of new equipment or systems. Design is the process of formulation of a plan for satisfaction of human needs References Category:Telecommunications engineering ","title":"Design objective"},{"id":"41021","text":"A detector is a device capable of registering a specific substance or physical phenomenon. Detector may also refer to: * Detector (radio), a device that recovers information from a modulated wave * Detector (film), a 2000 Norwegian film * USS Detector, two United States Navy ships ** , was a coastal minesweeper launched 29 May 1941 ** , was a minesweeper launched 5 December 1952 ","title":"Detector (disambiguation)"},{"id":"41022","text":"In telecommunications, deterministic routing is the advance determination of the routes between given pairs of nodes. Examples: #In a network where routing is controlled by a telephone switch or network switch, switching in which the routes between given pairs of nodes are pre-programmed, i.e., are determined, in advance of transmission. The routes used to complete a given call through a network are identified, in advance of transmission, in routing tables maintained in each switch database. The tables assign the trunks that are to be used to reach each switch code, area code, and International Access Prefix (IAP), usually with one or two alternate routes. #In a non-switched network, the routes used to send a given message through the network are identified in advance in routing tables maintained in a database. Notes and references Category:Telephone exchanges Category:Telecommunications engineering ","title":"Deterministic routing"},{"id":"41024","text":"The Western Electric model 500 rotary dial telephone was a pulse-dialing instrument. Pulse dialing is a signaling technology in telecommunications in which a direct current local loop circuit is interrupted according to a defined coding system for each signal transmitted, usually a digit. This lends the method the often used name loop disconnect dialing. In the most common variant of pulse dialing, decadic dialing, each of the ten Arabic numerals are encoded in a sequence of up to ten pulses. The most common version decodes the digits 1 through 9, as one to nine pulses, respectively, and the digit 0 as ten pulses. Historically, the most common device to produce such pulse trains is the rotary dial of the telephone, lending the technology another name, rotary dialing. The pulse repetition rate was historically determined based on the response time needed for electromechanical switching systems to operate reliably. Most telephone systems used the nominal rate of ten pulses per second, but operator dialing within and between central offices often used pulse rates up to twenty per second. Early automatic exchanges Automatic telephone exchange systems were developed in the late 19th and early 20th century. For identification, telephone subscribers were assigned a telephone number unique to each circuit. Various methods evolved to signal the desired destination telephone number for a telephone call directly dialed by the subscriber. An automatic switch-hook was designed by Hilborne Roosevelt. The first commercial automatic telephone exchange, designed by Almon Brown Strowger, opened in La Porte, Indiana on 3 November 1892, and used two telegraph-type keys on the telephone, which had to be operated the correct number of times to control the vertical and horizontal relay magnets in the exchange. But the use of separate keys with separate conductors to the exchange was not practical. The most common signaling system became a system of using direct-current pulse trains generated in the telephone sets of subscribers by interrupting the single-pair wire loop of the telephone circuit. Rotary dial Strowger also filed the first patent for a rotary dial in 1891. The first dials worked by direct, forward action. The pulses were sent as the user rotated the dial to the finger stop starting at a different position for each digit transmitted. Operating the dial error-free required smooth rotary motion of the finger wheel by the user, but was found as too unreliable. This mechanism was soon refined to include a recoil spring and a centrifugal governor to control the recoil speed. The user selected a digit to be dialed by inserting a finger into the corresponding hole and rotated the dial to the finger stop. When released from this position, the dial pulsing contacts were opened and closed repeatedly, thus interrupting the loop current in a pattern on the return to the home position. The exchange switch decoded the pattern for each digit thus transmitted by stepping relays or by accumulation in digit registers. Pulse rate and coding In the first electromechanical switching systems the current pulses generated by the rotary dial on the local loop directly operated electrical stepping switches at the central office. The mechanical nature of these relays generally limited the speed of operation, the pulsing rate, to ten pulses per second. The specifications of the Bell System in the US required service personnel to adjust dials in customer stations to a precision of 9.5 to 10.5 pulses per second (PPS), but the tolerance of the switching equipment was generally between 8 and 11 PPS.AT&T; Specification No. 4566, February 1926, p.113 The British (GPO, later Post Office Telecommunications) standard for Strowger switch exchanges has been ten impulses per second (allowable range 7 to 12) and a 66% break ratio (allowable range 63% to 72%)J. Atkinson, Telephony Volume 1, p.142 (1948, Pitman, London)Current UK standard BT SIN 351 In most switching systems one pulse is used for the digit 1, two pulses for 2, and so on, with ten pulses for the digit 0; this makes the code unary, excepting the digit 0. Exceptions to this are: Sweden (example dial), with one pulse for 0, two pulses for 1, and so on; and New Zealand with ten pulses for 0, nine pulses for 1, etc. Oslo, the capital city of Norway, used the New Zealand system, but the rest of the country did not. Systems that used this encoding of the ten digits in a sequence of up to ten pulses, are known as decadic dialing systems. Some switching systems used digit registers that doubled the allowable pulse rate up to twenty pulses per second, and the inter-digital pause could be reduced as the switch selection did not have to be completed during the pause. These included access lines to the Panel switch in the 1920s, Crossbar systems, the later version (7A2) of the Rotary system, and the earlier 1970s stored program control exchanges. In some telephones, the pulses may be heard in the receiver as clicking sounds. However, in general, such effects were undesirable and telephone designers suppressed them by mechanical means with off-normal switches on the dial, or greatly attenuated them by electrical means with a varistor connected across the receiver. Switch-hook dialing British (GPO) Type 232 phone of 1932 As pulse dialing is achieved by interruption of the local loop, it was possible to dial a telephone number by rapidly tapping, i.e. depressing, the switch hook the corresponding number of times for each digit at approximately ten taps per second. However, many telephone makers implemented a slow switch hook release to prevent rapid switching. In the United Kingdom, it used to be possible to make calls from coin-box phones (payphones) by tapping the switch hook without depositing coins. Unlawfully obtaining a free telephone call was deemed to be a criminal offense of abstracting electricity from the General Post Office, which operated the telephone system and several cases were prosecuted. In popular culture, tapping was used in the film Red Dragon as a way for prisoner Hannibal Lecter to dial out on a phone with no dialing mechanism. The same technique was also used by Phantom Phreak in Hackers (film) Successors It was recognized as early as the 1940s that dialing could be faster and more accurate with push buttons, but this was too unreliable in customer trials until transistors transformed the industry. In 1963, the Bell System introduced to the public dual-tone multi-frequency (DTMF) technology under the name Touch-Tone, which was a trademark in the U.S. until 1984.The Trademark Electronic Search System on the U.S. Patent and Trademark Office web site shows the trademark with serial number 72109459, registered 1962-09-04 and cancelled 1984-03-13. The Touch-Tone system used push-button telephones. In the decades after 1963, rotary dials were gradually phased out on new telephone models in favor of keypads and the primary dialing method to the central office became touchtone dialing, but most central office systems still support rotary telephones today. Some keypad telephones have a switch or configuration method for the selection of tone or pulse dialing. Mobile telephones and most voice-over-IP systems use out-of-band signaling and do not send any digits until the entire number has been keyed by the user. Many VoIP systems are based on the Session Initiation Protocol (SIP), which uses a form of Uniform Resource Identifiers (URI) for addressing, instead of digits alone. See also * Strowger switch * Federal Standard 1037C References Category:Obsolete technologies Category:Telephony signals ","title":"Pulse dialing"},{"id":"41026","text":"A polarized dielectric material A dielectric (or dielectric material) is an electrical insulator that can be polarized by an applied electric field. When a dielectric material is placed in an electric field, electric charges do not flow through the material as they do in an electrical conductor but only slightly shift from their average equilibrium positions causing dielectric polarization. Because of dielectric polarization, positive charges are displaced in the direction of the field and negative charges shift in the direction opposite to the field (for example, if the field is moving in the positive x-axis, the negative charges will shift in the negative x-axis). This creates an internal electric field that reduces the overall field within the dielectric itself. If a dielectric is composed of weakly bonded molecules, those molecules not only become polarized, but also reorient so that their symmetry axes align to the field. The study of dielectric properties concerns storage and dissipation of electric and magnetic energy in materials.Arthur R. von Hippel, in his seminal work, Dielectric Materials and Applications, stated: \\"Dielectrics... are not a narrow class of so-called insulators, but the broad expanse of nonmetals considered from the standpoint of their interaction with electric, magnetic, or electromagnetic fields. Thus we are concerned with gases as well as with liquids and solids, and with the storage of electric and magnetic energy as well as its dissipation.\\" (Technology Press of MIT and John Wiley, NY, 1954). Dielectrics are important for explaining various phenomena in electronics, optics, solid-state physics, and cell biophysics. Terminology Although the term insulator implies low electrical conduction, dielectric typically means materials with a high polarizability. The latter is expressed by a number called the relative permittivity. The term insulator is generally used to indicate electrical obstruction while the term dielectric is used to indicate the energy storing capacity of the material (by means of polarization). A common example of a dielectric is the electrically insulating material between the metallic plates of a capacitor. The polarization of the dielectric by the applied electric field increases the capacitor's surface charge for the given electric field strength.Dielectric. Encyclop√¶dia Britannica: \\"Dielectric, insulating material or a very poor conductor of electric current. When dielectrics are placed in an electric field, practically no current flows in them because, unlike metals, they have no loosely bound, or free, electrons that may drift through the material.\\" The term dielectric was coined by William Whewell (from dia- + electric) in response to a request from Michael Faraday.James, Frank A.J.L., editor. The Correspondence of Michael Faraday, Volume 3, 1841‚Äì1848, The Institution of Electrical Engineers, London, United Kingdom, 1996. A perfect dielectric is a material with zero electrical conductivity (cf. perfect conductor infinite electrical conductivity), thus exhibiting only a displacement current; therefore it stores and returns electrical energy as if it were an ideal capacitor. Electric susceptibility The electric susceptibility œáe of a dielectric material is a measure of how easily it polarizes in response to an electric field. This, in turn, determines the electric permittivity of the material and thus influences many other phenomena in that medium, from the capacitance of capacitors to the speed of light. It is defined as the constant of proportionality (which may be a tensor) relating an electric field E to the induced dielectric polarization density P such that :\\\\mathbf{P} = \\\\varepsilon_0 \\\\chi_e \\\\mathbf{E}, where Œµ0 is the electric permittivity of free space. The susceptibility of a medium is related to its relative permittivity Œµr by :\\\\chi_e\\\\ = \\\\varepsilon_r - 1. So in the case of a vacuum, :\\\\chi_e\\\\ = 0. The electric displacement D is related to the polarization density P by :\\\\mathbf{D} \\\\ = \\\\ \\\\varepsilon_0 \\\\mathbf{E} + \\\\mathbf{P} \\\\ = \\\\ \\\\varepsilon_0 \\\\left(1 + \\\\chi_e\\\\right) \\\\mathbf{E} \\\\ = \\\\ \\\\varepsilon_0 \\\\varepsilon_r \\\\mathbf{E}. =Dispersion and causality= In general, a material cannot polarize instantaneously in response to an applied field. The more general formulation as a function of time is :\\\\mathbf{P}(t) = \\\\varepsilon_0 \\\\int_{-\\\\infty}^t \\\\chi_e\\\\left(t - t'\\\\right) \\\\mathbf{E}\\\\left(t'\\\\right)\\\\, dt'. That is, the polarization is a convolution of the electric field at previous times with time-dependent susceptibility given by œáe(Œît). The upper limit of this integral can be extended to infinity as well if one defines for . An instantaneous response corresponds to Dirac delta function susceptibility . It is more convenient in a linear system to take the Fourier transform and write this relationship as a function of frequency. Due to the convolution theorem, the integral becomes a simple product, :\\\\mathbf{P}(\\\\omega) = \\\\varepsilon_0 \\\\chi_e(\\\\omega) \\\\mathbf{E}(\\\\omega). The susceptibility (or equivalently the permittivity) is frequency dependent. The change of susceptibility with respect to frequency characterizes the dispersion properties of the material. Moreover, the fact that the polarization can only depend on the electric field at previous times (i.e., for ), a consequence of causality, imposes Kramers‚ÄìKronig constraints on the real and imaginary parts of the susceptibility œáe(œâ). Dielectric polarization =Basic atomic model= Electric field interaction with an atom under the classical dielectric model. In the classical approach to the dielectric model, a material is made up of atoms. Each atom consists of a cloud of negative charge (electrons) bound to and surrounding a positive point charge at its centre. In the presence of an electric field the charge cloud is distorted, as shown in the top right of the figure. This can be reduced to a simple dipole using the superposition principle. A dipole is characterized by its dipole moment, a vector quantity shown in the figure as the blue arrow labeled M. It is the relationship between the electric field and the dipole moment that gives rise to the behavior of the dielectric. (Note that the dipole moment points in the same direction as the electric field in the figure. This isn't always the case, and is a major simplification, but is true for many materials.) When the electric field is removed the atom returns to its original state. The time required to do so is the so-called relaxation time; an exponential decay. This is the essence of the model in physics. The behavior of the dielectric now depends on the situation. The more complicated the situation, the richer the model must be to accurately describe the behavior. Important questions are: *Is the electric field constant or does it vary with time? At what rate? *Does the response depend on the direction of the applied field (isotropy of the material)? *Is the response the same everywhere (homogeneity of the material)? *Do any boundaries or interfaces have to be taken into account? *Is the response linear with respect to the field, or are there nonlinearities? The relationship between the electric field E and the dipole moment M gives rise to the behavior of the dielectric, which, for a given material, can be characterized by the function F defined by the equation: :\\\\mathbf{M} = \\\\mathbf{F}(\\\\mathbf{E}). When both the type of electric field and the type of material have been defined, one then chooses the simplest function F that correctly predicts the phenomena of interest. Examples of phenomena that can be so modeled include: *Refractive index *Group velocity dispersion *Birefringence *Self-focusing *Harmonic generation =Dipolar polarization= Dipolar polarization is a polarization that is either inherent to polar molecules (orientation polarization), or can be induced in any molecule in which the asymmetric distortion of the nuclei is possible (distortion polarization). Orientation polarization results from a permanent dipole, e.g., that arising from the 104.45¬∞ angle between the asymmetric bonds between oxygen and hydrogen atoms in the water molecule, which retains polarization in the absence of an external electric field. The assembly of these dipoles forms a macroscopic polarization. When an external electric field is applied, the distance between charges within each permanent dipole, which is related to chemical bonding, remains constant in orientation polarization; however, the direction of polarization itself rotates. This rotation occurs on a timescale that depends on the torque and surrounding local viscosity of the molecules. Because the rotation is not instantaneous, dipolar polarizations lose the response to electric fields at the highest frequencies. A molecule rotates about 1 radian per picosecond in a fluid, thus this loss occurs at about 1011 Hz (in the microwave region). The delay of the response to the change of the electric field causes friction and heat. When an external electric field is applied at infrared frequencies or less, the molecules are bent and stretched by the field and the molecular dipole moment changes. The molecular vibration frequency is roughly the inverse of the time it takes for the molecules to bend, and this distortion polarization disappears above the infrared. =Ionic polarization= Ionic polarization is polarization caused by relative displacements between positive and negative ions in ionic crystals (for example, NaCl). If a crystal or molecule consists of atoms of more than one kind, the distribution of charges around an atom in the crystal or molecule leans to positive or negative. As a result, when lattice vibrations or molecular vibrations induce relative displacements of the atoms, the centers of positive and negative charges are also displaced. The locations of these centers are affected by the symmetry of the displacements. When the centers don't correspond, polarization arises in molecules or crystals. This polarization is called ionic polarization. Ionic polarization causes the ferroelectric effect as well as dipolar polarization. The ferroelectric transition, which is caused by the lining up of the orientations of permanent dipoles along a particular direction, is called an order-disorder phase transition. The transition caused by ionic polarizations in crystals is called a displacive phase transition. In cells Ionic polarization enables the production of energy-rich compounds in cells (the proton pump in mitochondria) and, at the plasma membrane, the establishment of the resting potential, energetically unfavourable transport of ions, and cell-to-cell communication (the Na+/K+-ATPase). All cells in animal body tissues are electrically polarized ‚Äì in other words, they maintain a voltage difference across the cell's plasma membrane, known as the membrane potential. This electrical polarization results from a complex interplay between ion transporters and ion channels. In neurons, the types of ion channels in the membrane usually vary across different parts of the cell, giving the dendrites, axon, and cell body different electrical properties. As a result, some parts of the membrane of a neuron may be excitable (capable of generating action potentials), whereas others are not. Dielectric dispersion In physics, dielectric dispersion is the dependence of the permittivity of a dielectric material on the frequency of an applied electric field. Because there is a lag between changes in polarization and changes in the electric field, the permittivity of the dielectric is a complicated function of frequency of the electric field. Dielectric dispersion is very important for the applications of dielectric materials and for the analysis of polarization systems. This is one instance of a general phenomenon known as material dispersion: a frequency-dependent response of a medium for wave propagation. When the frequency becomes higher: # dipolar polarization can no longer follow the oscillations of the electric field in the microwave region around 1010 Hz; # ionic polarization and molecular distortion polarization can no longer track the electric field past the infrared or far-infrared region around 1013 Hz, ; # electronic polarization loses its response in the ultraviolet region around 1015 Hz. In the frequency region above ultraviolet, permittivity approaches the constant Œµ0 in every substance, where Œµ0 is the permittivity of the free space. Because permittivity indicates the strength of the relation between an electric field and polarization, if a polarization process loses its response, permittivity decreases. Dielectric relaxation Dielectric relaxation is the momentary delay (or lag) in the dielectric constant of a material. This is usually caused by the delay in molecular polarization with respect to a changing electric field in a dielectric medium (e.g., inside capacitors or between two large conducting surfaces). Dielectric relaxation in changing electric fields could be considered analogous to hysteresis in changing magnetic fields (e.g., in inductor or transformer cores). Relaxation in general is a delay or lag in the response of a linear system, and therefore dielectric relaxation is measured relative to the expected linear steady state (equilibrium) dielectric values. The time lag between electrical field and polarization implies an irreversible degradation of Gibbs free energy. In physics, dielectric relaxation refers to the relaxation response of a dielectric medium to an external, oscillating electric field. This relaxation is often described in terms of permittivity as a function of frequency, which can, for ideal systems, be described by the Debye equation. On the other hand, the distortion related to ionic and electronic polarization shows behavior of the resonance or oscillator type. The character of the distortion process depends on the structure, composition, and surroundings of the sample. =Debye relaxation= Debye relaxation is the dielectric relaxation response of an ideal, noninteracting population of dipoles to an alternating external electric field. It is usually expressed in the complex permittivity Œµ of a medium as a function of the field's angular frequency œâ: :\\\\hat{\\\\varepsilon}(\\\\omega) = \\\\varepsilon_{\\\\infty} + \\\\frac{\\\\Delta\\\\varepsilon}{1 + i\\\\omega\\\\tau}, where Œµ‚àû is the permittivity at the high frequency limit, where Œµs is the static, low frequency permittivity, and œÑ is the characteristic relaxation time of the medium. Separating into the real part \\\\varepsilon' and the imaginary part \\\\varepsilon of the complex dielectric permittivity yields: :\\\\begin{align} \\\\varepsilon' &= \\\\varepsilon_\\\\infty + \\\\frac{\\\\varepsilon_s - \\\\varepsilon_\\\\infty}{1 + \\\\omega^2\\\\tau^2} \\\\[3pt] \\\\varepsilon &= \\\\frac{(\\\\varepsilon_s - \\\\varepsilon_\\\\infty)\\\\omega\\\\tau}{1+\\\\omega^2\\\\tau^2} \\\\end{align} The dielectric loss is also represented by the loss tangent: :\\\\tan(\\\\delta) = \\\\frac{\\\\varepsilon}{\\\\varepsilon'} = \\\\frac{\\\\left(\\\\varepsilon_s - \\\\varepsilon_\\\\infty\\\\right)\\\\omega\\\\tau}{\\\\varepsilon_s + \\\\varepsilon_\\\\infty \\\\omega^2 \\\\tau^2} This relaxation model was introduced by and named after the physicist Peter Debye (1913).Debye, P. (1913), Ver. Deut. Phys. Gesell. 15, 777; reprinted 1954 in collected papers of Peter J.W. Debye. Interscience, New York It is characteristic for dynamic polarization with only one relaxation time. =Variants of the Debye equation= ;Cole‚ÄìCole equation: This equation is used when the dielectric loss peak shows symmetric broadening. ;Cole‚ÄìDavidson equation: This equation is used when the dielectric loss peak shows asymmetric broadening. ;Havriliak‚ÄìNegami relaxation: This equation considers both symmetric and asymmetric broadening. ;Kohlrausch‚ÄìWilliams‚ÄìWatts function: Fourier transform of stretched exponential function. ;Curie‚Äìvon Schweidler law: This shows the response of dielectrics to an applied DC field to behave according to a power law, which can be expressed as an integral over weighted exponential functions.. Paraelectricity Paraelectricity is the ability of many materials (specifically ceramics) to become polarized under an applied electric field. Unlike ferroelectricity, this can happen even if there is no permanent electric dipole that exists in the material, and removal of the fields results in the polarization in the material returning to zero.Chiang, Y. et al. (1997) Physical Ceramics, John Wiley & Sons, New York The mechanisms that cause paraelectric behaviour are the distortion of individual ions (displacement of the electron cloud from the nucleus) and polarization of molecules or combinations of ions or defects. Paraelectricity can occur in crystal phases where electric dipoles are unaligned and thus have the potential to align in an external electric field and weaken it. An example of a paraelectric material of high dielectric constant is strontium titanate. The LiNbO3 crystal is ferroelectric below 1430 K, and above this temperature it transforms into a disordered paraelectric phase. Similarly, other perovskites also exhibit paraelectricity at high temperatures. Paraelectricity has been explored as a possible refrigeration mechanism; polarizing a paraelectric by applying an electric field under adiabatic process conditions raises the temperature, while removing the field lowers the temperature. A heat pump that operates by polarizing the paraelectric, allowing it to return to ambient temperature (by dissipating the extra heat), bringing it into contact with the object to be cooled, and finally depolarizing it, would result in refrigeration. Tunability Tunable dielectrics are insulators whose ability to store electrical charge changes when a voltage is applied. Generally, strontium titanate () is used for devices operating at low temperatures, while barium strontium titanate () substitutes for room temperature devices. Other potential materials include microwave dielectrics and carbon nanotube (CNT) composites. In 2013 multi-sheet layers of strontium titanate interleaved with single layers of strontium oxide produced a dielectric capable of operating at up to 125 GHz. The material was created via molecular beam epitaxy. The two have mismatched crystal spacing that produces strain within the strontium titanate layer that makes it less stable and tunable. Systems such as have a paraelectric‚Äìferroelectric transition just below ambient temperature, providing high tunability. Such films suffer significant losses arising from defects. Applications =Capacitors= Charge separation in a parallel-plate capacitor causes an internal electric field. A dielectric (orange) reduces the field and increases the capacitance. Commercially manufactured capacitors typically use a solid dielectric material with high permittivity as the intervening medium between the stored positive and negative charges. This material is often referred to in technical contexts as the capacitor dielectric.M√ºssig, Hans-Joachim. Semiconductor capacitor with praseodymium oxide as dielectric, published 2003-11-06, issued 2004-10-18, assigned to IHP GmbH- Innovations for High Performance Microelectronics/Institute Fur Innovative Mikroelektronik The most obvious advantage to using such a dielectric material is that it prevents the conducting plates, on which the charges are stored, from coming into direct electrical contact. More significantly, however, a high permittivity allows a greater stored charge at a given voltage. This can be seen by treating the case of a linear dielectric with permittivity Œµ and thickness d between two conducting plates with uniform charge density œÉŒµ. In this case the charge density is given by :\\\\sigma_{\\\\varepsilon}=\\\\varepsilon\\\\frac{V}{d} and the capacitance per unit area by :c=\\\\frac{\\\\sigma_{\\\\varepsilon}}{V}=\\\\frac{\\\\varepsilon}{d} From this, it can easily be seen that a larger Œµ leads to greater charge stored and thus greater capacitance. Dielectric materials used for capacitors are also chosen such that they are resistant to ionization. This allows the capacitor to operate at higher voltages before the insulating dielectric ionizes and begins to allow undesirable current. =Dielectric resonator= A dielectric resonator oscillator (DRO) is an electronic component that exhibits resonance of the polarization response for a narrow range of frequencies, generally in the microwave band. It consists of a \\"puck\\" of ceramic that has a large dielectric constant and a low dissipation factor. Such resonators are often used to provide a frequency reference in an oscillator circuit. An unshielded dielectric resonator can be used as a dielectric resonator antenna (DRA). = BST thin films = From 2002 to 2004, the Army Research Laboratory (ARL) conducted research on thin film technology. Barium strontium titanate (BST), a ferroelectric thin film, was studied for the fabrication of radio frequency and microwave components, such as voltage-controlled oscillators, tunable filters, and phase shifters. The research was part of an effort to provide the Army with highly-tunable, microwave-compatible materials for broadband electric-field tunable devices, which operate consistently in extreme temperatures. This work improved tunability of bulk barium strontium titanate, which is a thin film enabler for electronics components. In a 2004 research paper, ARL researchers explored how small concentrations of acceptor dopants can dramatically modify the properties of ferroelectric materials such as BST. Researchers \\"doped\\" BST thin films with magnesium, analyzing the \\"structure, microstructure, surface morphology and film/substrate compositional quality\\" of the result. The Mg doped BST films showed \\"improved dielectric properties, low leakage current, and good tunability\\", meriting potential for use in microwave tunable devices. Some practical dielectrics Dielectric materials can be solids, liquids, or gases. (A high vacuum can also be a useful, nearly lossless dielectric even though its relative dielectric constant is only unity.) Solid dielectrics are perhaps the most commonly used dielectrics in electrical engineering, and many solids are very good insulators. Some examples include porcelain, glass, and most plastics. Air, nitrogen and sulfur hexafluoride are the three most commonly used gaseous dielectrics. *Industrial coatings such as Parylene provide a dielectric barrier between the substrate and its environment. *Mineral oil is used extensively inside electrical transformers as a fluid dielectric and to assist in cooling. Dielectric fluids with higher dielectric constants, such as electrical grade castor oil, are often used in high voltage capacitors to help prevent corona discharge and increase capacitance. *Because dielectrics resist the flow of electricity, the surface of a dielectric may retain stranded excess electrical charges. This may occur accidentally when the dielectric is rubbed (the triboelectric effect). This can be useful, as in a Van de Graaff generator or electrophorus, or it can be potentially destructive as in the case of electrostatic discharge. *Specially processed dielectrics, called electrets (which should not be confused with ferroelectrics), may retain excess internal charge or \\"frozen in\\" polarization. Electrets have a semipermanent electric field, and are the electrostatic equivalent to magnets. Electrets have numerous practical applications in the home and industry. *Some dielectrics can generate a potential difference when subjected to mechanical stress, or (equivalently) change physical shape if an external voltage is applied across the material. This property is called piezoelectricity. Piezoelectric materials are another class of very useful dielectrics. *Some ionic crystals and polymer dielectrics exhibit a spontaneous dipole moment, which can be reversed by an externally applied electric field. This behavior is called the ferroelectric effect. These materials are analogous to the way ferromagnetic materials behave within an externally applied magnetic field. Ferroelectric materials often have very high dielectric constants, making them quite useful for capacitors. See also *Classification of materials based on permittivity *Paramagnetism *Clausius-Mossotti relation *Dielectric absorption *Dielectric losses *Dielectric strength *Dielectric spectroscopy *EIA Class 1 dielectric *EIA Class 2 dielectric *High-k dielectric *Low-k dielectric *leakage *Linear response function *Metamaterial *RC delay *Rotational Brownian motion *Paschen's law ‚Äì variation of Dielectric strength of gas related to pressure *Separator (electricity) References Further reading * 808 or 832 pages. * External links *Electromagnetism ‚Äì A chapter from an online textbook *Dielectric Sphere in an Electric Field *DoITPoMS Teaching and Learning Package \\"Dielectric Materials\\" * Category:Electric and magnetic fields in matter ","title":"Dielectric"},{"id":"41027","title":"Dielectric strength"},{"id":"41030","text":"Differential Manchester Encoding (DM) is a line code in which data and clock signals are combined to form a single 2-level self-synchronizing data stream. In various specific applications, this line code is also called by various other names, including Biphase Mark Code (CC), Frequency Modulation (FM), F2F (frequency/double frequency), Aiken Biphase, and Conditioned diphase.US DoD: Design handbook for fiber optic communications systems, Military handbook. Dept. of Defense, 1985, p. 65. DM is a differential encoding, using the presence or absence of transitions to indicate logical value. It is not necessary to know the polarity of the sent signal since the information is not represented by the absolute voltage levels but in their changes: in other words it does not matter which of the two voltage levels is received, but only whether it is the same or different from the previous one; this makes synchronization easier. Differential Manchester encoding has the following advantages over some other line codes: * A transition is guaranteed at least once every bit, for robust clock recovery. * In a noisy environment, detecting transitions is less error-prone than comparing signal levels against a threshold. * Unlike with Manchester encoding, only the presence of a transition is important, not the polarity. Differential coding schemes will work exactly the same if the signal is inverted (e.g. wires swapped). Other line codes with this property include NRZI, bipolar encoding, coded mark inversion, and MLT-3 encoding. * If the high and low signal levels have the same magnitude with opposite polarity, the average voltage around each unconditional transition is zero. Zero DC bias reduces the necessary transmitting power, minimizes the amount of electromagnetic noise produced by the transmission line, and eases the use of isolating transformers. An example of Differential Manchester encoding: Gray vertical lines, full and dotted, represent the two clock ticks per bit period. In the shown variant of the encoding, 0 is represented by a transition and 1 is represented by no transition. The two line signals shown differ in their polarity; which one would occur on the line depends on the preceding line state. These positive features are achieved at the expense of doubling the clock frequency--there are two clock ticks per bit period (marked with full and dotted lines in the figure). At every second clock tick, marked with a dotted line, there is a potential level transition conditional on the data. At the other ticks, the line state changes unconditionally to ease clock recovery. One version of the code makes a transition for 0 and no transition for 1; the other makes a transition for 1 and no transition for 0. Differential Manchester is specified in the IEEE 802.5 standard for token ring LANs, and is used for many other applications, including magnetic and optical storage. As Biphase Mark Code (BMC), it is used in AES3, S/PDIF, SMPTE time code, and USB PD. Many magnetic stripe cards also use BMC encoding, often called F2F (frequency/double frequency) or Aiken Biphase, according to the ISO/IEC 7811 standard. Differential Manchester is also the original \\"frequency modulation\\" (FM) used on \\"single-density\\" floppy disks, followed by \\"double-density\\" modified frequency modulation (MFM), which gets its name from its relation to FM, or Differential Manchester, encoding.  See also  * Manchester code * McASP * Run-length limited: FM References Further reading * Watkinson, John (1994) The Art of Digital Audio, 2nd edition. Oxford: Focal Press. * * Introduction to magnetic stripe technology * (https://www.sqa.org.uk/e-learning/NetTechDC01ECD/page_09.htm) Introduction to rudimentary biphase encoding Category:Line codes ","title":"Differential Manchester encoding"},{"id":"41031","text":"A very large reflecting diffraction grating An incandescent light bulb viewed through a transmissive diffraction grating. In optics, a diffraction grating is an optical component with a periodic structure that splits and diffracts light into several beams travelling in different directions. The emerging coloration is a form of structural coloration. The directions of these beams depend on the spacing of the grating and the wavelength of the light so that the grating acts as the dispersive element. Because of this, gratings are commonly used in monochromators and spectrometers. For practical applications, gratings generally have ridges or rulings on their surface rather than dark lines. Such gratings can be either transmissive or reflective. Gratings that modulate the phase rather than the amplitude of the incident light are also produced, frequently using holography. The principles of diffraction gratings were discovered by James Gregory, about a year after Isaac Newton's prism experiments, initially with items such as bird feathers.Letter from James Gregory to John Collins, dated 13 May 1673. Reprinted in: especially p. 254 The first man-made diffraction grating was made around 1785 by Philadelphia inventor David Rittenhouse, who strung hairs between two finely threaded screws.Thomas D. Cope (1932) \\"The Rittenhouse diffraction grating\\". Reprinted in: (A reproduction of Rittenhouse's letter re his diffraction grating appears on pp. 369‚Äì374.) This was similar to notable German physicist Joseph von Fraunhofer's wire diffraction grating in 1821. Gratings with the lowest line- distance (d) were created, in the 1860s, by Friedrich Adolph Nobert (1806‚Äì1881) in Greifswald; then the two Americans Lewis Morris Rutherfurd (1816‚Äì1892) and William B. Rogers (1804‚Äì1882) took over the lead; and, by the end of the 19th century, the concave gratings of Henry Augustus Rowland (1848‚Äì1901) were the best available. Diffraction can create \\"rainbow\\" colors when illuminated by a wide-spectrum (e.g., continuous) light source. The sparkling effects from the closely spaced narrow tracks on optical storage disks such as CDs or DVDs are an example. Similar rainbow effects seen in thin layers of oil (or gasoline, etc.) on water are not caused by a grating but rather by iridescence in reflections from the closely spaced transmissive layers. A grating has parallel lines, while a CD has a spiral of finely spaced data tracks. Diffraction colors also appear when one looks at a bright point source through a translucent fine-pitch umbrella-fabric covering. Decorative patterned plastic films based on reflective grating patches are very inexpensive and commonplace. Theory of operation A diffraction grating reflecting only the green portion of the spectrum from a room's fluorescent lightingThe relationship between the grating spacing and the angles of the incident and diffracted beams of light is known as the grating equation. According to the Huygens‚ÄìFresnel principle, each point on the wavefront of a propagating wave can be considered to act as a point source, and the wavefront at any subsequent point can be found by adding together the contributions from each of these individual point sources. Gratings may be of the 'reflective' or 'transmissive' type, analogous to a mirror or lens, respectively. A grating has a 'zero-order mode' (where m = 0), in which there is no diffraction and a ray of light behaves according to the laws of reflection and refraction the same as with a mirror or lens, respectively. Diagram showing path difference between rays scattered from adjacent rulings of reflective diffraction grating An idealised grating is made up of a set of slits of spacing d, that must be wider than the wavelength of interest to cause diffraction. Assuming a plane wave of monochromatic light of wavelength Œª with normal incidence (perpendicular to the grating), each slit in the grating acts as a quasi point-source from which light propagates in all directions (although this is typically limited to a hemisphere). After light interacts with the grating, the diffracted light is composed of the sum of interfering wave components emanating from each slit in the grating. At any given point in space through which diffracted light may pass, the path length to each slit in the grating varies. Since path length varies, generally, so do the phases of the waves at that point from each of the slits. Thus, they add or subtract from each other to create peaks and valleys through additive and destructive interference. When the path difference between the light from adjacent slits is equal to half the wavelength, , the waves are out of phase, and thus cancel each other to create points of minimum intensity. Similarly, when the path difference is Œª, the phases add together and maxima occur. For a beam incident normally on a grating, the maxima occur at angles Œ∏m, which satisfy the relationship =  m , where Œ∏m is the angle between the diffracted ray and the grating's normal vector, and d is the distance from the center of one slit to the center of the adjacent slit, and m is an integer representing the propagation-mode of interest. Comparison of the spectra obtained from a diffraction grating by diffraction (1), and a prism by refraction (2). Longer wavelengths (red) are diffracted more, but refracted less than shorter wavelengths (violet). Intensity as heatmap for monochromatic light behind a grating Thus, when light is normally incident on the grating, the diffracted light has maxima at angles Œ∏m given by: :d \\\\sin\\\\theta_m = m\\\\lambda. It can be shown that if a plane wave is incident at any arbitrary angle Œ∏i, the grating equation becomes: :d(\\\\sin\\\\theta_i - \\\\sin\\\\theta_m) = m\\\\lambda. When solved for the diffracted angle maxima, the equation is: :\\\\theta_m = \\\\arcsin\\\\\\\\!\\\\left( \\\\sin\\\\theta_i -\\\\frac{m\\\\lambda}{d}\\\\right )\\\\\\\\!. Please note that these equations assume that both sides of the grating are in contact with the same medium (e.g. air). The light that corresponds to direct transmission (or specular reflection in the case of a reflection grating) is called the zero order, and is denoted m = 0. The other maxima occur at angles represented by non-zero integers m. Note that m can be positive or negative, resulting in diffracted orders on both sides of the zero order beam. This derivation of the grating equation is based on an idealised grating. However, the relationship between the angles of the diffracted beams, the grating spacing and the wavelength of the light apply to any regular structure of the same spacing, because the phase relationship between light scattered from adjacent elements of the grating remains the same. The detailed distribution of the diffracted light depends on the detailed structure of the grating elements as well as on the number of elements in the grating, but it always gives maxima in the directions given by the grating equation. Gratings can be made in which various properties of the incident light are modulated in a periodic pattern; these include *transparency (transmission amplitude diffraction gratings); *reflectance (reflection amplitude diffraction gratings); *refractive index or optical path length (phase diffraction gratings); *direction of optical axis (optical axis diffraction gratings). The grating equation applies in all these cases. =Quantum electrodynamics= A helical fluorescent lamp photographed in a reflection diffraction-grating, showing the various spectral lines produced by the lamp. Quantum electrodynamics (QED) offers another derivation of the properties of a diffraction grating in terms of photons as particles (at some level). QED can be described intuitively with the path integral formulation of quantum mechanics. As such it can model photons as potentially following all paths from a source to a final point, each path with a certain probability amplitude. These probability amplitudes can be represented as a complex number or equivalent vector‚Äîor, as Richard Feynman simply calls them in his book on QED, \\"arrows\\". For the probability that a certain event will happen, one sums the probability amplitudes for all of the possible ways in which the event can occur, and then takes the square of the length of the result. The probability amplitude for a photon from a monochromatic source to arrive at a certain final point at a given time, in this case, can be modeled as an arrow that spins rapidly until it is evaluated when the photon reaches its final point. For example, for the probability that a photon will reflect off of a mirror and be observed at a given point a given amount of time later, one sets the photon's probability amplitude spinning as it leaves the source, follows it to the mirror, and then to its final point, even for paths that do not involve bouncing off of the mirror at equal angles. One can then evaluate the probability amplitude at the photon's final point; next, one can integrate over all of these arrows (see vector sum), and square the length of the result to obtain the probability that this photon will reflect off of the mirror in the pertinent fashion. The times these paths take are what determine the angle of the probability amplitude arrow, as they can be said to \\"spin\\" at a constant rate (which is related to the frequency of the photon). The times of the paths near the classical reflection site of the mirror are nearly the same, so the probability amplitudes point in nearly the same direction‚Äîthus, they have a sizable sum. Examining the paths towards the edges of the mirror reveals that the times of nearby paths are quite different from each other, and thus we wind up summing vectors that cancel out quickly. So, there is a higher probability that light will follow a near-classical reflection path than a path further out. However, a diffraction grating can be made out of this mirror, by scraping away areas near the edge of the mirror that usually cancel nearby amplitudes out‚Äîbut now, since the photons don't reflect from the scraped-off portions, the probability amplitudes that would all point, for instance, at forty-five degrees, can have a sizable sum. Thus, this lets light of the right frequency sum to a larger probability amplitude, and as such possess a larger probability of reaching the appropriate final point. This particular description involves many simplifications: a point source, a \\"surface\\" that light can reflect off of (thus neglecting the interactions with electrons) and so forth. The biggest simplification is perhaps in the fact that the \\"spinning\\" of the probability amplitude arrows is actually more accurately explained as a \\"spinning\\" of the source, as the probability amplitudes of photons do not \\"spin\\" while they are in transit. We obtain the same variation in probability amplitudes by letting the time at which the photon left the source be indeterminate‚Äîand the time of the path now tells us when the photon would have left the source, and thus what the angle of its \\"arrow\\" would be. However, this model and approximation is a reasonable one to illustrate a diffraction grating conceptually. Light of a different frequency may also reflect off of the same diffraction grating, but with a different final point. Gratings as dispersive elements The wavelength dependence in the grating equation shows that the grating separates an incident polychromatic beam into its constituent wavelength components, i.e., it is dispersive. Each wavelength of input beam spectrum is sent into a different direction, producing a rainbow of colors under white light illumination. This is visually similar to the operation of a prism, although the mechanism is very different. bulb of a flashlight seen through a transmissive grating, showing two diffracted orders. The order m = 0 corresponds to a direct transmission of light through the grating. In the first positive order (m = +1), colors with increasing wavelengths (from blue to red) are diffracted at increasing angles. The diffracted beams corresponding to consecutive orders may overlap, depending on the spectral content of the incident beam and the grating density. The higher the spectral order, the greater the overlap into the next order. An argon laser beam consisting of multiple colors (wavelengths) strikes a silicon diffraction mirror grating and is separated into several beams, one for each wavelength. The wavelengths are (left to right) 458 nm, 476 nm, 488 nm, 497 nm, 502 nm, and 515 nm. The grating equation shows that the angles of the diffracted orders only depend on the grooves' period, and not on their shape. By controlling the cross-sectional profile of the grooves, it is possible to concentrate most of the diffracted energy in a particular order for a given wavelength. A triangular profile is commonly used. This technique is called blazing. The incident angle and wavelength for which the diffraction is most efficient are often called blazing angle and blazing wavelength. The efficiency of a grating may also depend on the polarization of the incident light. Gratings are usually designated by their groove density, the number of grooves per unit length, usually expressed in grooves per millimeter (g/mm), also equal to the inverse of the groove period. The groove period must be on the order of the wavelength of interest; the spectral range covered by a grating is dependent on groove spacing and is the same for ruled and holographic gratings with the same grating constant. The maximum wavelength that a grating can diffract is equal to twice the grating period, in which case the incident and diffracted light are at ninety degrees to the grating normal. To obtain frequency dispersion over a wider frequency one must use a prism. In the optical regime, in which the use of gratings is most common, this corresponds to wavelengths between 100 nm and 10 ¬µm. In that case, the groove density can vary from a few tens of grooves per millimeter, as in echelle gratings, to a few thousands of grooves per millimeter. When groove spacing is less than half the wavelength of light, the only present order is the m = 0 order. Gratings with such small periodicity are called subwavelength gratings and exhibit special optical properties. Made on an isotropic material the subwavelength gratings give rise to form birefringence, in which the material behaves as if it were birefringent. Fabrication Originally, high-resolution gratings were ruled by high-quality ruling engines whose construction was a large undertaking. Henry Joseph Grayson designed a machine to make diffraction gratings, succeeding with one of 120,000 lines to the inch (approx. 4,724 lines per mm) in 1899. Later, photolithographic techniques created gratings from a holographic interference pattern. Holographic gratings have sinusoidal grooves and may not be as efficient as ruled gratings, but are often preferred in monochromators because they produce less stray light. A copying technique can make high quality replicas from master gratings of either type, thereby lowering fabrication costs. Another method for manufacturing diffraction gratings uses a photosensitive gel sandwiched between two substrates. A holographic interference pattern exposes the gel, which is later developed. These gratings, called volume phase holography diffraction gratings (or VPH diffraction gratings) have no physical grooves, but instead a periodic modulation of the refractive index within the gel. This removes much of the surface scattering effects typically seen in other types of gratings. These gratings also tend to have higher efficiencies, and allow for the inclusion of complicated patterns into a single grating. In older versions of such gratings, environmental susceptibility was a trade-off, as the gel had to be contained at low temperature and humidity. Typically, the photosensitive substances are sealed between two substrates that make them resistant to humidity, and thermal and mechanical stresses. VPH diffraction gratings are not destroyed by accidental touches and are more scratch resistant than typical relief gratings. Semiconductor technology today is also utilized to etch holographically patterned gratings into robust materials such as fused silica. In this way, low stray-light holography is combined with the high efficiency of deep, etched transmission gratings, and can be incorporated into high volume, low cost semiconductor manufacturing technology. A new technology for grating insertion into integrated photonic lightwave circuits is digital planar holography (DPH). DPH gratings are generated in computer and fabricated on one or several interfaces of an optical waveguide planar with standard micro-lithography or nano-imprinting methods, compatible with mass-production. Light propagates inside the DPH gratings, confined by the refractive index gradient, which provides longer interaction path and greater flexibility in light steering. Examples The grooves of a compact disc can act as a grating and produce iridescent reflections. Diffraction gratings are often used in monochromators, spectrometers, lasers, wavelength division multiplexing devices, optical pulse compressing devices, and many other optical instruments. Ordinary pressed CD and DVD media are every-day examples of diffraction gratings and can be used to demonstrate the effect by reflecting sunlight off them onto a white wall. This is a side effect of their manufacture, as one surface of a CD has many small pits in the plastic, arranged in a spiral; that surface has a thin layer of metal applied to make the pits more visible. The structure of a DVD is optically similar, although it may have more than one pitted surface, and all pitted surfaces are inside the disc.Ambient Diagnostics by Yang Cai -- CRC Press 2014 Page 267http://www.nnin.org/sites/default/files/files/Karen_Rama_USING_CDs_AND_DVDs_AS_DIFFRACTION_GRATINGS_0.pdf Due to the sensitivity to the refractive index of the media, diffraction grating can be used as sensor of fluid properties. In a standard pressed vinyl record when viewed from a low angle perpendicular to the grooves, a similar but less defined effect to that in a CD/DVD is seen. This is due to viewing angle (less than the critical angle of reflection of the black vinyl) and the path of the light being reflected due to this being changed by the grooves, leaving a rainbow relief pattern behind. Diffraction gratings are also used to distribute evenly the frontlight of e-readers such as the Nook Simple Touch with GlowLight. =Gratings from electronic components= Diffraction of a spotlight over a mobile phone Some everyday electronic components contain fine and regular patterns, and as a result readily serve as diffraction gratings. For example, CCD sensors from discarded mobile phones and cameras can be removed from the device. With a laser pointer, diffraction can reveal the spatial structure of the CCD sensors. This can be done for LCD or LED displays of smart phones as well. Because such displays are usually protected just by transparent casing, experiments can be done without damaging the phones. If accurate measurements are not intended, a spotlight can reveal the diffraction patterns. =Natural gratings= A biofilm on the surface of a fishtank produces diffraction grating effects when the bacteria are all evenly sized and spaced. Such phenomena are an example of Quetelet rings. Striated muscle is the most commonly found natural diffraction grating and, this has helped physiologists in determining the structure of such muscle. Aside from this, the chemical structure of crystals can be thought of as diffraction gratings for types of electromagnetic radiation other than visible light, this is the basis for techniques such as X-ray crystallography. Most commonly confused with diffraction gratings are the iridescent colors of peacock feathers, mother-of-pearl, and butterfly wings. Iridescence in birds, fish and insects is often caused by thin-film interference rather than a diffraction grating. Diffraction produces the entire spectrum of colors as the viewing angle changes, whereas thin-film interference usually produces a much narrower range. The surfaces of flowers can also create a diffraction, but the cell structures in plants are usually too irregular to produce the fine slit geometry necessary for a diffraction grating. The iridescence signal of flowers is thus only appreciable very locally and hence not visible to man and flower visiting insects. However, natural gratings do occur in some invertebrate animals, like the peacock spiders, the antennae of seed shrimp, and have even been discovered in Burgess Shale fossils. Diffraction grating effects are sometimes seen in meteorology. Diffraction coronas are colorful rings surrounding a source of light, such as the sun. These are usually observed much closer to the light source than halos, and are caused by very fine particles, like water droplets, ice crystals, or smoke particles in a hazy sky. When the particles are all nearly the same size they diffract the incoming light at very specific angles. The exact angle depends on the size of the particles. Diffraction coronas are commonly observed around light sources, like candle flames or street lights, in the fog. Cloud iridescence is caused by diffraction, occurring along coronal rings when the particles in the clouds are all uniform in size. See also *Angle-sensitive pixel *Blazed grating *Diffraction efficiency *Diffraction spike *Echelle grating *Fraunhofer diffraction *Fraunhofer diffraction (mathematics) *Fresnel diffraction *Grism *Henry Augustus Rowland *Kapitza-Dirac effect *Kirchhoff's diffraction formula *N-slit interferometric equation *Ultrasonic grating *Virtually imaged phased array *Zone plate Notes References   * * External links *Diffraction Gratings (see and listen to Lecture 9) *Diffraction Gratings ‚Äî The Crucial Dispersive Element *Optics Tutorial ‚Äî Diffraction Gratings Ruled & Holographic *Ray-Tracing program handling general reflective concave gratings for Windows XP and above * Category:Diffraction Category:Diffraction gratings Category:Optics Category:Photonics ","title":"Diffraction grating"},{"id":"41033","text":"A general finite impulse response filter with n stages, each with an independent delay, di, and amplification gain, ai. In signal processing, a digital filter is a system that performs mathematical operations on a sampled, discrete-time signal to reduce or enhance certain aspects of that signal. This is in contrast to the other major type of electronic filter, the analog filter, which is an electronic circuit operating on continuous-time analog signals. A digital filter system usually consists of an analog-to-digital converter (ADC) to sample the input signal, followed by a microprocessor and some peripheral components such as memory to store data and filter coefficients etc. Program Instructions (software) running on the microprocessor implement the digital filter by performing the necessary mathematical operations on the numbers received from the ADC. In some high performance applications, an FPGA or ASIC is used instead of a general purpose microprocessor, or a specialized digital signal processor (DSP) with specific paralleled architecture for expediting operations such as filtering. Digital filters may be more expensive than an equivalent analog filter due to their increased complexity, but they make practical many designs that are impractical or impossible as analog filters. Digital filters can often be made very high order, and are often finite impulse response filters which allows for linear phase response. When used in the context of real-time analog systems, digital filters sometimes have problematic latency (the difference in time between the input and the response) due to the associated analog-to- digital and digital-to-analog conversions and anti-aliasing filters, or due to other delays in their implementation. Digital filters are commonplace and an essential element of everyday electronics such as radios, cellphones, and AV receivers. Characterization A digital filter is characterized by its transfer function, or equivalently, its difference equation. Mathematical analysis of the transfer function can describe how it will respond to any input. As such, designing a filter consists of developing specifications appropriate to the problem (for example, a second-order low pass filter with a specific cut-off frequency), and then producing a transfer function which meets the specifications. The transfer function for a linear, time-invariant, digital filter can be expressed as a transfer function in the Z-domain; if it is causal, then it has the form: :H(z) = \\\\frac{B(z)}{A(z)} = \\\\frac{{b_{0}+b_{1}z^{-1}+b_{2}z^{-2} + \\\\cdots + b_{N}z^{-N}}}{{1+a_{1}z^{-1}+a_{2}z^{-2} + \\\\cdots +a_{M}z^{-M}}} where the order of the filter is the greater of N or M. See Z-transform's LCCD equation for further discussion of this transfer function. This is the form for a recursive filter, which typically leads to an IIR infinite impulse response behaviour, but if the denominator is made equal to unity i.e. no feedback, then this becomes an FIR or finite impulse response filter. =Analysis techniques= A variety of mathematical techniques may be employed to analyze the behaviour of a given digital filter. Many of these analysis techniques may also be employed in designs, and often form the basis of a filter specification. Typically, one characterizes filters by calculating how they will respond to a simple input such as an impulse. One can then extend this information to compute the filter's response to more complex signals. Impulse response The impulse response, often denoted h[k] or h_k, is a measurement of how a filter will respond to the Kronecker delta function. For example, given a difference equation, one would set x_0 = 1 and x_k = 0 for k e 0 and evaluate. The impulse response is a characterization of the filter's behaviour. Digital filters are typically considered in two categories: infinite impulse response (IIR) and finite impulse response (FIR). In the case of linear time-invariant FIR filters, the impulse response is exactly equal to the sequence of filter coefficients, and thus: :\\\\ y_n= \\\\sum_{k=0}^{N} b_{k} x_{n-k} =\\\\sum_{k=0}^{N} h_{k} x_{n-k} IIR filters on the other hand are recursive, with the output depending on both current and previous inputs as well as previous outputs. The general form of an IIR filter is thus: :\\\\ \\\\sum_{m=0}^{M} a_{m}y_{n-m} = \\\\sum_{k=0}^{N} b_{k} x_{n-k} Plotting the impulse response will reveal how a filter will respond to a sudden, momentary disturbance. An IIR filter will always be recursive. While it is possible for a recursive filter to have a finite impulse response, non-recursive filters will always have a finite impulse response. An example is the moving average (MA) filter, that can be implemented both recursively and non recursively. Difference equation  In discrete-time systems, the digital filter is often implemented by converting the transfer function to a linear constant- coefficient difference equation (LCCD) via the Z-transform. The discrete frequency-domain transfer function is written as the ratio of two polynomials. For example: :H(z) = \\\\frac{(z+1)^2} {(z-\\\\frac{1}{2}) (z+\\\\frac{3}{4})} This is expanded: :H(z) = \\\\frac{z^2+ 2z +1} {z^2 +\\\\frac{1}{4} z - \\\\frac{3}{8}} and to make the corresponding filter causal, the numerator and denominator are divided by the highest order of z: : H(z) = \\\\frac{1 + 2z^{-1} +z^{-2}} {1 +\\\\frac{1}{4} z^{-1} - \\\\frac{3}{8} z^{-2}} = \\\\frac{Y(z)}{X(z)} The coefficients of the denominator, a_{k}, are the 'feed-backward' coefficients and the coefficients of the numerator are the 'feed-forward' coefficients, b_{k}. The resultant linear difference equation is: : y[n] = -\\\\sum_{k=1}^{M} a_{k} y[n-k] + \\\\sum_{k=0}^{N} b_{k} x[n-k] or, for the example above: : \\\\frac{Y(z)}{X(z)} = \\\\frac{1 + 2z^{-1} +z^{-2}} {1 +\\\\frac{1}{4} z^{-1} - \\\\frac{3}{8} z^{-2}} rearranging terms: : \\\\Rightarrow (1 +\\\\frac{1}{4} z^{-1} - \\\\frac{3}{8} z^{-2}) Y(z) = (1 + 2z^{-1} +z^{-2}) X(z) then by taking the inverse z-transform: : \\\\Rightarrow y[n] + \\\\frac{1}{4} y[n-1] - \\\\frac{3}{8} y[n-2] = x[n] + 2x[n-1] + x[n-2] and finally, by solving for y[n]: : y[n] = - \\\\frac{1}{4} y[n-1] + \\\\frac{3}{8} y[n-2] + x[n] + 2x[n-1] + x[n-2] This equation shows how to compute the next output sample, y[n], in terms of the past outputs, y[n-p], the present input, x[n], and the past inputs, x[n-p]. Applying the filter to an input in this form is equivalent to a Direct Form I or II (see below) realization, depending on the exact order of evaluation. In plain terms, for example, as used by a computer programmer implementing the above equation in code, it can be described as follows: y = the output, or filtered value x = the input, or incoming raw value n = the sample number, iteration number, or time period number and therefore: y[n] = the current filtered (output) value y[n-1] = the last filtered (output) value y[n-2] = the 2nd-to-last filtered (output) value x[n] = the current raw input value x[n-1] = the last raw input value x[n-2] = the 2nd-to-last raw input value Filter design The design of digital filters is a deceptively complex topic. Although filters are easily understood and calculated, the practical challenges of their design and implementation are significant and are the subject of much advanced research. There are two categories of digital filter: the recursive filter and the nonrecursive filter. These are often referred to as infinite impulse response (IIR) filters and finite impulse response (FIR) filters, respectively.A. Antoniou, Digital Filters: Analysis, Design, and Applications, New York, NY: McGraw-Hill, 1993., chapter 1 Filter realization After a filter is designed, it must be realized by developing a signal flow diagram that describes the filter in terms of operations on sample sequences. A given transfer function may be realized in many ways. Consider how a simple expression such as ax + bx + c could be evaluated - one could also compute the equivalent x(a + b) + c. In the same way, all realizations may be seen as \\"factorizations\\" of the same transfer function, but different realizations will have different numerical properties. Specifically, some realizations are more efficient in terms of the number of operations or storage elements required for their implementation, and others provide advantages such as improved numerical stability and reduced round-off error. Some structures are better for fixed-point arithmetic and others may be better for floating-point arithmetic. =Direct form I= A straightforward approach for IIR filter realization is direct form I, where the difference equation is evaluated directly. This form is practical for small filters, but may be inefficient and impractical (numerically unstable) for complex designs.J. O. Smith III, Direct Form I In general, this form requires 2N delay elements (for both input and output signals) for a filter of order N. 400px =Direct form II= The alternate direct form II only needs N delay units, where N is the order of the filter ‚Äì potentially half as much as direct form I. This structure is obtained by reversing the order of the numerator and denominator sections of Direct Form I, since they are in fact two linear systems, and the commutativity property applies. Then, one will notice that there are two columns of delays (z^{-1}) that tap off the center net, and these can be combined since they are redundant, yielding the implementation as shown below. The disadvantage is that direct form II increases the possibility of arithmetic overflow for filters of high Q or resonance.J. O. Smith III, Direct Form II It has been shown that as Q increases, the round-off noise of both direct form topologies increases without bounds.L. B. Jackson, \\"On the Interaction of Roundoff Noise and Dynamic Range in Digital Filters,\\" Bell Sys. Tech. J., vol. 49 (1970 Feb.), reprinted in Digital Signal Process, L. R. Rabiner and C. M. Rader, Eds. (IEEE Press, New York, 1972). This is because, conceptually, the signal is first passed through an all-pole filter (which normally boosts gain at the resonant frequencies) before the result of that is saturated, then passed through an all-zero filter (which often attenuates much of what the all-pole half amplifies). 400px =Cascaded second-order sections= A common strategy is to realize a higher-order (greater than 2) digital filter as a cascaded series of second-order \\"biquadratric\\" (or \\"biquad\\") sectionsJ. O. Smith III, Series Second Order Sections (see digital biquad filter). The advantage of this strategy is that the coefficient range is limited. Cascading direct form II sections results in N delay elements for filters of order N. Cascading direct form I sections results in N + 2 delay elements, since the delay elements of the input of any section (except the first section) are redundant with the delay elements of the output of the preceding section. =Other forms= Other forms include: * Direct form I and II transpose * Series/cascade lower (typical second) order subsections * Parallel lower (typical second) order subsections ** Continued fraction expansion * Lattice and ladder ** One, two and three-multiply lattice forms ** Three and four- multiply normalized ladder forms ** ARMA structures * State-space structures: ** optimal (in the minimum noise sense): (N+1)^2 parameters ** block-optimal and section-optimal: 4N-1 parameters ** input balanced with Givens rotation: 4N-1 parameters * Coupled forms: Gold Rader (normal), State Variable (Chamberlin), Kingsbury, Modified State Variable, Z√∂lzer, Modified Z√∂lzer * Wave Digital Filters (WDF) * Agarwal‚ÄìBurrus (1AB and 2AB) * Harris‚ÄìBrooking * ND-TDL * Multifeedback * Analog-inspired forms such as Sallen-key and state variable filters * Systolic arrays Comparison of analog and digital filters Digital filters are not subject to the component non-linearities that greatly complicate the design of analog filters. Analog filters consist of imperfect electronic components, whose values are specified to a limit tolerance (e.g. resistor values often have a tolerance of ¬±5%) and which may also change with temperature and drift with time. As the order of an analog filter increases, and thus its component count, the effect of variable component errors is greatly magnified. In digital filters, the coefficient values are stored in computer memory, making them far more stable and predictable.http://www.dspguide.com/ch21/1.htm Because the coefficients of digital filters are definite, they can be used to achieve much more complex and selective designs - specifically with digital filters, one can achieve a lower passband ripple, faster transition, and higher stopband attenuation than is practical with analog filters. Even if the design could be achieved using analog filters, the engineering cost of designing an equivalent digital filter would likely be much lower. Furthermore, one can readily modify the coefficients of a digital filter to make an adaptive filter or a user- controllable parametric filter. While these techniques are possible in an analog filter, they are again considerably more difficult. Digital filters can be used in the design of finite impulse response filters. Equivalent analog filters are often more complicated, as these require delay elements. Digital filters rely less on analog circuitry, potentially allowing for a better signal-to-noise ratio. A digital filter will introduce noise to a signal during analog low pass filtering, analog to digital conversion, digital to analog conversion and may introduce digital noise due to quantization. With analog filters, every component is a source of thermal noise (such as Johnson noise), so as the filter complexity grows, so does the noise. However, digital filters do introduce a higher fundamental latency to the system. In an analog filter, latency is often negligible; strictly speaking it is the time for an electrical signal to propagate through the filter circuit. In digital systems, latency is introduced by delay elements in the digital signal path, and by analog-to-digital and digital-to-analog converters that enable the system to process analog signals. In very simple cases, it is more cost effective to use an analog filter. Introducing a digital filter requires considerable overhead circuitry, as previously discussed, including two low pass analog filters. Another argument for analog filters is low power consumption. Analog filters require substantially less power and are therefore the only solution when power requirements are tight. When making an electrical circuit on a PCB it is generally easier to use a digital solution, because the processing units are highly optimized over the years. Making the same circuit with analog components would take up a lot more space when using discrete components. Two alternatives are FPAA's and ASIC's, but they are expensive for low quantities. Types of digital filters Many digital filters are based on the fast Fourier transform, a mathematical algorithm that quickly extracts the frequency spectrum of a signal, allowing the spectrum to be manipulated (such as to create very high order band-pass filters) before converting the modified spectrum back into a time-series signal with an inverse FFT operation. These filters give O(n log n) computational costs whereas conventional digital filters tend to be O(n2). Another form of a digital filter is that of a state- space model. A well used state-space filter is the Kalman filter published by Rudolf Kalman in 1960. Traditional linear filters are usually based on attenuation. Alternatively nonlinear filters can be designed, including energy transfer filters Billings S.A. \\"Nonlinear System Identification: NARMAX Methods in the Time, Frequency, and Spatio-Temporal Domains\\". Wiley, 2013 which allow the user to move energy in a designed way. So that unwanted noise or effects can be moved to new frequency bands either lower or higher in frequency, spread over a range of frequencies, split, or focused. Energy transfer filters complement traditional filter designs and introduce many more degrees of freedom in filter design. Digital energy transfer filters are relatively easy to design and to implement and exploit nonlinear dynamics. There are various ways to characterize filters; for example: * A linear filter is a linear transformation of input samples; other filters are nonlinear. Linear filters satisfy the superposition principle, i.e. if an input is a weighted linear combination of different signals, the output is a similarly weighted linear combination of the corresponding output signals. * A causal filter uses only previous samples of the input or output signals; while a non- causal filter uses future input samples. A non-causal filter can usually be changed into a causal filter by adding a delay to it. * A time-invariant filter has constant properties over time; other filters such as adaptive filters change in time. * A stable filter produces an output that converges to a constant value with time, or remains bounded within a finite interval. An unstable filter can produce an output that grows without bounds, with bounded or even zero input. * A finite impulse response (FIR) filter uses only the input signals, while an infinite impulse response (IIR) filter uses both the input signal and previous samples of the output signal. FIR filters are always stable, while IIR filters may be unstable. A filter can be represented by a block diagram, which can then be used to derive a sample processing algorithm to implement the filter with hardware instructions. A filter may also be described as a difference equation, a collection of zeros and poles or an impulse response or step response.  See also  * Bessel filter * Butterworth filter * Matched filter * Elliptical filter (Cauer filter) * Linkwitz‚ÄìRiley filter * Chebyshev filter * Sample (signal) * Electronic filter * Filter design * Biquad filter * High-pass filter, Low-pass filter * Infinite impulse response, Finite impulse response * Bilinear transform * Savitzky‚ÄìGolay filter References Further reading *J. O. Smith III, Introduction to Digital Filters with Audio Applications, Center for Computer Research in Music and Acoustics (CCRMA), Stanford University, September 2007 Edition.   * Category:Digital signal processing Category:Synthesiser modules * ","title":"Digital filter"},{"id":"41035","title":"Digital milliwatt"},{"id":"41036","text":"In telecommunications, a digital multiplex hierarchy is a hierarchy consisting of an ordered repetition of tandem digital multiplexers that produce signals of successively higher data rates at each level of the hierarchy. Digital multiplexing hierarchies may be implemented in many different configurations depending on; (a) the number of channels desired, (b) the signaling system to be used, and (c) the bit rate allowed by the communications media. Some currently available digital multiplexers have been designated as Dl-, DS-, or M-series, all of which operate at T-carrier rates. In the design of digital multiplex hierarchies, care must be exercised to ensure interoperability of the multiplexers used in the hierarchy. Digroup Digroup is an abbreviation for digital group. In telephony, a basic group in the digital multiplex hierarchy. In the North American and Japanese T-carrier digital hierarchies, each digroup supports 12 PCM voice channels or their equivalent in other services. The DS1 line rate (2 digroups plus overhead bits) is 1.544 Mbit/s, supporting 24 voice channels or their equivalent in other services. In the E-carrier European hierarchy, each digroup supports 15 PCM channels or their equivalent in other services. The DS1 line rate (2 digroups plus overhead bits) is 2.048 Mbit/s, supporting 30 voice channels or their equivalent in other services. References See also *Plesiochronous digital hierarchy *Synchronous digital hierarchy References * Category:Multiplexing ","title":"Digital multiplex hierarchy"},{"id":"41037","text":"Digital Signal 0 (DS0) is a basic digital signaling rate of 64 kilobits per second (kbit/s), corresponding to the capacity of one analog voice-frequency- equivalent communication channel. The DS0 rate, and its equivalents E0 in the E-carrier system and T0 in the T-carrier system, form the basis for the digital multiplex transmission hierarchy in telecommunications systems used in North America, Europe, Japan, and the rest of the world, for both the early plesiochronous systems such as T-carrier and for modern synchronous systems such as SDH/SONET. The DS0 rate was introduced to carry a single digitized voice call. For a typical phone call, the audio sound is digitized at an 8 kHz sample rate, or 8000 samples per second, using 8-bit pulse-code modulation for each of the samples. This results in a data rate of 64 kbit/s. Because of its fundamental role in carrying a single phone call, the DS0 rate forms the basis for the digital multiplex transmission hierarchy in telecommunications systems used in North America. To limit the number of wires required between two involved in exchanging voice calls, a system was built in which multiple DS0s are multiplexed together on higher capacity circuits. In this system, twenty- four (24) DS0s are multiplexed into a DS1 signal. Twenty-eight (28) DS1s are multiplexed into a DS3. When carried over copper wire, this is the well-known T-carrier system, with T1 and T3 corresponding to DS1 and DS3, respectively. Besides its use for voice communications, the DS0 rate may support twenty 2.4 kbit/s channels, ten 4.8 kbit/s channels, five 9.67 kbit/s channels, one 56 kbit/s channel, or one 64 kbit/s clear channel. E0 (standardized as ITU G.703) is the European equivalent of the North American DS0 for carrying a single voice call. However, there are some subtle differences in implementation. Voice signals are encoded for carriage over E0 according to ITU G.711. Note that when a T-carrier system is used as in North America, robbed bit signaling can mean that a DS0 channel carried over that system is not an error-free bit- stream. The out-of-band signaling used in the European E-carrier system avoids this. References See also *DS0A *Digital Signal 1 *Digital Signal 3 Category:Telecommunications standards ","title":"Digital Signal 0"},{"id":"41038","text":"Digital subscriber line (DSL; originally digital subscriber loop) is a family of technologies that are used to transmit digital data over telephone lines. In telecommunications marketing, the term DSL is widely understood to mean asymmetric digital subscriber line (ADSL), the most commonly installed DSL technology, for Internet access. DSL service can be delivered simultaneously with wired telephone service on the same telephone line since DSL uses higher frequency bands for data. On the customer premises, a DSL filter on each non- DSL outlet blocks any high-frequency interference to enable simultaneous use of the voice and DSL services. The bit rate of consumer DSL services typically ranges from 256 kbit/s to over 100 Mbit/s in the direction to the customer (downstream), depending on DSL technology, line conditions, and service-level implementation. Bit rates of 1 Gbit/s have been reached.The Next Generation of DSL Can Pump 1Gbps Through Copper Phone Lines, Gizmodo, 18 December 2013, Andrew Tarantola In ADSL, the data throughput in the upstream direction (the direction to the service provider) is lower, hence the designation of asymmetric service. In symmetric digital subscriber line (SDSL) services, the downstream and upstream data rates are equal. Researchers at Bell Labs have reached speeds over 1 Gbit/s for symmetrical broadband access services using traditional copper telephone lines, though such speeds have not yet been deployed elsewhere.Alcatel-Lucent sets broadband speed record using copper, Phys.org, 10 July 2014, Nancy OwanoResearchers get record broadband speeds out of old-school copper wire, Engadget, 10 July 2014, Matt Brian History It was originally thought that it was not possible to operate a conventional phone line beyond low-speed limits (typically under 9600 bit/s). In the 1950s, ordinary twisted-pair telephone cable often carried four megahertz (MHz) television signals between studios, suggesting that such lines would allow transmitting many megabits per second. One such circuit in the United Kingdom ran some between the BBC studios in Newcastle-upon-Tyne and the Pontop Pike transmitting station. However, these cables had other impairments besides Gaussian noise, preventing such rates from becoming practical in the field. The 1980s saw the development of techniques for broadband communications that allowed the limit to be greatly extended. A patent was filed in 1979 for the use of existing telephone wires for both telephones and data terminals that were connected to a remote computer via a digital data carrier system. The motivation for digital subscriber line technology was the Integrated Services Digital Network (ISDN) specification proposed in 1984 by the CCITT (now ITU-T) as part of Recommendation I.120, later reused as ISDN digital subscriber line (IDSL). Employees at Bellcore (now Telcordia Technologies) developed asymmetric digital subscriber line (ADSL) by placing wide-band digital signals at frequencies above the existing baseband analog voice signal carried on conventional twisted pair cabling between telephone exchanges and customers. A patent was filed in 1988. Joseph W. Lechleider's contribution to DSL was his insight that an asymmetric arrangement offered more than double the bandwidth capacity of symmetric DSL. This allowed Internet service providers to offer efficient service to consumers, who benefited greatly from the ability to download large amounts of data but rarely needed to upload comparable amounts. ADSL supports two modes of transport: fast channel and interleaved channel. Fast channel is preferred for streaming multimedia, where an occasional dropped bit is acceptable, but lags are less so. Interleaved channel works better for file transfers, where the delivered data must be error-free but latency (time delay) incurred by the retransmission of error-containing packets is acceptable. Consumer-oriented ADSL was designed to operate on existing lines already conditioned for Basic Rate Interface ISDN services. Engineers developed high speed DSL facilities such as high bit rate digital subscriber line (HDSL) and symmetric digital subscriber line (SDSL) to provision traditional Digital Signal 1 (DS1) services over standard copper pair facilities. Older ADSL standards delivered 8 Mbit/s to the customer over about of unshielded twisted-pair copper wire. Newer variants improved these rates. Distances greater than significantly reduce the bandwidth usable on the wires, thus reducing the data rate. But ADSL loop extenders increase these distances by repeating the signal, allowing the LEC to deliver DSL speeds to any distance.Infinite Reach ADSL SoC Until the late 1990s, the cost of digital signal processors for DSL was prohibitive. All types of DSL employ highly complex digital signal processing algorithms to overcome the inherent limitations of the existing twisted pair wires. Due to the advancements of very-large-scale integration (VLSI) technology, the cost of the equipment associated with a DSL deployment lowered significantly. The two main pieces of equipment are a digital subscriber line access multiplexer (DSLAM) at one end and a DSL modem at the other end. A DSL connection can be deployed over existing cable. Such deployment, even including equipment, is much cheaper than installing a new, high-bandwidth fiber-optic cable over the same route and distance. This is true both for ADSL and SDSL variations. The commercial success of DSL and similar technologies largely reflects the advances made in electronics over the decades that have increased performance and reduced costs even while digging trenches in the ground for new cables (copper or fiber optic) remains expensive. These advantages made ADSL a better proposition for customers requiring Internet access than metered dial up, while also allowing voice calls to be received at the same time as a data connection. Telephone companies were also under pressure to move to ADSL owing to competition from cable companies, which use DOCSIS cable modem technology to achieve similar speeds. Demand for high bandwidth applications, such as video and file sharing, also contributed to the popularity of ADSL technology. Early DSL service required a dedicated dry loop, but when the U.S. Federal Communications Commission (FCC) required incumbent local exchange carriers (ILECs) to lease their lines to competing DSL service providers, shared-line DSL became available. Also known as DSL over unbundled network element, this unbundling of services allows a single subscriber to receive two separate services from two separate providers on one cable pair. The DSL service provider's equipment is co-located in the same telephone exchange as that of the ILEC supplying the customer's pre-existing voice service. The subscriber's circuit is rewired to interface with hardware supplied by the ILEC which combines a DSL frequency and POTS signals on a single copper pair. By 2012, some carriers in the United States reported that DSL remote terminals with fiber backhaul were replacing older ADSL systems. Operation Telephones are connected to the telephone exchange via a local loop, which is a physical pair of wires. The local loop was originally intended mostly for the transmission of speech, encompassing an audio frequency range of 300 to 3400 hertz (commercial bandwidth). However, as long-distance trunks were gradually converted from analog to digital operation, the idea of being able to pass data through the local loop (by utilizing frequencies above the voiceband) took hold, ultimately leading to DSL. The local loop connecting the telephone exchange to most subscribers has the capability of carrying frequencies well beyond the 3400 Hz upper limit of POTS. Depending on the length and quality of the loop, the upper limit can be tens of megahertz. DSL takes advantage of this unused bandwidth of the local loop by creating 4312.5 Hz wide channels starting between 10 and 100 kHz, depending on how the system is configured. Allocation of channels continues to higher frequencies (up to 1.1 MHz for ADSL) until new channels are deemed unusable. Each channel is evaluated for usability in much the same way an analog modem would on a POTS connection. More usable channels equate to more available bandwidth, which is why distance and line quality are a factor (the higher frequencies used by DSL travel only short distances). The pool of usable channels is then split into two different frequency bands for upstream and downstream traffic, based on a preconfigured ratio. This segregation reduces interference. Once the channel groups have been established, the individual channels are bonded into a pair of virtual circuits, one in each direction. Like analog modems, DSL transceivers constantly monitor the quality of each channel and will add or remove them from service depending on whether they are usable. Once upstream and downstream circuits are established, a subscriber can connect to a service such as an Internet service provider or other network services, like a corporate MPLS network. The underlying technology of transport across DSL facilities uses modulation of high-frequency carrier waves, an analog signal transmission. A DSL circuit terminates at each end in a modem which modulates patterns of bits into certain high-frequency impulses for transmission to the opposing modem. Signals received from the far-end modem are demodulated to yield a corresponding bit pattern that the modem passes on, in digital form, to its interfaced equipment, such as a computer, router, switch, etc. Unlike traditional dial-up modems, which modulate bits into signals in the 300‚Äì3400 Hz audio baseband, DSL modems modulate frequencies from 4000 Hz to as high as 4 MHz. This frequency band separation enables DSL service and plain old telephone service (POTS) to coexist on the same cables. On the subscriber's end of the circuit, inline DSL filters are installed on each telephone to pass voice frequencies but filter the high-frequency signals that would otherwise be heard as hiss. Also, nonlinear elements in the phone could otherwise generate audible intermodulation and may impair the operation of the data modem in the absence of these low-pass filters. DSL and RADSL modulations do not use the voice-frequency band so high-pass filters are incorporated in the circuitry of DSL modems filter out voice frequencies. A DSL modem Because DSL operates above the 3.4 kHz voice limit, it cannot pass through a loading coil, which is an inductive coil that is designed to counteract loss caused by shunt capacitance (capacitance between the two wires of the twisted pair). Loading coils are commonly set at regular intervals in POTS lines. Voice service cannot be maintained past a certain distance without such coils. Therefore, some areas that are within range for DSL service are disqualified from eligibility because of loading coil placement. Because of this, phone companies endeavor to remove loading coils on copper loops that can operate without them. Longer lines that require them can be replaced with fiber to the neighborhood or node (FTTN). Most residential and small-office DSL implementations reserve low frequencies for POTS, so that (with suitable filters and/or splitters) the existing voice service continues to operate independently of the DSL service. Thus POTS-based communications, including fax machines and dial-up modems, can share the wires with DSL. Only one DSL modem can use the subscriber line at a time. The standard way to let multiple computers share a DSL connection uses a router that establishes a connection between the DSL modem and a local Ethernet, powerline, or Wi-Fi network on the customer's premises. The theoretical foundations of DSL, like much of communication technology, can be traced back to Claude Shannon's seminal 1948 paper: A Mathematical Theory of Communication. Generally, higher bit rate transmissions require a wider frequency band, though the ratio of bit rate to symbol rate and thus to bandwidth are not linear due to significant innovations in digital signal processing and digital modulation methods. =Naked DSL= Naked DSL is a way of providing only DSL services over a local loop. It is useful when the customer does not need the traditional telephony voice service because voice service is received either on top of the DSL services (usually VoIP) or through another network (E.g., mobile telephony). It is also commonly called a UNE (for unbundled network element) in the United States; in Australia it is known as a ULL (unconditioned local loop);ULL (unconditioned local loop). Whirlpool.net.au. Retrieved on 2013-09-18. in Belgium it is known as \\"raw copper\\" and in the UK it is known as Single Order GEA (SoGEA). It started making a comeback in the United States in 2004 when Qwest started offering it, closely followed by Speakeasy. As a result of AT&T;'s merger with SBC, and Verizon's merger with MCI,Verizon MCI merger Archived copy at WebCite (July 14, 2007). those telephone companies have an obligation to offer naked DSL to consumers. Typical setup On the customer side, the DSL transceiver, or ATU-R, or more commonly known as a DSL modem, is hooked up to a phone line. The telephone company connects the other end of the line to a DSLAM, which concentrates a large number of individual DSL connections into a single box. The location of the DSLAM depends on the telco, but it cannot be located too far from the user because of attenuation between the DSLAM and the user's DSL modem. It is common for a few residential blocks to be connected to one DSLAM. The accompanying figure is a schematic of a simple DSL connection (in blue). The right side shows a DSLAM residing in the telephone company's telephone exchange. The left side shows the customer premises equipment with an optional router. The router manages a local area network (LAN) which connects PCs and other local devices. With many service providers, the customer may opt for a modem which contains both a router and wireless access. This option (within the dashed bubble) often simplifies the connection. DSL Connection schematic Example of a DSLAM from 2006 =Exchange equipment= At the exchange, a digital subscriber line access multiplexer (DSLAM) terminates the DSL circuits and aggregates them, where they are handed off to other networking transports. In the case of ADSL, the voice component is also separated at this step, either by a filter integrated in the DSLAM or by a specialized filtering equipment installed before it. The DSLAM terminates all connections and recovers the original digital information. =Customer equipment= The customer end of the connection consists of a terminal adapter or \\"DSL modem\\". This converts data between the digital signals used by computers and the analog voltage signal of a suitable frequency range which is then applied to the phone line. DSL Modem schematic In some DSL variations (for example, HDSL), the terminal adapter connects directly to the computer via a serial interface, using protocols such as ethernet or V.35. In other cases (particularly ADSL), it is common for the customer equipment to be integrated with higher level functionality, such as routing, firewalling, or other application-specific hardware and software. In this case, the equipment is referred to as a gateway. Most DSL technologies require installation of appropriate filters to separate, or split, the DSL signal from the low- frequency voice signal. The separation can take place either at the demarcation point, or with filters installed at the telephone outlets inside the customer premises. Each way has its practical and economic limitations. DSL modem initialization When the DSL modem powers up it goes through a series of steps to establish connections. The actual process varies from modem to modem but generally involves the following steps: # The DSL transceiver performs a self-test, including image load and activation. # The DSL transceiver then attempts to synchronize with the DSLAM. Data can only come into the computer when the DSLAM and the modem are synchronized. The synchronization process is relatively quick (in the range of seconds) but is very complex, involving extensive tests that allow both sides of the connection to optimize the performance for line characteristics including noise and error handling. External, or standalone modem units have an indicator labeled \\"CD\\", \\"DSL\\", or \\"LINK\\", which can be used to tell if the modem is synchronized. During synchronization the light flashes; when synchronized, the light stays lit, usually green. # If supported, the DSL transceiver establishes a gateway internet connection. # The DSL transceiver establishes a connection with the router or computer. For residential variations of DSL, this is usually the Ethernet (RJ-45) port or a USB port; in rare models, a FireWire port is used. Older DSL modems sported a native ATM interface (usually, a 25 Mbit/s serial interface). Also, some variations of DSL (such as SDSL) use synchronous serial connections. Modern DSL gateways often integrate routing and other functionality. Their initialization is very similar to a PC boot up. The system image is loaded from the flash storage; the system boots, synchronizes the DSL connection and finally establishes the internet IP services and connection between the local network and the service provider, using protocols such as DHCP or PPPoE. According to Implementation and Applications of DSL Technology (2007), the PPPoE method far outweighed DHCP in terms of deployment on DSLs, and PAP was the predominant form of subscriber authentication used in such circumstances. The system image can usually be updated to correct bugs, or to add new functionality. Protocols and configurations Many DSL technologies implement an asynchronous transfer mode (ATM) layer over the low-level bitstream layer to enable the adaptation of a number of different technologies over the same link. DSL implementations may create bridged or routed networks. In a bridged configuration, the group of subscriber computers effectively connect into a single subnet. The earliest implementations used DHCP to provide network details such as the IP address to the subscriber equipment, with authentication via MAC address or an assigned host name. Later implementations often use Point-to-Point Protocol (PPP) to authenticate with a user ID and password, and to provide network details (Point-to-Point Protocol over Ethernet (PPPoE) or Point-to-Point Protocol over ATM (PPPoA)). Transmission modulation methods Transmission methods vary by market, region, carrier, and equipment. * DMT: Discrete multitone modulation, the most common kind, also known as OFDM (Orthogonal frequency-division multiplexing) * TC-PAM: Trellis Coded Pulse Amplitude Modulation, used for HDSL2 and SHDSL * CAP: Carrierless Amplitude Phase Modulation - deprecated in 1996 for ADSL, used for HDSL * 2B1Q: Two-binary, one-quaternary, used for IDSL and HDSL DSL technologies DSL technologies (sometimes collectively summarized as xDSL) include: *Symmetric digital subscriber line (SDSL), umbrella term for xDSL where the bitrate is equal in both directions. **ISDN digital subscriber line (IDSL), ISDN-based technology that provides a bitrate equivalent to two ISDN bearer and one data channel, 144 kbit/s symmetric over one pair **High bit rate digital subscriber line (HDSL), ITU-T G.991.1, the first DSL technology that used a higher frequency spectrum than ISDN, 1,544 kbit/s and 2,048 kbit/s symmetric services, either on 2 or 3 pairs at 784 kbit/s each, 2 pairs at 1,168 kbit/s each, or one pair at 2,320 kbit/s **High bit rate digital subscriber line 2/4 (HDSL2, HDSL4), ANSI, 1,544 kbit/s symmetric over one pair (HDSL2) or two pairs (HDSL4) **Symmetric digital subscriber line (SDSL), specific proprietary technology, up to 1,544 kbit/s symmetric over one pair **Single-pair high-speed digital subscriber line (G.SHDSL), ITU-T G.991.2, standardized successor of HDSL and proprietary SDSL, up to 5,696 kbit/s per pair, up to four pairs *Asymmetric digital subscriber line (ADSL), umbrella term for xDSL where the bitrate is greater in one direction than the other. **ANSI T1.413 Issue 2, up to 8 Mbit/s and 1 Mbit/s **G.dmt, ITU-T G.992.1, up to 10 Mbit/s and 1 Mbit/s **G.lite, ITU-T G.992.2, more noise and attenuation resistant than G.dmt, up to 1,536 kbit/s and 512 kbit/s **Asymmetric digital subscriber line 2 (ADSL2), ITU-T G.992.3, up to 12 Mbit/s and 3.5 Mbit/s **Asymmetric digital subscriber line 2 plus (ADSL2+), ITU-T G.992.5, up to 24 Mbit/s and 3.5 Mbit/s **Very-high-bit-rate digital subscriber line (VDSL), ITU-T G.993.1, up to 52 Mbit/s and 16 Mbit/s **Very- high-bit-rate digital subscriber line 2 (VDSL2), ITU-T G.993.2, an improved version of VDSL, compatible with ADSL2+, sum of both directions up to 200 Mbit/s. G.vector crosstalk cancelling feature (ITU-T G.993.5) can be used to increase range at a given bitrate, e.g. 100 Mbit/s at up to 500 meters.http://www.ericsson.com/res/thecompany/docs/journal_conference_papers/broadband_and_transport/itu- ts_new_g_vector_standard_proliferates_100mbs_dsl.pdf **G.fast, ITU-T G.9700 and G.9701, up to approximately 1 Gbit/s aggregate uplink and downlink at 100m. Approved in December 2014, deployments planned for 2016. *Bonded DSL Rings (DSL Rings), a shared ring topology at 400 Mbit/s *Etherloop Ethernet local loop *High Speed Voice and Data Link *Internet Protocol subscriber line (IPSL), developed by Rim Semiconductor in 2007, allowed for 40 Mbit/s using 26 AWG copper telephone wire at a radius, 26 Mbit/s at a radius. The company operated until 2008. *Rate-adaptive digital subscriber line (RADSL), designed to increase range and noise tolerance by sacrificing upstream speed *Uni-DSL (Uni digital subscriber line or UDSL), technology developed by Texas Instruments, backwards compatible with all DMT standards *Frequency Division Vectoring, copper networks working with fiberAdtran lays groundwork for superfast broadband over copper, PC World * Hybrid Access Networks combine existing xDSL deployments with a wireless network such as LTE to increase bandwidth and quality of experience by balancing the traffic over the two access networks. The line-length limitations from telephone exchange to subscriber impose severe limits on data transmission rates. Technologies such as VDSL provide very high-speed but short-range links. VDSL is used as a method of delivering \\"triple play\\" services (typically implemented in fiber to the curb network architectures). See also * ADSL loop extender * Broadband Internet access * Dynamic spectrum management (DSM) * Electronic filter * John Cioffi ‚Äì Known as \\"the father of DSL\\" * List of countries by number of Internet subscriptions * List of device bandwidths  References  Further reading * pp 53‚Äì86 * * External links * ADSL Theory‚ÄîInformation about the background & workings of ADSL, and the factors involved in achieving a good sync between your modem and the DSLAM. Category:American inventions Category:Modems Category:Internet access ","title":"Digital subscriber line"},{"id":"41040","text":"In telecommunication, a digital transmission group is a group of digitized voice or data channels or both with bit streams that are combined into a single digital bit stream for transmission over communications media. Digital transmission groups usually are categorized by their maximum capacity, not by a specific number of channels. However, the maximum digital transmission group capacity must be equal to or greater than the sum of the individual multiplexer input channel capacities. See also *Digital Signal 1 *E-carrier *Plesiochronous Digital Hierarchy References Category:Multiplexing ","title":"Digital transmission group"},{"id":"41044","text":"Direct access may refer to: *DirectAccess, a network technology in Windows 7 and Windows Server 2008 R2, and Windows 8 and Windows Server 2012 *Direct access (computing), a concept in computer science *Direct Access Archive, a proprietary file format *Direct access storage device, a secondary computer storage device *Direct Access Test Unit, special numbers used to test telephone exchanges *Direct access trading, a technology for stock trading ","title":"Direct access"},{"id":"41045","text":"Direct connect may refer to: * Direct Connect (protocol), a file sharing client and protocol * A protocol used by the program AOL Instant Messenger * Sprint Direct Connect, a brand name used by Sprint Corporation for its digital push-to-talk service, similar to a walkie-talkie * Direct Connect is an Australian company related to Lumo Energy ","title":"Direct connect"},{"id":"41046","text":"Direct distance dialing (DDD) is a telecommunication service feature in North America by which a caller may, without operator assistance, call any other user outside the local calling area. Direct dialing by subscribers typically requires extra digits to be dialed as prefixes to the directory telephone number of the destination. DDD also extends beyond the boundaries of the national public telephone network, in which case it is called international direct dialing or international direct distance dialing (IDDD). History The first direct-dialed long-distance telephone calls were possible in the New Jersey communities of Englewood and Teaneck. Customers of the ENglewood 3, ENglewood 4 and TEaneck 7 exchanges, who could already dial telephone numbers in the New York City area, could place calls to eleven major cities across the United States by dialing the three-digit area code and the seven-digit directory number. Local telephone numbers still consisted of the first two letters of the central office name and five digits. On November 10, 1951, Englewood Mayor M. Leslie Denning made the first customer-dialed long-distance call, to Mayor Frank Osborne of Alameda, California. The destinations, and their area codes, equipped with a long-distance toll-switch at that time were: * 617: Boston, Massachusetts * 312: Chicago, Illinois * 216: Cleveland, Ohio * 313: Detroit, Michigan * 414: Milwaukee, Wisconsin * 415: Oakland, California * 215: Philadelphia, Pennsylvania * 412: Pittsburgh, Pennsylvania * 401: Providence, Rhode Island * 916: Sacramento, California * 318: San Francisco Other areas could not yet be included in DDD as they did not have the necessary toll switching equipment, or because they still did not use a seven- digit local numbering plan. Montreal, Quebec and Toronto, Ontario in Canada, for example, had a mix of six- and seven-digit telephone numbers from 1951 to 1957, and did not have DDD until 1958. Whitehorse, Yukon had seven-digit numbers from 1965, but the necessary switching equipment was not in place until 1972. San Francisco required the special code 318 for temporary routing requirements. San Francisco and Oakland each had their own separate toll- switches, so calls had to be routed accordingly depending on the final destination. As the telephone equipment used at the time could only handle three-digit translation, the temporary use of area code 318 was required to distinguish between the two areas. area code 318 was temporarily used to specify San Francisco and areas north of the Golden Gate, while calls with destinations in Oakland and the East Bay continued to use area code 415. When the electromechanical card-translator box became available sometime during 1952‚Äì53, six-digit translation became possible and the use of area code 318 was no longer required. Area code 318 was reclaimed for future use and the entire San Francisco Bay Area returned to using area code 415. Hardware The No. 4 Crossbar switching system had been introduced in the early 1940s to switch four-wire circuits and replace the incoming operator. With semiautomatic operation analogous to the early days of the panel switch, the operator in the originating city used a multifrequency keypad to dial an access code to connect to the correct city and to send the seven-digit number to incoming equipment at the terminating city. This design was further refined to serve DDD. The card sorter of the 4A/CTS (Number 4A Crossbar / Card Translator System) allowed six-digit translation of the central office code number dialed by the customer. This determined the proper trunk circuits to use, where separate circuit groups were used for different cities in the same area code, as in the case of Oakland and San Francisco. The new device used metal cards similar in principle to computer punched cards, and they were rapidly scanned as they fell past a light beam. CTS machines were called 4A (Advanced) if the translator was included in the original installation, and 4M (Modified) if it was added later. A 1970s version of 4XB, the 4A/ETS, used a computer to translate. For international dialing, Traffic Service Position System (TSPS) provided the extra computer power. The reach of DDD was limited due to the inefficiency and expense of switching equipment, and the limited ability to process records of completed calls. An early obstacle was that the majority of switching systems did not provide Automatic Number Identification (ANI). Common control switches, such as the 1XB switch, were fairly quickly retrofitted to provide ANI, and most 5XB switches were initially installed with ANI services. Panel switch were eventually retrofitted, as were some step-by-step systems that were not scheduled for immediate replacement. Even if a switch had ANI, it could not identify callers on party lines. This was only partly overcome by tip-party identification for two-party lines. As the cost of subscriber line carrier declined, party lines were gradually phased out. As this and other improved technologies became available, as well as Automatic Message Accounting (AMA) computers to process the long-distance records into customer bills, the reach of DDD was slow in the 1950s, but quickened in the early 1960s. Electronic switching systems allowed electronic processing of the dialed digits, referring to electronic memories to determine call routing, and this has reached the state of the art, with digital telephone exchanges which are basically specialized computers that route voice traffic from one \\"peripheral\\" to another as digital data. Call routing can now be done based on the area code, central office code and even the first two digits of the line number, although routing based on digits past the central office code is usually limited to cases of competitive local exchange carriers, number pooling and number portability. IDDD AT&T; Long-Distance Building In the 1960s, with the domestic conversion still underway, plans were laid to extend Direct Dialing beyond North America and its nearby islands. With so much new equipment already working that could only handle ten digit phone numbers, a system was devised by which most toll offices did not have to store and forward the whole international phone number. Gateway offices were set up in New York, London and Paris, connected to the ordinary automatic toll network. The New York gateway was at 32 Avenue of the Americas. The new LT1 5XB switch on the tenth floor of 435 West 50th Street received new Originating Registers and Outgoing Senders able to handle 15 digit telephone numbers, with appropriate modifications to Completing Markers and other equipment. Other 5XB in the next few years were installed with IDDD as original equipment, and in the 1970s ESS offices also provided the service. The key to the new system was two-stage multi-frequency pulsing. The outgoing sender sent its Class 4 toll center an off-hook signal as usual, received a wink as usual as a \\"proceed to send\\" signal, and outpulsed only a special 3-digit (later 6-digit) access code. The toll center picked a trunk through the long-distance network to the gateway office, which sent a second wink to the originating office, which then sent the whole dialed number. Thus the toll switching system needed no modification except at the gateway. The international trunks used Signaling System No. 5, a \\"North Atlantic\\" version of the North American multi-frequency signaling system, with minor modifications including slightly higher digit rate. European MF systems of the time used compelled signalling, which would slow down too much on a long transoceanic connection. In the 1970s, toll centers were modified by adding TSPS. With these new computers in place, digit storage in the toll system was no longer a problem. End offices were less extensively modified, and sent all their digits in a single stream. TSPS handled the gateway codes and other complexities of toll connections to the gateway office. Other cities could not yet be included in DDD as they did not yet have the necessary toll switching equipment to handle incoming calls automatically, or because they still did not use a seven-digit numbering system. Montreal, Quebec and Toronto, Ontario in Canada, for example, had a mix of six- and seven-digit numbers from 1951 to 1957, and did not have DDD until 1958. Whitehorse, Yukon had seven-digit numbers from 1965, but the necessary switching equipment was not in place locally until 1972. Equivalent service in the United Kingdom In the United Kingdom and other parts of the Commonwealth of Nations, an equivalent service to direct distance dialing is subscriber trunk dialing (STD), and ISD for international subscriber trunk dialing. The Queen inaugurated STD on 5 December 1958, when she dialed a call from Bristol to Edinburgh and spoke to the Lord Provost. See also *1958 in the United Kingdom References * * External links *4XB switch Category:Telecommunication services Category:Telecommunications-related introductions in 1951 it:Teleselezione ","title":"Direct distance dialing"},{"id":"41049","text":"In telecommunications, direct-sequence spread spectrum (DSSS) is a spread- spectrum modulation technique primarily used to reduce overall signal interference. The direct-sequence modulation makes the transmitted signal wider in bandwidth than the information bandwidth. After the despreading or removal of the direct-sequence modulation in the receiver, the information bandwidth is restored, while the unintentional and intentional interference is substantially reduced. With DSSS, the message bits are modulated by a pseudorandom bit sequence known as a spreading sequence. Each spreading- sequence bit, which is known as a chip, has a much shorter duration (larger bandwidth) than the original message bits. The modulation of the message bits scrambles and spreads the pieces of data, and thereby results in a bandwidth size nearly identical to that of the spreading sequence. The smaller the chip duration, the larger the bandwidth of the resulting DSSS signal; more bandwidth multiplexed to the message signal results in better resistance against interference. Some practical and effective uses of DSSS include the code-division multiple access (CDMA) method, the IEEE 802.11b specification used in Wi-Fi networks, and the Global Positioning System. Features # DSSS phase-shifts a sine wave pseudorandomly with a continuous string of chips, each of which has a much shorter duration than an information bit. That is, each information bit is modulated by a sequence of much faster chips. Therefore, the chip rate is much higher than the information bit rate. # DSSS uses a signal structure in which the spreading sequence produced by the transmitter is already known by the receiver. The receiver can then use the same spreading sequence to counteract its effect on the received signal in order to reconstruct the information signal. Transmission method Direct- sequence spread-spectrum transmissions multiply the data being transmitted by a pseudorandom spreading sequence that has a much higher bit rate than the original data rate. The resulting transmitted signal resembles bandlimited white noise, like an audio recording of \\"static\\". However, this noise-like signal is used to exactly reconstruct the original data at the receiving end, by multiplying it by the same spreading sequence (because 1 √ó 1 = 1, and ‚àí1 √ó ‚àí1 = 1). This process, known as despreading, is mathematically a correlation of the transmitted spreading sequence with the spreading sequence that the receiver already knows the transmitter is using. After the despreading, the signal-to-noise ratio is approximately increased by the spreading factor, which is the ratio of the spreading-sequence rate to the data rate. While a transmitted DSSS signal occupies a much wider bandwidth than a simple modulation of the original signal would require, its frequency spectrum can be somewhat restricted for spectrum economy by a conventional analog bandpass filter to give a roughly bell-shaped envelope centered on the carrier frequency. In contrast, frequency-hopping spread spectrum pseudorandomly retunes the carrier and requires a uniform frequency response since any bandwidth shaping would cause amplitude modulation of the signal by the hopping code. If an undesired transmitter transmits on the same channel but with a different spreading sequence (or no sequence at all), the despreading process reduces the power of that signal. This effect is the basis for the code division multiple access (CDMA) property of DSSS, which allows multiple transmitters to share the same channel within the limits of the cross- correlation properties of their spreading sequences. Benefits * Resistance to unintended or intended jamming * Sharing of a single channel among multiple users * Reduced signal/background-noise level hampers interception * Determination of relative timing between transmitter and receiver Uses * The United States GPS, European Galileo and Russian GLONASS satellite navigation systems; earlier GLONASS used DSSS with a single spreading sequence in conjunction with FDMA, while later GLONASS used DSSS to achieve CDMA with multiple spreading sequences. * DS-CDMA (Direct-Sequence Code Division Multiple Access) is a multiple access scheme based on DSSS, by spreading the signals from/to different users with different codes. It is the most widely used type of CDMA. * Cordless phones operating in the 900 MHz, 2.4 GHz and 5.8 GHz bands * IEEE 802.11b 2.4 GHz Wi-Fi, and its predecessor 802.11-1999. (Their successor 802.11g uses both OFDM and DSSS) * Automatic meter reading * IEEE 802.15.4 (used, e.g., as PHY and MAC layer for ZigBee, or, as the physical layer for WirelessHART) * Radio-controlled model Automotive vehicles See also * Complementary code keying * Frequency-hopping spread spectrum * Linear feedback shift register * Orthogonal frequency-division multiplexing References * The Origins of Spread-Spectrum Communications * * NTIA Manual of Regulations and Procedures for Federal Radio Frequency Management  External links  * Civil Spread Spectrum History Category:Quantized radio modulation modes Category:Wireless networking Category:IEEE 802.11 ja:„Çπ„Éö„ÇØ„Éà„É©„É†Êã°Êï£#Áõ¥Êé•Êã°Êï£ ","title":"Direct-sequence spread spectrum"},{"id":"41050","text":"In telecommunication, a disengagement originator is the user or execution unit that initiates a disengagement attempt. The disengagement originator may be the originating user, the destination user, or the communications system. The communications system may deliberately originate the disengagement because of preemption, or inadvertently due to system malfunction. See also * Clearing (telecommunications) (a.k.a. teardown) * Signaling System 7 References Category:Teletraffic ","title":"Disengagement originator"},{"id":"41051","text":"A dispersion-limited operation is an operation of a communications link in which signal waveform degradation attributable to the dispersive effects of the communications medium is the dominant mechanism that limits link performance. The dispersion is the filter-like effect which a link has on the signal, due to the different propagation speeds of the eigenmodes of the link. Practically, this means that the waveform at the input will be different from the waveform at the output of the link. Note that the amount of allowable degradation is dependent on the quality of the receiver. In fiber optic communications, dispersion-limited operation is often confused with distortion-limited operation. References * Category:Fiber-optic communications ","title":"Dispersion-limited operation"},{"id":"41052","text":"Distortion is the alteration of the original shape (or other characteristic) of something. In communications and electronics it means the alteration of the waveform of an information-bearing signal, such as an audio signal representing sound or a video signal representing images, in an electronic device or communication channel. Distortion is usually unwanted, and so engineers strive to eliminate or minimize it. In some situations, however, distortion may be desirable. For example, in noise reduction systems like the Dolby system, an audio signal is deliberately distorted in ways that emphasize aspects of the signal that are subject to electrical noise, then it is symmetrically \\"undistorted\\" after passing through a noisy communication channel, reducing the noise in the received signal. Distortion is also used as a musical effect, particularly with electric guitars. The addition of noise or other outside signals (hum, interference) is not considered distortion, though the effects of quantization distortion are sometimes included in noise. Quality measures that reflect both noise and distortion include the signal-to- noise and distortion (SINAD) ratio and total harmonic distortion plus noise (THD+N). Electronic signals Graph of a waveform and some distorted versions of the same waveform In telecommunication and signal processing, a noise-free system can be characterised by a transfer function, such that the output y(t) can be written as a function of the input x as : y(t) = F(x(t)) When the transfer function comprises only a perfect gain constant A and perfect delay T : y(t) = A\\\\cdot x(t-T) the output is undistorted. Distortion occurs when the transfer function F is more complicated than this. If F is a linear function, for instance a filter whose gain and/or delay varies with frequency, the signal suffers linear distortion. Linear distortion does not introduce new frequency components to a signal but does alter the balance of existing ones. This diagram shows the behaviour of a signal (made up of a square wave followed by a sine wave) as it is passed through various distorting functions. # The first trace (in black) shows the input. It also shows the output from a non-distorting transfer function (straight line). # A high-pass filter (green trace) distorts the shape of a square wave by reducing its low frequency components. This is the cause of the \\"droop\\" seen on the top of the pulses. This \\"pulse distortion\\" can be very significant when a train of pulses must pass through an AC-coupled (high-pass filtered) amplifier. As the sine wave contains only one frequency, its shape is unaltered. # A low-pass filter (blue trace) rounds the pulses by removing the high frequency components. All systems are low pass to some extent. Note that the phase of the sine wave is different for the lowpass and the highpass cases, due to the phase distortion of the filters. # A slightly non-linear transfer function (purple), this one gently compresses the peaks of the sine wave, as may be typical of a tube audio amplifier. This generates small amounts of low order harmonics. # A hard-clipping transfer function (red) generates high order harmonics. Parts of the transfer function are flat, which indicates that all information about the input signal has been lost in this region. The transfer function of an ideal amplifier, with perfect gain and delay, is only an approximation. The true behavior of the system is usually different. Nonlinearities in the transfer function of an active device (such as vacuum tubes, transistors, and operational amplifiers) are a common source of non- linear distortion; in passive components (such as a coaxial cable or optical fiber), linear distortion can be caused by inhomogeneities, reflections, and so on in the propagation path. =Amplitude distortion= Amplitude distortion is distortion occurring in a system, subsystem, or device when the output amplitude is not a linear function of the input amplitude under specified conditions. =Harmonic distortion= Harmonic distortion adds overtones that are whole number multiples of a sound wave's frequencies. Nonlinearities that give rise to amplitude distortion in audio systems are most often measured in terms of the harmonics (overtones) added to a pure sinewave fed to the system. Harmonic distortion may be expressed in terms of the relative strength of individual components, in decibels, or the root mean square of all harmonic components: Total harmonic distortion (THD), as a percentage. The level at which harmonic distortion becomes audible depends on the exact nature of the distortion. Different types of distortion (like crossover distortion) are more audible than others (like soft clipping) even if the THD measurements are identical. Harmonic distortion in radio frequency applications is rarely expressed as THD. =Frequency response distortion= Non-flat frequency response is a form of distortion that occurs when different frequencies are amplified by different amounts in a filter. For example, the non-uniform frequency response curve of AC-coupled cascade amplifier is an example of frequency distortion. In the audio case, this is mainly caused by room acoustics, poor loudspeakers and microphones, long loudspeaker cables in combination with frequency dependent loudspeaker impedance, etc. =Phase distortion= This form of distortion mostly occurs due to electrical reactance. Here, all the components of the input signal are not amplified with the same phase shift, hence making some parts of the output signal out of phase with the rest of the output. =Group delay distortion= Can be found only in dispersive media. In a waveguide, phase velocity varies with frequency. In a filter, group delay tends to peak near the cut-off frequency, resulting in pulse distortion. When analog long distance trunks were commonplace, for example in 12 channel carrier, group delay distortion had to be corrected in repeaters. Correction of distortion As the system output is given by y(t) = F(x(t)), then if the inverse function F‚àí1 can be found, and used intentionally to distort either the input or the output of the system, then the distortion is corrected. An example of a similar correction is where LP/vinyl recordings or FM audio transmissions are deliberately pre-emphasised by a linear filter, the reproducing system applies an inverse filter to make the overall system undistorted. Correction is not possible if the inverse does not exist‚Äîfor instance if the transfer function has flat spots (the inverse would map multiple input points to a single output point). This produces an uncorrectable loss of information. Such a situation can occur when an amplifier is overdriven‚Äîcausing clipping or slew rate distortion when, for a moment, the amplifier characteristics alone and not the input signal determine the output. =Cancellation of even-order harmonic distortion= Many symmetrical electronic circuits reduce the magnitude of even harmonics generated by the non-linearities of the amplifier's components, by combining two signals from opposite halves of the circuit where distortion components that are roughly the same magnitude but out of phase. Examples include push- pull amplifiers and long-tailed pairs. Teletypewriter or modem signaling In binary signaling such as FSK, distortion is the shifting of the significant instants of the signal pulses from their proper positions relative to the beginning of the start pulse. The magnitude of the distortion is expressed in percent of an ideal unit pulse length. This is sometimes called bias distortion. Telegraphic distortion is a similar and older problem, distorting the ratio between mark and space intervals. Distortion in art In the art world, a distortion is any change made by an artist to the size, shape or visual character of a form to express an idea, convey a feeling or enhance visual impact. Often referred to as \\"abstraction,\\" examples of distortion include \\"The Weeping Woman\\" by Picasso and \\"The Adoration of the Shepherds\\" by El Greco. Audio distortion A graph of a waveform and the distorted version of the same waveform With respect to audio, distortion refers to any kind of deformation of an output waveform compared to its input, usually clipping, harmonic distortion, or intermodulation distortion (mixing phenomena) caused by non-linear behavior of electronic components and power supply limitations.Audio Electronics by John Linsley Hood; page 162 Terms for specific types of nonlinear audio distortion include: crossover distortion and slew-induced distortion (SID). Other forms of audio distortion are non-flat frequency response, compression, modulation, aliasing, quantization noise, wow and flutter from analog media such as vinyl records and magnetic tape. The human ear cannot hear phase distortion, except that it may affect the stereo imaging. In most fields, distortion is characterized as unwanted change to a signal. Distortion in music is often intentionally used as an effect when applied to an electric guitar signal in styles of rock music such as heavy metal and punk rock. Optics In optics, image/optical distortion is a divergence from rectilinear projection caused by a change in magnification with increasing distance from the optical axis of an optical system. Map projections In cartography, a distortion is the misrepresentation of the area or shape of a feature. The Mercator projection, for example, distorts by exaggerating the size of regions at high latitude. See also * Aliasing * Attenuation distortion * Audio system measurements * Bias distortion * Distortion synthesis * Fading * Image warping * Lossy compression References Category:Audio amplifier specifications Category:Audio effects Category:Cartography Category:Optics Category:Effects units ","title":"Distortion"},{"id":"41053","text":"In telecommunication, distortion-limited operation is the condition prevailing when distortion of a received signal, rather than its attenuated amplitude (or power), limits performance under stated operational conditions and limits. Note: Distortion-limited operation is reached when the system distorts the shape of the waveform beyond specified limits. For linear systems, distortion- limited operation is equivalent to bandwidth-limited operation. References Category:Telecommunications engineering ","title":"Distortion-limited operation"},{"id":"41055","text":"In telecommunication, a distributed-queue dual-bus network (DQDB) is a distributed multi-access network that (a) supports integrated communications using a dual bus and distributed queuing, (b) provides access to local or metropolitan area networks, and (c) supports connectionless data transfer, connection-oriented data transfer, and isochronous communications, such as voice communications. IEEE 802.6 is an example of a network providing DQDB access methods.  Concept of operation  The DQDB Medium Access Control (MAC) algorithm is generally credited to Robert Newman who developed this algorithm in his PhD thesis in the 1980s at the University of Western Australia. To appreciate the innovative value of the DQDB MAC algorithm, it must be seen against the background of LAN protocols at that time, which were based on broadcast (such as ethernet IEEE 802.3) or a ring (like token ring IEEE 802.5 and FDDI). The DQDB may be thought of as two token rings, one carrying data in each direction around the ring. This improves reliability which is important in Metropolitan Area Networks (MAN), where repairs may take longer than in a LAN and Wi-Fi because the damage may be inaccessible. The DQDB standard IEEE 802.6 was developed while ATM (Broadband ISDN) was still in early development, but there was strong interaction between the two standards. ATM cells and DQDB frames were harmonized. They both settled on essentially a 48-byte data frame with a 5-byte header. In the DQDB algorithm, a distributed queue was implemented by communicating queue state information via the header. Each node in a DQDB network maintains a pair of state variables which represent its position in the distributed queue and the size of the queue. The headers on the reverse bus communicated requests to be inserted in the distributed queue so that upstream nodes would know that they should allow DQDB cells to pass unused on the forward bus. The algorithm was remarkable for its extreme simplicity. Currently DQDB systems are being installed by many carriers in entire cities, with lengths that reach up to with speeds of a DS3 line (44.736 Mbit/s). Other implementations use optical fiber for a length of up to 100 km and speeds around 150 Mbit/s.  References  Category:Metropolitan area networks Category:Local area networks Category:Link protocols ","title":"Distributed-queue dual-bus"},{"id":"41056","text":"Distributed switching is an architecture in which multiple processor- controlled switching units are distributed. There is often a hierarchy of switching elements, with a centralized host switch and with remote switches located close to concentrations of users.  Use in telephony networks  Distributed switching is often used in telephone networks, though it is often called host-remote switching. In rural areas, population centers tend to be too small for economical deployment of a full-featured dedicated telephone exchange, and distances between these centers make transmission costs relatively high. Normal telephone traffic patterns show that most calling is done between people in a community of interest, in this case a geographical one: the population center. Use of distributed switching allows for the majority of calls that are local to that population center to be switched there without needing to be transported to and from the host switch. The host switch provides connectivity between the remote switches and to the larger network, and the host may also directly handle some rare and complex call types (conference calling, for example) that the remote itself is not equipped to handle. Host switches also perform OAM&P; (Operation, Administration, Maintenance, and Provisioning) functions, including billing, for the entire cluster of the host and its remote switches. A key capability of a remote switch is the ability to act in emergency standalone (ESA) mode, wherein local calls can still be placed even in the event that the connection between that remote and the host has been lost. In this mode, only local calling is available anyway, so the billing capability of the host switch is not required. ESA is increasingly available on digital loop carrier platforms as well as on purpose-built remote switches in order to improve the scope of their utility.  Use within telecommunications equipment platforms  Many data-centric telecommunications platforms such as routers and Ethernet switches utilize distributed switching on separate cards within an equipment chassis. Even when this is used, it is common to have a centralized switching fabric to interconnect the distributed switches. This architecture has become less common as backplane bus speeds and centralized switch fabric capacities have increased.  See also  *Remote Digital Terminal *Remote concentrator  References  * From Host-Remote to Next-Generation - a white paper by MetaSwitch * Nortel RSC-S Overview * Lucent 5E-XC Standalone Remote Switches description * Category:Local loop Category:Telephone exchanges ","title":"Distributed switching"},{"id":"41057","text":"In telecommunication, a disturbance voltage is an unwanted voltage induced in a system by natural or man-made sources. In telecommunications systems, the disturbance voltage creates currents that limit or interfere with the interchange of information. An example of a disturbance voltage is a voltage that produces (a) false signals in a telephone, (b) Noise (radio) in a radio receiver, or (c) distortion in a received signal. References * Category:Electrical parameters Category:Telecommunications engineering Category:Noise (electronics) ","title":"Disturbance voltage"},{"id":"41058","text":"In telecommunication, diurnal phase shift is the phase shift of electromagnetic signals associated with daily changes in the ionosphere. The major changes usually occur during the period of time when sunrise or sunset is present at critical points along the path. Significant phase shifts may occur on paths wherein a reflection area of the path is subject to a large tidal range. In cable systems, significant phase shifts can be occasioned by diurnal temperature variance. See also *Terminator (solar) - \\"grey line\\" References Category:Radio frequency propagation ","title":"Diurnal phase shift"},{"id":"41061","text":"U.S. Naval Observatory in Washington D.C., which provides the time standard for the U.S. Department of Defense.USNO Master Clock The rack mounted units in the background are caesium beam clocks. The black units in the foreground are hydrogen maser standards. The Department of Defense master clock is the atomic master clock to which time and frequency measurements for the United States Department of Defense are referenced. Located in Washington D.C., the U.S. Naval Observatory master clock is designated as the \\"DOD Master Clock\\". It is one of the two standard time and frequency references for the U.S. Government in accordance with Federal Standard 1002-A. The other standard time and frequency reference for the U.S. Government is the National Institute of Standards and Technology (NIST) master clock. In 2018, it was proposed to replace the existing Clock House building it's housed in, designed by Richard Morris Hunt, with a new facility. The U.S. Naval Observatory also maintains an alternate clock designated \\"USNO Alternate Master Clock\\" at Schriever Air Force Base, Colorado. References Category:Clocks in the United States Category:United States Department of Defense ","title":"Department of Defense master clock"},{"id":"41062","text":"For two connected exchanges in a communications network, a double-ended synchronization (also called double-ended control) is a synchronization control scheme in which the phase error signals used to control the clock at one telephone exchange are derived by comparison with the phase of the incoming digital signal and the phase of the internal clocks at both exchanges. References * Category:Telecommunications techniques Category:Synchronization ","title":"Double-ended synchronization"},{"id":"41063","text":"Double-sideband reduced carrier transmission (DSB-RC): transmission in which (a) the frequencies produced by amplitude modulation are symmetrically spaced above and below the carrier and (b) the carrier level is reduced for transmission at a fixed level below that which is provided to the modulator. Note: In DSB-RC transmission, the carrier is usually transmitted at a level suitable for use as a reference by the receiver, except for the case in which it is reduced to the minimum practical level, i.e. the carrier is suppressed. See also *Double-sideband suppressed-carrier transmission References * Category:Radio modulation modes ","title":"Double-sideband reduced-carrier transmission"},{"id":"41064","text":"Double-sideband suppressed-carrier transmission (DSB-SC) is transmission in which frequencies produced by amplitude modulation (AM) are symmetrically spaced above and below the carrier frequency and the carrier level is reduced to the lowest practical level, ideally being completely suppressed. In the DSB-SC modulation, unlike in AM, the wave carrier is not transmitted; thus, much of the power is distributed between the side bands, which implies an increase of the cover in DSB-SC, compared to AM, for the same power use DSB-SC transmission is a special case of double-sideband reduced carrier transmission. It is used for radio data systems. This mode is frequently used in Amateur radio voice communications, especially on High-Frequency bands. Spectrum DSB-SC is basically an amplitude modulation wave without the carrier, therefore reducing power waste, giving it a 50% efficiency. This is an increase compared to normal AM transmission (DSB) that has a maximum efficiency of 33.333%, since 2/3 of the power is in the carrier which conveys no useful information and both sidebands containing identical copies of the same information. Single Side Band Suppressed Carrier (SSB-SC) is 100% efficient. Spectrum plot of a DSB-SC signal: Image:Spectrum DSBSC.svg Generation DSB-SC is generated by a mixer. This consists of a message signal multiplied by a carrier signal. The mathematical representation of this process is shown below, where the product-to-sum trigonometric identity is used. : \\\\underbrace{V_m \\\\cos \\\\left( \\\\omega_m t \\\\right)}_{\\\\mbox{Message}} \\\\times \\\\underbrace{V_c \\\\cos \\\\left( \\\\omega_c t \\\\right)}_{\\\\mbox{Carrier}} = \\\\underbrace{\\\\frac{V_m V_c}{2} \\\\left[ \\\\cos\\\\left(\\\\left( \\\\omega_m + \\\\omega_c \\\\right)t\\\\right) + \\\\cos\\\\left(\\\\left( \\\\omega_m - \\\\omega_c \\\\right)t\\\\right) \\\\right]}_{\\\\mbox{Modulated Signal}} Image:DSBSC Modulation.svg Demodulation Demodulation is done by multiplying the DSB-SC signal with the carrier signal just like the modulation process. This resultant signal is then passed through a low pass filter to produce a scaled version of the original message signal. : \\\\overbrace{\\\\frac{V_m V_c}{2} \\\\left[ \\\\cos\\\\left(\\\\left( \\\\omega_m + \\\\omega_c \\\\right)t\\\\right) + \\\\cos\\\\left(\\\\left( \\\\omega_m - \\\\omega_c \\\\right)t\\\\right) \\\\right]}^{\\\\mbox{Modulated Signal}} \\\\times \\\\overbrace{V'_c \\\\cos \\\\left( \\\\omega_c t \\\\right)}^{\\\\mbox{Carrier}} ::= \\\\left(\\\\frac{1}{2}V_c V'_c\\\\right)\\\\underbrace{V_m \\\\cos(\\\\omega_m t)}_{\\\\text{original message}} + \\\\frac{1}{4}V_c V'_c V_m \\\\left[\\\\cos((\\\\omega_m + 2\\\\omega_c)t) + \\\\cos((\\\\omega_m - 2\\\\omega_c)t)\\\\right] The equation above shows that by multiplying the modulated signal by the carrier signal, the result is a scaled version of the original message signal plus a second term. Since \\\\omega_c \\\\gg \\\\omega_m, this second term is much higher in frequency than the original message. Once this signal passes through a low pass filter, the higher frequency component is removed, leaving just the original message. =Distortion and attenuation= For demodulation, the demodulation oscillator's frequency and phase must be exactly the same as the modulation oscillator's, otherwise, distortion and/or attenuation will occur. To see this effect, take the following conditions: *Message signal to be transmitted: f(t) *Modulation (carrier) signal: V_c\\\\cos(\\\\omega_c t) *Demodulation signal (with small frequency and phase deviations from the modulation signal): V'_c\\\\cos\\\\left[(\\\\omega_c+\\\\Delta\\\\omega)t + \\\\theta\\\\right] The resultant signal can then be given by :f(t) \\\\times V_c\\\\cos(\\\\omega_c t) \\\\times V'_c\\\\cos\\\\left[(\\\\omega_c+\\\\Delta\\\\omega)t + \\\\theta\\\\right] ::=\\\\frac{1}{2}V_c V'_c f(t) \\\\cos\\\\left(\\\\Delta\\\\omega\\\\cdot t+\\\\theta\\\\right) + \\\\frac{1}{2}V_c V'_c f(t) \\\\cos\\\\left[(2\\\\omega_c+\\\\Delta\\\\omega)t+\\\\theta\\\\right] ::\\\\xrightarrow{\\\\text{After low pass filter}} \\\\frac{1}{2}V_c V'_c f(t) \\\\cos\\\\left(\\\\Delta\\\\omega\\\\cdot t+\\\\theta\\\\right) The \\\\cos\\\\left(\\\\Delta\\\\omega\\\\cdot t+\\\\theta\\\\right) terms results in distortion and attenuation of the original message signal. In particular, if the frequencies are correct, but the phase is wrong, contribution from \\\\theta is a constant attenuation factor, also \\\\Delta\\\\omega\\\\cdot t represents a cyclic inversion of the recovered signal, which is a serious form of distortion. File:Demodulation distortion diagram.png  How it works  This is best shown graphically. Below is a message signal that one may wish to modulate onto a carrier, consisting of a couple of sinusoidal components with frequencies respectively 800 Hz and 1200 Hz. Image:DSBSC Message Signal.png The equation for this message signal is s(t) = \\\\frac{1}{2}\\\\cos\\\\left(2\\\\pi 800 t\\\\right) - \\\\frac{1}{2}\\\\cos\\\\left( 2\\\\pi 1200 t\\\\right). The carrier, in this case, is a plain 5 kHz (c(t) = \\\\cos\\\\left( 2\\\\pi 5000 t \\\\right)) sinusoid‚Äîpictured below. Image:DSBSC Carrier Signal.png The modulation is performed by multiplication in the time domain, which yields a 5 kHz carrier signal, whose amplitude varies in the same manner as the message signal. Image:DSBSC Modulated Output.png x(t) = \\\\underbrace{\\\\cos\\\\left( 2\\\\pi 5000 t \\\\right)}_\\\\mbox{Carrier} \\\\times \\\\underbrace{\\\\left[\\\\frac{1}{2}\\\\cos\\\\left(2\\\\pi 800 t\\\\right) - \\\\frac{1}{2}\\\\cos\\\\left( 2\\\\pi 1200 t\\\\right)\\\\right]}_\\\\mbox{Message Signal} The name \\"suppressed carrier\\" comes about because the carrier signal component is suppressed‚Äîit does not appear in the output signal. This is apparent when the spectrum of the output signal is viewed. In the picture shown below we see four peaks, the two peaks below 5000 Hz are the lower sideband (LSB) and the two peaks above 5000 Hz are the upper sideband (USB), but there is no peak at the 5000 Hz mark, which is the frequency of the suppressed carrier. Image:DSBSC Spectrum.png References External links *A DSBSC generation and demodulation instrument is described as side application of a commercial lock-in amplifier in Double-sideband Suppressed- carrier Modulation. Category:Radio modulation modes ","title":"Double-sideband suppressed-carrier transmission"},{"id":"41067","text":"Drift or Drifts may refer to: Geography  * Drift, Kentucky, unincorporated community in the United States * In Cornwall, England: ** Drift, Cornwall, village ** Drift Reservoir, associated with the village  Science and technology  * Directional Recoil Identification from Tracks, dark matter experiment * Drift pin, metalworking tool for enlarging and aligning holes * Drift (geology), deposited material of glacial origin * Drift, linear term of a stochastic process * Incremental changes: ** Drift (linguistics), type of language change ** Genetic drift, change in allele frequency ** Drift (telecommunication), long-term change in an attribute of a system or equipment Film and television * Drift (film series), 2006‚Äì2008 film series by Futoshi Jinno * Drift, 2006 TV crime drama film directed by Paul W.S. Anderson * Drift, fictional technology system that links the minds of two Jaeger pilots in the 2013 sci-fi film Pacific Rim and its sequel * Drift (2013 Australian film), film starring Sam Worthington * Drift (2013 Belgian film), art house film * Drift (2015 film), Swiss film * Drift (2017 film), German film * Drift, 2007 experimental short film by Max Hattler Books * Drift (novel), a 2002 Doctor Who novel * Drift: The Unmooring of American Military Power, a book by Rachel Maddow * Plot drift, when a story deviates unexpectedly from its initial direction, in writing, television, or other media. Music * The Drift (band), American post-rock band * Songs: ** \\"Drift\\", 1985 song from work ‚Äò‚ÄôSecret‚Äô‚Äô ** \\"Drift\\" (Emily Osment song) (2011) ** \\"Drift\\", end credits song of 2013 film Pacific Rim * Albums/EPs: ** Drift (Flotsam and Jetsam album) (1995) ** The Drift, album by Scott Walker (2006) ** Drift (Ken Block album) (2008) ** Drift (Nosaj Thing album) (2009) ** The Drift (EP), by Michelle Channel and Arjun Singh (2014) ** Drift (Erra album) (2016) ** Drift (Underworld project), ongoing music-and-video experiment by that band See also * Daventry International Rail Freight Terminal (DIRFT), a rail-road intermodal freight terminal in Northamptonshire, England * D√©rive, an unplanned journey through a landscape * Drifter (disambiguation) * Drifting (disambiguation) * Velddrif, a town in South Africa * * ","title":"Drift"},{"id":"41068","text":"Water drops falling from a tap. Surface tension prevents the droplet from being cut by a knife Rain water flux from a canopy. Among the forces that govern drop formation: surface tension, cohesion, Van der Waals force , Plateau‚ÄìRayleigh instability. A drop or droplet is a small column of liquid, bounded completely or almost completely by free surfaces. A drop may form when liquid accumulates at the lower end of a tube or other surface boundary, producing a hanging drop called a pendant drop. Drops may also be formed by the condensation of a vapor or by atomization of a larger mass of liquid.  Surface tension  Drop of water bouncing on a water surface subject to vibrations The pendant drop test illustrated. Liquid forms drops because the liquid exhibits surface tension. A simple way to form a drop is to allow liquid to flow slowly from the lower end of a vertical tube of small diameter. The surface tension of the liquid causes the liquid to hang from the tube, forming a pendant. When the drop exceeds a certain size it is no longer stable and detaches itself. The falling liquid is also a drop held together by surface tension. = Viscosity and pitch drop experiments= Some substances that appear to be solid, can be shown to instead be extremely viscous liquids, because they form drops and display droplet behavior. In the famous pitch drop experiments, pitch ‚Äì a substance somewhat like solid bitumen ‚Äì is shown to be a liquid in this way. Pitch in a funnel slowly forms droplets, each droplet taking about 10 years to form and break off.  Pendant drop test  In the pendant drop test, a drop of liquid is suspended from the end of a tube or by any surface by surface tension. The force due to surface tension is proportional to the length of the boundary between the liquid and the tube, with the proportionality constant usually denoted \\\\gamma. Since the length of this boundary is the circumference of the tube, the force due to surface tension is given by : \\\\,F_{\\\\gamma} = \\\\pi d \\\\gamma where d is the tube diameter. The mass m of the drop hanging from the end of the tube can be found by equating the force due to gravity (F_{g} = mg) with the component of the surface tension in the vertical direction (F_{\\\\gamma} \\\\sin \\\\alpha) giving the formula : \\\\,mg = \\\\pi d \\\\gamma \\\\sin \\\\alpha where Œ± is the angle of contact with the tube, and g is the acceleration due to gravity. The limit of this formula, as Œ± goes to 90¬∞, gives the maximum weight of a pendant drop for a liquid with a given surface tension, \\\\gamma. : \\\\,mg = \\\\pi d \\\\gamma This relationship is the basis of a convenient method of measuring surface tension, commonly used in the petroleum industry. More sophisticated methods are available to take account of the developing shape of the pendant as the drop grows. These methods are used if the surface tension is unknown.  Drop adhesion to a solid  The drop adhesion to a solid can be divided into two categories: lateral adhesion and normal adhesion. Lateral adhesion resembles friction (though tribologically lateral adhesion is a more accurate term) and refers to the force required to slide a drop on the surface, namely the force to detach the drop from its position on the surface only to translate it to another position on the surface. Normal adhesion is the adhesion required to detach a drop from the surface in the normal direction, namely the force to cause the drop to fly off from the surface. The measurement of both adhesion forms can be done with the Centrifugal Adhesion Balance (CAB). The CAB uses a combination of centrifugal and gravitational forces to obtain any ratio of lateral and normal forces. For example, it can apply a normal force at zero lateral force for the drop to fly off away from the surface in the normal direction or it can induce a lateral force at zero normal force (simulating zero gravity).  Droplet  The term droplet is a diminutive form of 'drop' ‚Äì and as a guide is typically used for liquid particles of less than 500 Œºm diameter. In spray application, droplets are usually described by their perceived size (i.e., diameter) whereas the dose (or number of infective particles in the case of biopesticides) is a function of their volume. This increases by a cubic function relative to diameter; thus a 50 Œºm droplet represents a dose in 65 pl and a 500 Œºm drop represents a dose in 65 nanolitres.  Speed  A droplet with a diameter of 3 mm has a terminal velocity of approximately 8 m/s. Drops smaller than in diameter will attain 95% of their terminal velocity within . But above this size the distance to get to terminal velocity increases sharply. An example is a drop with a diameter of that may achieve this at .  Optics  Due to the different refractive index of water and air, refraction and reflection occur on the surfaces of raindrops, leading to rainbow formation.  Sound  The major source of sound when a droplet hits a liquid surface is the resonance of excited bubbles trapped underwater. These oscillating bubbles are responsible for most liquid sounds, such as running water or splashes, as they actually consist of many drop-liquid collisions. =\\"Dripping tap\\" noise prevention= Reducing the surface tension of a body of liquid makes possible to reduce or prevent noise due to droplets falling into it. This would involve adding soap, detergent or a similar substance to water. The reduced surface tension reduces the noise from dripping.  Shape  188x188px The classic shape associated with a drop (with a pointy end in its upper side) comes from the observation of a droplet clinging to a surface. The shape of a drop falling through a gas is actually more or less spherical for drops less than 2 mm in diameter. Larger drops tend to be flatter on the bottom part due to the pressure of the gas they move through. As a result, as drops get larger, a concave depression forms which leads to the eventual breakup of the drop. = Capillary length = The capillary length is a length scaling factor that relates gravity and surface tension, and is directly responsible for the shape a droplet for a specific fluid will take. The capillary length stems from the Laplace pressure, using the radius of the droplet. Using the capillary length we can define microdrops and macrodrops. Microdrops are droplets with radius smaller than the capillary length, where the shape of the droplet is governed solely by surface tension and they form a spherical cap shape. If a droplet has a radius larger than the capillary length, they are known as macrodrops and the gravitational forces will dominate. Macrodrops will be 'flattened' by gravity and the height of the droplet will be reduced. alt=  Size  Raindrop sizes typically range from 0.5 mm to 4 mm, with size distributions quickly decreasing past diameters larger than 2-2.5 mm. Scientists traditionally thought that the variation in the size of raindrops was due to collisions on the way down to the ground. In 2009 French researchers succeeded in showing that the distribution of sizes is due to the drops' interaction with air, which deforms larger drops and causes them to fragment into smaller drops, effectively limiting the largest raindrops to about 6 mm diameter. However, drops up to 10 mm (equivalent in volume to a sphere of radius 4.5 mm) are theoretically stable and could be levitated in a wind tunnel. The largest recorded raindrop was 8.8 mm in diameter, located at the base of a cumulus congestus cloud in the vicinity of Kwajalein Atoll in July 1999. A raindrop of identical size was detected over northern Brazil in September 1995. = Standardized droplet sizes in medicine= In medicine, this property is used to create droppers and IV infusion sets which have a standardized diameter, in such a way that 1 millilitre is equivalent to 20 drops. When smaller amounts are necessary (such as paediatrics), microdroppers or paediatric infusion sets are used, in which 1 millilitre = 60 microdrops.  Gallery  Image:Blue Droplet.jpgBlue dye being dropped in a saucer of milk. Image:2006-02-13 Drop- impact.jpgImpact of a drop of water. Image:2006-01-28 drop-impact backjet.jpgBackjet from drop impact. Image:Water splashes 001.jpgA drop of water hitting a metal surface/ crown formation due to splashing of droplet. Image:Post-splash with droplets.jpgA drop of water hitting a wet metal surface and ejecting more droplets, which become water globules and skim across the surface of the water. Image:Water drop on a leaf.jpgA drop of water on a leaf / Hydrophobic effect/ Partial Wetting. Image:Water droplet backjet.JPGA triple backjet after impact. Image:Raindrop on a fern frond.jpgPhoto of a raindrop on a fern frond. Image:2006-01-21 Detaching drop.jpgDetaching drop. Image:Showerheadandwaterdroplets.jpgWater droplets forming out of a shower head. Image:Asteraceae03.JPGA drop of water on an Asteraceae Image:A small flower refracted in rain droplets.jpgDroplets of water refracting a small flower. Image:Water Drop on rose leaf.JPGA raindrop on a leaf Image:Water_Droplets_Background.JPGWater droplets on glass. Image:Fountain water droplets.jpgFountain water droplets as seen in very short exposure Image:Water drops on rose leaf.jpgRain droplets on Rose plant leaf See also * Pitch drop experiment * Rain References External links * Liquid Sculpture ‚Äì pictures of drops * Liquid Art ‚Äì Galleries of fine art droplet photography * (Greatly varying) calculation of water waste from dripping tap: , Category:Liquids Category:Fluid dynamics Category:Articles containing video clips Category:Alcohol measurement ps:⁄Öÿß⁄Ö⁄©€ê ","title":"Drop (liquid)"},{"id":"41069","text":"In a multichannel transmission system, drop and insert is a process that diverts (drop) a portion of the multiplexed aggregate signal at an intermediate point, and introduces (insert) a different signal for subsequent transmission in the same position. Drop and insert is practiced, for example, in time-division multiplexing (TDM) when a time slot or frequency band is replaced from another source. The diverted signal may be demodulated or reinserted into another transmission system in the same or another time slot or frequency band. The time slot or frequency band vacated by the diverted signal need not necessarily be reoccupied by another signal. Likewise, a previously unoccupied time slot or frequency band may be occupied by a signal inserted at the drop-and-insert point. Signals not of interest at the drop- and-insert point are not diverted. References Category:Multiplexing ","title":"Drop and insert"},{"id":"41070","text":"Dropout or drop out may refer to: * Dropping out, prematurely leaving high school, college or university  Arts and entertainment  =Film and television= * Dropout (film), a 1970 Italian drama * \\"The Dropout\\", an 1970 episode of The Brady Bunch *The Dropout (podcast), 2019 true crime podcast * The Dropout (TV series), an upcoming American TV drama series =Music= * \\"Drop Out\\" (Lil Pump song), 2019 * \\"Drop Out,\\" a song by Rocket from the Crypt from the 1995 album Scream, Dracula, Scream! * \\"Drop Out\\", a song by Converge from the 2004 album You Fail Me * \\"Drop Out\\", music of Dance Dance Revolution Extreme * Drop Out with The Barracudas, by The Barracudas, 1981  Science and technology * Dropout (astronomy), a radiation source whose radiation intensity falls off sharply * Dropout (bicycle part), a type of fork end * Dropout (communications), a momentary loss of signal * Dropout (neural networks), a regularization technique for reducing overfitting Other uses * Dropout (streaming platform), an American subscription media service provider  See also   Drop out ceiling, beneath existing fire sprinklers * Turn on, tune in, drop out, a counterculture-era phrase popularized by Timothy Leary in 1966. ","title":"Dropout"},{"id":"41071","text":"DTE may refer to: * Data terminal equipment, an end instrument used in telecommunication and data transmission * Distance to empty, a feature in an automobile electronic instrument cluster * Dithioerythritol, a chemical * DTE (direct to edit), a digital video recording method * DTE80, the Microsoft Development Environment 8.0 Extensibility namespace * DTE Energy, a Detroit, Michigan-based utility * Dora the Explorer, a children's animated television show. * Dual-Tile encoding, another name for byte pair encoding * Directorate of Technical Education, Maharashtra, an Indian state government agency for higher education. * Department of Technical Education, a higher education governance body under the government of Kerala, India See also * Down to Earth (disambiguation) ","title":"DTE"},{"id":"41072","text":"In telecommunication, the term dual access has the following meanings: #The connection of a user to two switching centers by separate access lines using a single message routing indicator or telephone number. #In satellite communications, the transmission of two carriers simultaneously through a single communication satellite repeater. Also, network hardware company D-Link has named technology which allows two simultaneous connections over one cable, for example 1) Internet and 2) provider's local FTP or game servers or IPTV data flow. References Category:Network access ","title":"Dual access"},{"id":"41073","text":"4000-series logic ICs in 0.3\\" wide 14-pin plastic DIP packages (DIP-14N), also known as PDIP (Plastic DIP) EPROM ICs in 0.6\\" wide ceramic DIP-40, DIP-32, DIP-28, DIP-24 packages, also known as CDIP (Ceramic DIP) 8 contact DIP switch with 0.3\\" wide 16-pin (DIP-16N) footprint In microelectronics, a dual in-line package (DIP or DIL),see for instance or dual in-line pin package (DIPP)see for instance is an electronic component package with a rectangular housing and two parallel rows of electrical connecting pins. The package may be through- hole mounted to a printed circuit board (PCB) or inserted in a socket. The dual-inline format was invented by Don Forbes, Rex Rice and Bryant Rogers at Fairchild R&D; in 1964,Dummer, G.W.A. Electronic Inventions and Discoveries (2nd ed)., Pergamon Press, when the restricted number of leads available on circular transistor-style packages became a limitation in the use of integrated circuits.Jackson, Kenneth.A.; Schr√∂ter, Wolfgang Handbook of Semiconductor Technology, John Wiley & Sons, 2000 page 610 Increasingly complex circuits required more signal and power supply leads (as observed in Rent's rule); eventually microprocessors and similar complex devices required more leads than could be put on a DIP package, leading to development of higher-density chip carriers. Furthermore, square and rectangular packages made it easier to route printed-circuit traces beneath the packages. A DIP is usually referred to as a DIPn, where n is the total number of pins. For example, a microcircuit package with two rows of seven vertical leads would be a DIP14. The photograph at the upper right shows three DIP14 ICs. Common packages have as few as three and as many as 64 leads. Many analog and digital integrated circuit types are available in DIP packages, as are arrays of transistors, switches, light emitting diodes, and resistors. DIP plugs for ribbon cables can be used with standard IC sockets. DIP packages are usually made from an opaque molded epoxy plastic pressed around a tin-, silver-, or gold-plated lead frame that supports the device die and provides connection pins. Some types of IC are made in ceramic DIP packages, where high temperature or high reliability is required, or where the device has an optical window to the interior of the package. Most DIP packages are secured to a PCB by inserting the pins through holes in the board and soldering them in place. Where replacement of the parts is necessary, such as in test fixtures or where programmable devices must be removed for changes, a DIP socket is used. Some sockets include a zero insertion force mechanism. Variations of the DIP package include those with only a single row of pins, e.g. a resistor array, possibly including a heat sink tab in place of the second row of pins, and types with four rows of pins, two rows, staggered, on each side of the package. DIP packages have been mostly displaced by surface- mount package types, which avoid the expense of drilling holes in a PCB and which allow higher density of interconnections. Applications =Types of devices= An operating prototyped circuit on a solderless breadboard incorporating four DIP ICs, a DIP LED bargraph display (upper left), and a DIP 7-segment LED display (lower left). DIPs are commonly used for integrated circuits (ICs). Other devices in DIP packages include resistor networks, DIP switches, LED segmented and bargraph displays, and electromechanical relays. DIP connector plugs for ribbon cables are common in computers and other electronic equipment. Dallas Semiconductor manufactured integrated DIP real- time clock (RTC) modules which contained an IC chip and a non-replaceable 10-year lithium battery. DIP header blocks on to which discrete components could be soldered were used where groups of components needed to be easily removed, for configuration changes, optional features or calibration. =Uses= The original dual-in-line package was invented by Bryant \\"Buck\\" Rogers in 1964 while working for Fairchild Semiconductor. The first devices had 14 pins and looked much like they do today.Dummer, G.W.A. Electronic Inventions and Discoveries 2nd ed. Pergamon Press The rectangular shape allowed integrated circuits to be packaged more densely than previous round packages.Computer Museum retrieved April 16, 2008 The package was well-suited to automated assembly equipment; a PCB could be populated with scores or hundreds of ICs, then all the components on the circuit board could be soldered at one time on a wave soldering machine and passed on to automated testing machines, with very little human labor required. DIP packages were still large with respect to the integrated circuits within them. By the end of the 20th century, surface-mount packages allowed further reduction in the size and weight of systems. DIP chips are still popular for circuit prototyping on a breadboard because of how easily they can be inserted and utilized there. DIPs were the mainstream of the microelectronics industry in the 1970s and 1980s. Their use has declined in the first decade of the 21st century due to the emerging new surface-mount technology (SMT) packages such as plastic leaded chip carrier (PLCC) and small-outline integrated circuit (SOIC), though DIPs continued in extensive use through the 1990s, and still continue to be used substantially as the year 2011 passes. Because some modern chips are available only in surface-mount package types, a number of companies sell various prototyping adapters to allow those surface-mount devices (SMD) to be used like DIP devices with through-hole breadboards and soldered prototyping boards (such as stripboard and perfboard). (SMT can pose quite a problem, at least an inconvenience, for prototyping in general; most of the characteristics of SMT that are advantages for mass production are difficulties for prototyping.) For programmable devices like EPROMs and GALs, DIPs remained popular for many years due to their easy handling with external programming circuitry (i.e., the DIP devices could be simply plugged into a socket on the programming device.) However, with In-System Programming (ISP) technology now state of the art, this advantage of DIPs is rapidly losing importance as well. Through the 1990s, devices with fewer than 20 leads were manufactured in a DIP format in addition to the newer formats. Since about 2000, newer devices are often unavailable in the DIP format. =Mounting= DIPs can be mounted either by through-hole soldering or in sockets. Sockets allow easy replacement of a device and eliminates the risk of damage from overheating during soldering. Generally sockets were used for high-value or large ICs, which cost much more than the socket. Where devices would be frequently inserted and removed, such as in test equipment or EPROM programmers, a zero insertion force socket would be used. DIPs are also used with breadboards, a temporary mounting arrangement for education, design development or device testing. Some hobbyists, for one-off construction or permanent prototyping, use point-to-point wiring with DIPs, and their appearance when physically inverted as part of this method inspires the informal term \\"dead bug style\\" for the method. Image:DIP sockets.jpg0.3\\" wide DIP sockets with dual-wipe contacts for 16-, 14-, and 8-pin DIP ICs Image:DIL socket 16p.jpg0.3\\" wide 16-pin machined DIP socket with round pins for DIP-16 IC Image:Textoolfassung 28 (smial).jpgZero insertion force (ZIF) socket for 0.6\\" wide DIP-28W IC, commonly used on EPROM IC programmers Image:28 Pin IC Socket.jpg0.3\\" wide DIP socket for narrow DIP-28 IC, also known as DIP-28N, commonly used on older Arduino boards Image:Arduino UNO unpacked.jpgArduino UNO R2 board with ATmega328P 8-bit microcontroller in 28-pin IC socket Construction Side view of a dual in-line package (DIP) IC Dual in-line (DIP) integrated circuit metal tape base with contacts The body (housing) of a DIP containing an IC chip is usually made from molded plastic or ceramic. The hermetic nature of a ceramic housing is preferred for extremely high reliability devices. However, the vast majority of DIPs are manufactured via a thermoset molding process in which an epoxy mold compound is heated and transferred under pressure to encapsulate the device. Typical cure cycles for the resins are less than 2 minutes and a single cycle may produce hundreds of devices. The leads emerge from the longer sides of the package along the seam, parallel to the top and bottom planes of the package, and are bent downward approximately 90 degrees (or slightly less, leaving them angled slightly outward from the centerline of the package body). (The SOIC, the SMT package that most resembles a typical DIP, appears essentially the same, notwithstanding size scale, except that after being bent down the leads are bent upward again by an equal angle to become parallel with the bottom plane of the package.) In ceramic (CERDIP) packages, an epoxy or grout is used to hermetically seal the two halves together, providing an air and moisture tight seal to protect the IC die inside. Plastic DIP (PDIP) packages are usually sealed by fusing or cementing the plastic halves around the leads, but a high degree of hermeticity is not achieved because the plastic itself is usually somewhat porous to moisture and the process cannot ensure a good microscopic seal between the leads and the plastic at all points around the perimeter. However, contaminants are usually still kept out well enough that the device can operate reliably for decades with reasonable care in a controlled environment. Inside the package, the lower half has the leads embedded, and at the center of the package is a rectangular space, chamber, or void into which the IC die is cemented. The leads of the package extend diagonally inside the package from their positions of emergence along the periphery to points along a rectangular perimeter surrounding the die, tapering as they go to become fine contacts at the die. Ultra-fine bond wires (barely visible to the naked human eye) are welded between these die periphery contacts and bond pads on the die itself, connecting one lead to each bond pad, and making the final connection between the microcircuits and the external DIP leads. The bond wires are not usually taut but loop upward slightly to allow slack for thermal expansion and contraction of the materials; if a single bond wire breaks or detaches, the entire IC may become useless. The top of the package covers all of this delicate assemblage without crushing the bond wires, protecting it from contamination by foreign materials. Usually, a company logo, alphanumeric codes and sometimes words are printed on top of the package to identify its manufacturer and type, when it was made (usually as a year and a week number), sometimes where it was made, and other proprietary information (perhaps revision numbers, manufacturing plant codes, or stepping ID codes.) The necessity of laying out all of the leads in a basically radial pattern in a single plane from the die perimeter to two rows on the periphery of the package is the main reason that DIP packages with higher lead counts must have wider spacing between the lead rows, and it effectively limits the number of leads which a practical DIP package may have. Even for a very small die with many bond pads (e.g. a chip with 15 inverters, requiring 32 leads), a wider DIP would still be required to accommodate the radiating leads internally. This is one of the reasons that four-sided and multiple rowed packages, such as PGAs, were introduced (around the early 1980s). A large DIP package (such as the DIP64 used for the Motorola 68000 CPU) has long leads inside the package between pins and the die, making such a package unsuitable for high speed devices. Some other types of DIP devices are built very differently. Most of these have molded plastic housings and straight leads or leads that extend directly out of the bottom of the package. For some, LED displays particularly, the housing is usually a hollow plastic box with the bottom/back open, filled (around the contained electronic components) with a hard translucent epoxy material from which the leads emerge. Others, such as DIP switches, are composed of two (or more) plastic housing parts snapped, welded, or glued together around a set of contacts and tiny mechanical parts, with the leads emerging through molded-in holes or notches in the plastic. =Variants= Several PDIPs and CERDIPs. The large CERDIP in the foreground is an NEC 8080AF (Intel 8080-compatible) microprocessor. Several DIP variants for ICs exist, mostly distinguished by packaging material: * Ceramic Dual In-line Package (CERDIP or CDIP) * Plastic Dual In-line Package (PDIP) * Shrink Plastic Dual In-line Package (SPDIP) - A denser version of the PDIP with a 0.07 in (1.778 mm) lead pitch. * Skinny Dual In-line Package (SDIP or SPDIPFor instance, Microchip: http://www.microchip.com/packaging) - Sometimes used to refer to a \\"narrow\\" 0.300 in. (or 300 mil) wide DIP, normally when clarification is needed e.g. for DIP with 24 pins or more, which usually come in \\"wide\\" 0.600 in wide DIP package. An example of a typical proper full spec for a \\"narrow\\" DIP package would be 300 mil body width, pin pitch. EPROMs were sold in ceramic DIPs manufactured with a circular window of clear quartz over the chip die to allow the part to be erased by ultraviolet light. Often, the same chips were also sold in less expensive windowless PDIP or CERDIP packages as one-time programmable (OTP) versions. Windowed and windowless packages were also used for microcontrollers, and other devices, containing EPROM memory. Windowed CERDIP-packaged EPROMs were used for the BIOS ROM of many early IBM PC clones with an adhesive label covering the window to prevent inadvertent erasure through exposure to ambient light. Molded plastic DIPs are much lower in cost than ceramic packages; one 1979 study showed that a plastic 14 pin DIP cost around US$0.063 and a ceramic package cost US$0.82.Rao R. Tummala, Eugene J. Rymaszewski, Alan G. Klopfenstein Microelectronics Packaging Handbook: Semiconductor packaging, Springer, 1997 page 395 =Single in-line= Package sample for single in-line (SIL) devices A single in-line (pin) package (SIP or SIPP) has one row of connecting pins. It is not as popular as the DIP, but has been used for packaging RAM chips and multiple resistors with a common pin. As compared to DIPs with a typical maximum pin count of 64, SIPs have a typical maximum pin count of 24 with lower package costs.Pecht, M. (1994). Integrated circuit, hybrid, and multichip module package design guidelines. Wiley-IEEE. One variant of the single in-line package uses part of the lead frame for a heat sink tab. This multi-leaded power package is useful for such applications as audio power amplifiers, for example. =Quad in-line= A Rockwell 6502-based microcontroller in a QIP package Rockwell used a quad in-line package with 42 leads formed into staggered rows for their PPS-4 microprocessor family introduced in 1973, and other microprocessors and microcontrollers, some with higher lead counts, through the early 1990s. The QIP, sometimes called a QIL package, has the same dimensions as a DIL package, but the leads on each side are bent into an alternating zigzag configuration so as to fit four lines of solder pads (instead of two with a DIL). The QIL design increased the spacing between solder pads without increasing package size, for two reasons: # First it allowed more reliable soldering. This may seem odd today, given the far closer solder pad spacing in use now, but in the 1970s, the heyday of the QIL, bridging of neighbouring solder pads on DIL chips was an issue at times, # QIL also increased the possibility of running a copper track between 2 solder pads. This was very handy on the then standard single sided single layer PCBs. Some QIL packaged ICs had added heatsinking tabs, such as the HA1306.lamson.dnsdojo.com Intel and 3M developed the ceramic leadless quad in-line package (QUIP), introduced in 1979, to boost microprocessor density and economy.Intel & 3M Develop Package to Boost Microprocessor Density & Economy, Intelligent Machines Journal, March 14, 1979 The ceramic leadless QUIP is not designed for surface-mount use, and requires a socket. It was used by Intel for the iAPX 432 microprocessor chip set, and by Zilog for the Z8-02 external-ROM prototyping version of the Z8 microcontroller. =Lead count and spacing= Commonly found DIP packages that conform to JEDEC standards use an inter-lead spacing (lead pitch) of (JEDEC MS-001BA). Row spacing varies depending on lead counts, with 0.3 in. (7.62 mm) (JEDEC MS-001) or 0.6 inch (15.24 mm) (JEDEC MS-011) the most common. Less common standardized row spacings include 0.4 inch (10.16 mm) (JEDEC MS-010) and 0.9 inch (22.86 mm), as well as a row spacing of 0.3 inch, 0.6 inch or 0.75 inch with a 0.07 inch (1.778 mm) lead pitch. The former Soviet Union and Eastern bloc countries used similar packages, but with a metric pin-to-pin spacing of 2.5 mm rather than . The number of leads is always even. For 0.3 inch spacing, typical lead counts are 8, 14, 16, 18, and 28; less common are 4, 6, 20, and 24 lead counts. To have an even number of leads some DIPs have unused not connected (NC) leads to the internal chip, or are duplicated, e.g. two ground pins. For 0.6 inch spacing, typical lead counts are 24, 28, 32, and 40; less common are 36, 48, 52, and 64 lead counts. Some microprocessors, such as the Motorola 68000 and Zilog Z180, used lead counts as high as 64; this is typically the maximum number of leads for a DIP package. Orientation and lead numbering Pin numbering is counter-clockwise As shown in the diagram, leads are numbered consecutively from Pin 1. When the identifying notch in the package is at the top, Pin 1 is the top left corner of the device. Sometimes Pin 1 is identified with an indent or paint dot mark. For example, for a 14-lead DIP, with the notch at the top, the left leads are numbered from 1 to 7 (top to bottom) and the right row of leads are numbered 8 to 14 (bottom to top). Some DIP devices, such as segmented LED displays, relays, or those that replace leads with a heat sink fin, skip some leads; the remaining leads are numbered as if all positions had leads. In addition to providing for human visual identification of the orientation of the package, the notch allows automated chip-insertion machinery to confirm correct orientation of the chip by mechanical sensing. Descendants The SOIC (Small Outline IC), a surface- mount package which is currently very popular, particularly in consumer electronics and personal computers, is essentially a shrunk version of the standard IC PDIP, the fundamental difference which makes it an SMT device being a second bend in the leads to flatten them parallel to the bottom plane of the plastic housing. The SOJ (Small Outline J-lead) and other SMT packages with \\"SOP\\" (for \\"Small Outline Package\\") in their names can be considered further relatives of the DIP, their original ancestor. SOIC packages tend to have half the pitch of DIP, and SOP are half that, a fourth of DIP. (0.1\\"/2.54 mm, 0.05\\"/1.27 mm, and 0.025\\"/0.635 mm, respectively) Pin grid array (PGA) packages may be considered to have evolved from the DIP. PGAs with the same pin centers as most DIPs were popular for microprocessors from the early to mid-1980s through the 1990s. Owners of personal computers containing Intel 80286 through P5 Pentium processors may be most familiar with these PGA packages, which were often inserted into ZIF sockets on motherboards. The similarity is such that a PGA socket may be physically compatible with some DIP devices, though the converse is rarely true. See also * Chip carrier * DIP switch * Flatpack (electronics) * List of integrated circuit package dimensions * NORBIT 2 (a larger 19-pin DIP, introduced in 1967) * Pin grid array * QFP * Zig-zag in-line package  References  * Further reading * External links * DIP packages documentation, photos and videos Category:Chip carriers Category:CPU sockets ","title":"Dual in-line package"},{"id":"41075","text":"The word duct is derived from the Latin word for led/leading. It may refer to: * Duct (anatomy), various ducts in anatomy and physiology ** Tear duct, which carry tears to the eyes * Duct (HVAC), for transfer of air between spaces in a structure * Duct tape, a kind of adhesive tape * Ducted fan, motor for aircraft * Electrical bus duct, a metal enclosure for busbars * Duct (industrial exhaust), industrial exhaust duct system designed for low pressure-pneumatic convey of gas, fumes, dusts, shavings, and other pollutants from works space to atmosphere after cleaning and removal of contaminants * Atmospheric duct, a horizontal layer in the lower atmosphere in which the vertical refractive index gradients are such that radio signals (a) are guided or ducted, (b) tend to follow the curvature of the Earth, and (c) experience less attenuation in the ducts than they would if the ducts were not present ** Tropospheric ducting, a type of radio propagation in the troposphere that allows signals to travel unusually long distances ** Earth‚Äìionosphere waveguide, a type of atmospheric duct * Duct bank, a set of electrical conduits or telecommunications conduits, entering a building underground * Duct Publishing, an imprint of the German group VDM Publishing devoted to the reproduction of wikipedia content * Dispatchable Unit Control Table (DUCT) in z/Architecture See also * Ducked ","title":"Duct"},{"id":"41077","text":"A duplexer is an electronic device that allows bi-directional (duplex) communication over a single path. In radar and radio communications systems, it isolates the receiver from the transmitter while permitting them to share a common antenna. Most radio repeater systems include a duplexer. Duplexers can be based on frequency (often a waveguide filter), polarization (such as an orthomode transducer), or timing (as is typical in radar). Radar engineers have added the automatic switch (also called a duplexer) in the ... As soon as the transmitter stops sending a signal, the duplexer switches so that the receiver is now connected to the antenna. Types =Transmit-receive switch= TR duplex switching In radar, a transmit/receive (TR) switch alternately connects the transmitter and receiver to a shared antenna. In the simplest arrangement, the switch consists of a gas-discharge tube across the input terminals of the receiver. When the transmitter is active, the resulting high voltage causes the tube to conduct, shorting together the receiver terminals to protect it, while its complementary, the anti-transmit/receive (ATR) switch, is a similar discharge tube which decouples the transmitter from the antenna while not operating, to prevent it from wasting received energy. =Circulator= =Hybrid= A hybrid, such as a magic T, may be used as a duplexer by terminating the fourth port in a matched load. This arrangement suffers from the disadvantage that half of the transmitter power is lost in the matched load, while thermal noise in the load is delivered to the receiver. =Orthomode transducer= =Frequency domain= 190px In radio communications (as opposed to radar), the transmitted and received signals can occupy different frequency bands, and so may be separated by frequency- selective filters. These are effectively a higher-performance version of a diplexer, typically with a narrow split between the two frequencies in question (typically around 2%-5% for a commercial two-way radio system). With a duplexer the high- and low-frequency signals are traveling in opposite directions at the shared port of the duplexer. Modern duplexers often use nearby frequency bands, so the frequency separation between the two ports is also much less. For example, the transition between the uplink and downlink bands in the GSM frequency bands may be about one percent (915 MHz to 925 MHz). Significant attenuation (isolation) is needed to prevent the transmitter's output from overloading the receiver's input, so such duplexers employ multi-pole filters. Duplexers are commonly made for use on the 30-50 MHz (\\"low band\\"), 136-174 MHz (\\"high band\\"), 380-520 MHz (\\"UHF\\"), plus the 790‚Äì862 MHz (\\"800\\"), 896-960 MHz (\\"900\\") and 1215-1300 MHz (\\"1200\\") bands. There are two predominant types of duplexer in use - \\"notch duplexers\\", which exhibit sharp notches at the \\"unwanted\\" frequencies and only pass through a narrow band of wanted frequencies and \\"bandpass duplexers\\", which have wide- pass frequency ranges and high out-of-band attenuation. On shared-antenna sites, the bandpass duplexer variety is greatly preferred because this virtually eliminates interference between transmitters and receivers by removing out-of-band transmit emissions and considerably improving the selectivity of receivers. Most professionally engineered sites ban the use of notch duplexers and insist on bandpass duplexers for this reason. Commercial 19\\" rack mount antenna filter Isolation typical >75 dB Insertion Loss typical < 1.0 dB Note 1: A duplexer must be designed for operation in the frequency band used by the receiver and transmitter, and must be capable of handling the output power of the transmitter. Note 2: A duplexer must provide adequate rejection of transmitter noise occurring at the receive frequency, and must be designed to operate at, or less than, the frequency separation between the transmitter and receiver. Note 3: A duplexer must provide sufficient isolation to prevent receiver desensitization. Source: from Federal Standard 1037C History The first duplexers were invented for use on the electric telegraph and were known as duplex rather than duplexer. They were an early form of the hybrid coil. The telegraph companies were keen to have such a device since the ability to have simultaneous traffic in both directions had the potential to save the cost of thousands of miles of telegraph wire. The first of these devices was designed in 1853 by Julius Wilhelm Gintl of the Austrian State Telegraph. Gintl's design was not very successful. Further attempts were made by Carl Frischen of Hanover with an artificial line to balance the real line and Siemens & Halske, who bought and modified Frischen's design. The first really successful duplex was designed by Joseph Barker Stearns of Boston in 1872. This was further developed into the quadruplex telegraph by Thomas Edison. The device is estimated to have saved Western Union $500,000 per year in construction of new telegraph lines.Tom Standage, The Victorian Internet, ch. 11, Walker & Company, 2007 .George Bartlett Prescott, Electricity and the Electric Telegraph, pp. 792-793, New York: D. Appleton, 1877 References Category:Broadcast engineering Category:Radio electronics Category:Electronic circuits Category:Telegraphy ","title":"Duplexer"},{"id":"41078","text":"The duty cycle D is defined as the ratio between the pulse duration, or pulse width (PW) and the period (T) of a rectangular waveform Spectrum in relation to duty cycle A duty cycle or power cycle is the fraction of one period in which a signal or system is active. Duty cycle is commonly expressed as a percentage or a ratio. A period is the time it takes for a signal to complete an on-and-off cycle. As a formula, a duty cycle (%) may be expressed as: :D = \\\\frac{PW}{T} \\\\times 100\\\\% Equally, a duty cycle (ratio) may be expressed as: :D = \\\\frac{PW}{T} where D is the duty cycle, PW is the pulse width (pulse active time), and T is the total period of the signal. Thus, a 60% duty cycle means the signal is on 60% of the time but off 40% of the time. The \\"on time\\" for a 60% duty cycle could be a fraction of a second, a day, or even a week, depending on the length of the period. Duty cycles can be used to describe the percent time of an active signal in an electrical device such as the power switch in a switching power supply or the firing of action potentials by a living system such as a neuron. The duty factor for periodic signal expresses the same notion, but is usually scaled to a maximum of one rather than 100%. The duty cycle can also be notated as \\\\alpha.  Applications  = Electrical and electronics = In electronics, duty cycle is the percentage of the ratio of pulse duration, or pulse width (PW) to the total period (T) of the waveform. It is generally used to represent time duration of a pulse when it is high (1). In digital electronics, signals are used in rectangular waveform which are represented by logic 1 and logic 0. Logic 1 stands for presence of an electric pulse and 0 for absence of an electric pulse. For example, a signal (10101010) has 50% duty cycle, because the pulse remains high for 1/2 of the period or low for 1/2 of the period. Similarly, for pulse (10001000) the duty cycle will be 25% because the pulse remains high only for 1/4 of the period and remains low for 3/4 of the period. Electrical motors typically use less than a 100% duty cycle. For example, if a motor runs for one out of 100 seconds, or 1/100 of the time, then, its duty cycle is 1/100, or 1 percent. Pulse-width modulation (PWM) is used in a variety of electronic situations, such as power delivery and voltage regulation. In electronic music, music synthesizers vary the duty cycle of their audio-frequency oscillators to obtain a subtle effect on the tone colors. This technique is known as pulse-width modulation. In the printer / copier industry, the duty cycle specification refers to the rated throughput (that is, printed pages) of a device per month. In a welding power supply, the maximum duty cycle is defined as the percentage of time in a 10-minute period that it can be operated continuously before overheating. = Biological systems = The concept of duty cycles is also used to describe the activity of neurons and muscle fibers. In neural circuits for example, a duty cycle specifically refers to the proportion of a cycle period in which a neuron remains active. = Generation = One way to generate fairly accurate square wave signals with 1/n duty factor, where n is an integer, is to vary the duty cycle until the nth-harmonic is significantly suppressed. For audio-band signals, this can even be done \\"by ear\\"; for example, a -40dB reduction in the 3rd harmonic corresponds to setting the duty factor to 1/3 with a precision of 1% and -60 dB reduction corresponds to a precision of 0.1%. = Mark-Space ratio = Mark-Space ratio, or mark-to-space ratio, is another term for the same concept, to describe the temporal relationship between two alternating periods of a waveform. However, whereas the duty cycle relates the duration of one period to the duration of the entire cycle, the mark-space ratio relates the durations of the two individual periods: :\\\\text{Mark Space Ratio} = \\\\frac{PW_{on}}{PW_{off}} where PW_{on} and PW_{off} are the durations of the two alternating periods. References Category:Mechanical engineering Category:Timing in electronic circuits Category:Articles containing video clips ","title":"Duty cycle"},{"id":"41079","title":"Dynamic range"},{"id":"41081","text":"In Greek mythology, Echo (; , ƒíkh≈ç, \\"echo\\",·º†œáœé, Henry Liddell, Robert Scott, A Greek-English Lexicon, on Perseus from ·º¶œáŒøœÇ (ƒìchos), \\"sound\\"·º¶œáŒøœÇ, Henry George Liddell, Robert Scott, A Greek-English Lexicon, on Perseus) was an Oread who resided on Mount Cithaeron.Aristophanes, Translated by Eugene O'Neill Jr. (1938). Thesmophoriazusae. Lines 990-1000. Available at perseus.tufts.edu Zeus loved consorting with beautiful nymphs and often visited them on Earth. Eventually, Zeus's wife, Hera, became suspicious, and came from Mount Olympus in an attempt to catch Zeus with the nymphs. Echo, by trying to protect Zeus (as he had ordered her to do), endured Hera's wrath, and Hera made her only able to speak the last words spoken to her. So when Echo met Narcissus and fell in love with him, she was unable to tell him how she felt and was forced to watch him as he fell in love with himself. Classical depiction Echo and Narcissus (John William Waterhouse, 1903, Walker Art Gallery, Liverpool) =Metamorphoses= In Metamorphoses (8 AD), the poet Ovid tells of Juno (Hera in Greek mythology) and the jealousy she felt over her husband Jupiter's (Zeus in Greek mythology) many affairs. Though vigilant, whenever she was about to catch him, Echo distracted her with lengthy conversations. When at last Juno realized the truth, she cursed Echo. From that moment on, the once loquacious nymph could only repeat the most recently spoken words of another person.Ovid, Translated by David Raeburn (2004). Metamorphoses. Penguin Classics. 3. 361-369. Sometime after being cursed, Echo spied a young man, Narcissus, while he was out hunting deer with his companions. She immediately fell in love with him and, infatuated, followed quietly. The more she looked at the young man, the more she longed for him. Though she wished with all her heart to call out to Narcissus, Juno's curse prevented her.Ovid, Metamorphoses, 3. 370-378 During the hunt, Narcissus became separated from his companions and called out, ‚Äòis anyone there,‚Äô and heard the nymph repeat his words. Startled, Narcissus answered the voice, ‚Äòcome here,‚Äô only to be told the same. When Narcissus saw that nobody had emerged from the glade, he concluded that the owner of the voice must be running away from him and called out again. Finally, he shouted, \\"This way, we must come together.\\" Taking this to be a reciprocation of her love, Echo concurred ecstatically, \\"We must come together!\\"Ovid, Metamorphoses, 3. 379-386 In her delight, Echo rushed to Narcissus ready to throw her arms around her beloved. Narcissus, however, was appalled and, spurning her, exclaimed, ‚ÄòHands off! May I die before you enjoy my body.‚Äô All Echo could whisper in reply was, ‚Äòenjoy my body‚Äô and having done so she fled, scorned, humiliated, and shamed.Ovid, Metamorphoses, 3. 386-392 Despite the harshness of his rejection, Echo‚Äôs love for Narcissus only grew.Ovid, Metamorphoses, 3. 394 When Narcissus died, wasting away before his own reflection, consumed by a love that could not be, Echo mourned over his body. When Narcissus, looking one last time into the pool uttered, \\"Oh marvellous boy, I loved you in vain, farewell\\", Echo too chorused, \\"Farewell.\\"Ovid, Metamorphoses, 3. 493-501 Eventually, Echo, too, began to waste away. Her beauty faded, her skin shrivelled, and her bones turned to stone. Today, all that remains of Echo is the sound of her voice.Ovid, Metamorphoses, 3. 395-397 =Daphnis and Chloe= Daphnis recounting the tale of Echo to Chloe. (Fran√ßois Boucher, 1743, The Wallace Collection, London) The tale of Daphnis and Chloe is a 2nd-century romance by Greek author Longus. At one point in the novel, Daphnis and Chloe are staring out at the boats gliding across the sea. Chloe, having never heard an echo before, is confused on hearing the fisherman‚Äôs song repeated in a nearby valley. Daphnis promises to tell her the story of Echo in exchange for ten more kisses.Longus, Translated by Ronald McCail (2009). Daphnis and Chloe. Oxford University Press. Page 56, [3.22]. Daphnis‚Äô rendition differs radically from Ovid‚Äôs account. According to Daphnis, Echo was raised among the Nymph√¶ because her mother was a nymph. Her father, however, was merely a man and hence Echo was not herself a nymph but mortal. Echo spent her days dancing with the Nymph√¶ and singing with the Muses who taught her all manner of musical instruments. Pan then grew angry with her, envious of her musical virtuosity and covetous of her virginity, which she would yield neither to men nor gods. Pan drove the men of the fields mad, and, like wild animals, they tore Echo apart and scattered the still singing fragments of her body across the earth. Showing favour to the Nymph√¶, Gaia hid the shreds of Echo within herself providing shelter for her music, and, at the Muses‚Äô command, Echo‚Äôs body will still sing, imitating with perfect likeness the sound of any earthly thing. Daphnis recounts that Pan himself often hears his very own pipes and, giving chase across the mountains, looks in vain for the secret student he can never find. =Other= Both the Homeric and Orphic Hymns to Pan reiterate Longus‚Äô tale of Pan chasing Echo‚Äôs secret voice across the mountains.Hesiod and Homer, Translated by Hugh. G. Evelyn-White (2008). Hesiod, the Homeric Hymns, and Homerica. Digireads.com. Homeric Hymn XIX. To Pan, p.127. Orpheus, Translated by Thomas Taylor (2013). The Mystical Hymns of Orpheus. Old Book Publishing Ltd. Orphic Hymn XI. To Pan, page 35. Codex 190 of Photius' Bibliotheca states that Pan's unrequited love for Echo was placed there by Aphrodite, angry at his verdict in a beauty contest.Photius, Translated by Ren√© Henry (2003). Biblioth√®que: Tome III: Codices 186-222. Les Belles Lettres. Codex 190. Nonnus‚Äô Dionysiaca contains a number of references to Echo. In Nonnus‚Äô account, though Pan frequently chased Echo, he never won her affection.Nonnus, Translated by W. H. D. Rouse (1989). Dionysiaca: Books 1-15. Loeb. Book XV, para. 306. Book VI also makes reference to Echo in the context of the Great Deluge. Nonnus states that the waters rose so far that even high on the hills Echo was forced to swim. Having escaped the advances of Pan, she feared now the lust of Poseidon.Nonnus, Dionysiaca, Book VI, para. 257. Whereas Nonnus is adamant that Pan never wins Echo, in Apuleius' The Golden Ass Pan is described with Echo in his arms, teaching the nymph to repeat all manner of songs.Apuleius, Translated by P. G. Walsh (2008). The Golden Ass. Oxford University Press. Page 94, Book 5, para. 25. Similarly in the Suda Echo is described as bearing Pan a child, Iynx. Other fragments mention a second daughter, Iambe. Medieval depiction =The Lay of Narcissus= Echo and Narcissus, a depiction of Echo and Narcissus featuring Cupid and his arrows. (Nicolas Poussin, 1630, Louvre Museum, Paris) The Lay of Narcissus, one of many titles by which the work is known, is Norman-French verse narrative written towards the end of the 12th century. In the four manuscripts that remain, an unknown author borrows from the Echo and Narcissus of Ovid to create a story better suited to the needs of his time.Dwyer, Richard (1978), Review: Narcisse: Conte ovidien fran√ßais du XIIe si√®cle by Martine Thiry-Stassin, Madeline Tyssens. Speculum Vol. 53, No. 2, p.417 This medieval account alters the characters of both Echo and Narcissus. In Ovid‚Äôs account Echo is a beautiful nymph residing with the Muses, and Narcissus is a haughty prince. In The Lay of Narcissus, Echo is replaced by the princess Dan√©. Conversely, Narcissus loses the royal status he bore in Ovid's account: in this rendition he is no more than a commoner, a vassal of Dan√©‚Äôs father, the King. In the Lay, Dan√© is pierced by the arrows of Amor and falls madly in love with Narcissus. Though aware that she should first consult her father, she nonetheless shares her feelings with Narcissus. Despite her emphasising her royal lineage, Narcissus spurns her just as he spurns and flees from all women. Humiliated, Dan√© calls out to Amor, and, in response, the god curses Narcissus. In a classic example of poetic justice, Narcissus is forced to suffer the same pain he inflicted on others, namely the pain of unrequited love. The vehicle of this justice is a pool of water in which Narcissus falls in love with his own reflection, which he at first mistakes for a woman. Deranged by lust, Dan√© searches for Narcissus, naked but for a cloak, and finds him at the point of death. Devastated, Dan√© repents ever calling to Amor. Dan√© expresses her love for the last time, pulls close to her beloved and dies in his arms. The poet warns men and women alike not to disdain suitors lest they suffer a similar fate.Harrison, Echo and her Medieval Sister, 327 While Ovid‚Äôs story is still recognisable, many of the details have changed considerably. Almost all references to pagan deities are gone, save Amor who is little more than a personification of love. Narcissus is demoted to the status of a commoner while Echo is elevated to the status of princess. Allusions to Narcissus‚Äô homosexuality are expunged. While Ovid talks of Narcissus' disdain for both male and female suitors, the Lay only mentions his hatred of women. Similarly, in the Lay, Narcissus mistakes his reflection for that of a woman, whereas no mention is made of this in Ovid‚Äôs account. Finally, the tale is overtly moralized with messages about courtly love. Such exhortations were entirely absent from the Metamorphoses rendition. =The Romance of the Rose= The Romance of the Rose The Romance of the Rose is a medieval French poem, the first section of which was written by Guillaume de Lorris in around 1230. The poem was completed by Jean de Meun in around 1275. Part of a much larger narrative, the tale of Echo and Narcissus is relayed when the central figure stumbles across the pool wherein Narcissus first glimpsed his own reflection.Guillaume de Lorris and Jean de Meun (2008). The Romance of the Rose. Oxford University Press. Page 23. In this rendition, Echo is not a nymph, or a princess, but a noble lady. She fell madly in love with Narcissus, so much so that she declared that she would die should he fail to love her in turn. Narcissus refuses, not because he despises all women, but merely because he is haughty and excessively proud of his own beauty. Guillaume relays that on hearing Narcissus‚Äô rejection, Echo‚Äôs grief and anger were so great that she died at once. However, in a similar vein to the Lay of Narcissus, just before she dies, Echo calls out to Deus. She asks that Narcissus might one day be tormented by unrequited love as she had been, and, in so doing, understand how the spurned suffer. As in the classical myth, Narcissus comes across a pool following a hunt. Though Echo prayed to Deus, and the tale notes that he answered her prayer, it is Amor who waits for Narcissus by the water. Amor causes Narcissus his fall for his own reflection, leading quickly to his death. The tale makes clear that this is not merely justice for Echo, but also punishment for Narcissus‚Äô slight against love itself. The tale concludes with an exhortation to all men warning them that, should they scorn their lovers, God will repay the offence.Guillaume, The Romance of the Rose, 24 Guillaume‚Äôs rendition builds on the themes of courtly love emphasised in the Lay and moves further away from Ovid‚Äôs initial account. The curse of Athena is absent entirely, and the tale is overtly moralised. Unlike in the Lay, however, this moral message is aimed solely at women; this despite the fact that the offending behaviour is perpetrated by Narcissus not Echo.Harrison, The Romance of the Rose, 328-329 References Category:Metamorphoses in Greek mythology Category:Oreads ","title":"Echo (mythology)"},{"id":"41082","text":"In telecommunication, effective data transfer rate is the average number of units of data, such as bits, characters, blocks, or frames, transferred per unit time from a source and accepted as valid by a sink. Note: The effective data transfer rate is usually expressed in bits, characters, blocks, or frames per second. The effective data transfer rate may be averaged over a period of seconds, minutes, or hours. References Category:Data transmission Category:Units of information ","title":"Effective data transfer rate"},{"id":"41084","text":"In telecommunication, the effective height, or effective length, of an antenna is the height of the antenna's center of radiation above the ground. It is defined as the ratio of the induced voltage to the incident field . In low- frequency applications involving loaded or nonloaded vertical antennas, the effective height is the moment of the current distribution in the vertical section, divided by the input current. For an antenna with a symmetrical current distribution, the center of radiation is the center of the distribution. For an antenna with asymmetrical current distribution, the center of radiation is the center of current moments when viewed from points near the direction of maximum radiation.  See also  * antenna effective length * antenna factor  References  Category:Antennas ","title":"Effective height"},{"id":"41085","text":"In telecommunications, effective input noise temperature is the source noise temperature in a two-port network or amplifier that will result in the same output noise power, when connected to a noise-free network or amplifier, as that of the actual network or amplifier connected to a noise-free source. If F is the noise figure numeric and 290K the standard noise temperature, then the effective noise temperature is given by T n = 290(F' ‚àí 1). References Category:Noise (electronics) Category:Equivalent units ","title":"Effective input noise temperature"},{"id":"41086","text":"For an optical fiber, the effective mode volume is the square of the product of the diameter of the near-field pattern and the sine of the radiation angle of the far-field pattern. The diameter of the near-field radiation pattern is defined here as the full width at half maximum and the radiation angle at half maximum radiant intensity. Effective mode volume is proportional to the breadth of the relative distribution of power amongst the modes in a multimode fiber. It is not truly a spatial volume but rather an \\"optical volume\\" equal to the product of area and solid angle. The power divided by the effective mode volume is proportional to the radiance of the light emitted by the fiber. References * Category:Fiber optics ","title":"Effective mode volume"},{"id":"41088","text":"In telecommunications, effective transmission rate (average rate of transmission, effective speed of transmission) is the rate at which information is processed by a transmission facility. *The effective transmission rate is calculated as (a) the measured number of units of data, such as bits, characters, blocks, or frames, transmitted during a significant measurement time interval divided by (b) the measurement time interval. *The effective transmission rate is usually expressed as a number of units of data per unit time, such as bits per second or characters per second. References Category:Data transmission Category:Units of information Category:Temporal rates ","title":"Effective transmission rate"},{"id":"41089","text":"Efficiency factor is a ratio of some measure of performance to an expected value. Data communication In data communications, the factor is the ratio of the time to transmit a text automatically at a specified modulation rate to the time actually required to receive the same text at a specified maximum error rate. All of the communication facilities are assumed to be in the normal condition of adjustment and operation. The practical conditions of measurement should be specified, especially the duration of the measurement. Telegraph communications may have different temporal efficiency factors for the two directions of transmission. Industrial engineering In industrial engineering, the efficiency factor is the relationship between the allowance time and the time taken, in the form of percentage. Efficiency factors are used in performance rating and remuneration calculation exercises. The efficiency factor is an extremely simple to use and readily comprehensible index, the prerequisite being exact time management for maintaining the allowed times.Poeschel, Frank: Zeitgrad. In: Landau, Kurt (Ed.): Lexikon Arbeitsgestaltung : Best Practise im Arbeitsprozess. Stuttgart: Genter, 2007. - . P. 1322. References Category:Data transmission Category:Industrial engineering Category:Time management ","title":"Efficiency factor"},{"id":"41091","text":"In telecommunications and electrical engineering, electrical length (or phase length) refers to the length of an electrical conductor in terms of the phase shift introduced by transmission over that conductorRon Schmitt, Electromagnetics explained [electronic resource]: a handbook for wireless/RF, EMC, and high-speed electronics. 8 at some frequency. Use of the term Depending on the specific context, the term \\"electrical length\\" is used rather than simple physical length to incorporate one or more of the following three concepts: *When one is concerned with the number of wavelengths, or phase, involved in a wave's transit across a segment of transmission line especially, one may simply specify that electrical length, while specification of a physical length, frequency, or velocity factor is omitted. The electrical length is then typically expressed as N wavelengths or as the phase œÜ expressed in degrees or radians. Thus in a microstrip design one might specify a shorted stub of 60¬∞ phase length, which will correspond to different physical lengths when applied to different frequencies. Or one might consider a 2 meter section of coax which has an electrical length of one quarter wavelength (90¬∞) at 37.5 MHz and ask what its electrical length becomes when the circuit is operated at a different frequency. *Due to the velocity factor of a particular transmission line, for instance, the transit time of a signal in a certain length of cable is equal to the transit time over a longer distance when travelling at the speed of light. So a pulse sent down a 2 meter section of coax (whose velocity factor is 67%) would arrive at the end of the coax at the same time that the same pulse arrives at the end of a bare wire of length 3 meters (over which it propagates at the speed of light), and one might refer to the 2 meter section of coax as having an electrical length of 3 meters, or an electrical length of ¬Ω wavelength at 50 MHz (since a 50 MHz radio wave has a wavelength of 6 meters). *Since resonant antennas are usually specified in terms of the electrical length of their conductors (such as the half wave dipole), the attainment of such an electrical length is loosely equated with electrical resonance, that is, a purely resistive impedance at the antenna's input, as is usually desired. An antenna that has been made slightly too long, for instance, will present an inductive reactance, which can be corrected by physically shortening the antenna. Based on this understanding, a common jargon in the antenna trade refers to the achievement of resonance (cancellation of reactance) at the antenna terminals as electrically shortening that too-long antenna (or electrically lengthening a too-short antenna) when an electrical matching network (or antenna tuner) has performed that task without physically altering the antenna's length. Although the terminology is very inexact, this use is widespread, especially as applied to the use of a loading coil at the bottom of a short monopole (a vertical, or whip antenna) to \\"electrically lengthen\\" it and achieve electrical resonance as seen through the loading coil. Phase length The first use of the term \\"electrical length\\" assumes a sine wave of some frequency, or at least a narrowband waveform centered around some frequency f. The sine wave will repeat with a period of T = . The frequency f will correspond to a particular wavelength Œª along a particular conductor. For conductors (such as bare wire or air-filled coax) which transmit signals at the speed of light c, the wavelength is given by Œª = . A distance L along that conductor corresponds to N wavelengths where N; = . 250px In the figure at the right, the wave shown is seen to be N = 1.5 wavelengths long. A wave crest at the beginning of the graph, moving towards the right, will arrive at the end after a time 1.5 T . The electrical length of that segment is said to be \\"1.5 wavelengths\\" or, expressed as a phase angle, \\"540¬∞\\" (or 3 œÄ radians) where N wavelengths corresponds to œÜ = 360¬∞‚Ä¢N (or œÜ = 2œÄ‚Ä¢N radians). In radio frequency applications, when a delay is introduced due to a transmission line, it is often the phase shift œÜ that is of importance, so specifying a design in terms of the phase or electrical length allows one to adapt that design to an arbitrary frequency by employing the wavelength Œª applying to that frequency. Velocity factor In a transmission line, a signal travels at a rate controlled by the effective capacitance and inductance per unit of length of the transmission line. Some transmission lines consist only of bare conductors, in which case their signals propagate at the speed of light, c. More often the signal travels at a reduced velocity Œ∫c, where Œ∫ is the velocity factor, a number less than 1, representing the ratio of that velocity to the speed of light. Most transmission lines contain a dielectric material (insulator) filling some or all of the space in between the conductors. The relative permittivity or dielectric constant of that material increases the distributed capacitance in the cable, which reduces the velocity factor below unity. It is also possible for Œ∫ to be reduced due to a relative permeability (\\\\mu_\\\\text{r}) of that material, which increases the distributed inductance, but this is almost never the case. Now, if one fills a space with a dielectric of relative permittivity \\\\epsilon_\\\\text{r}, then the velocity of an electromagnetic plane wave is reduced by the velocity factor: :\\\\kappa = \\\\frac{v_p}{c} = \\\\frac{1}{\\\\sqrt{\\\\epsilon_\\\\text{r}\\\\mu_\\\\text{r}}} \\\\approx \\\\frac{1}{\\\\sqrt{\\\\epsilon_\\\\text{r}}}. This reduced velocity factor would also apply to propagation of signals along wires immersed in a large space filled with that dielectric. However, with only part of the space around the conductors filled with that dielectric, there is less reduction of the wave velocity. Part of the electromagnetic wave surrounding each conductor \\"feels\\" the effect of the dielectric, and part is in free space. Then it is possible to define an effective relative permittivity \\\\epsilon_\\\\text{eff} which then predicts the velocity factor according to :\\\\kappa = \\\\frac{1}{\\\\sqrt{\\\\epsilon_\\\\text{eff}}} \\\\epsilon_\\\\text{eff} is computed as a weighted average of the relative permittivity of free space (1) and that of the dielectric: :\\\\epsilon_\\\\text{eff}= (1-F) + F \\\\epsilon_\\\\text{r} where the fill factor F expresses the effective proportion of space so affected by the dielectric. In the case of coaxial cable, where all of the volume in between the inner conductor and the shield is filled with a dielectric, the fill factor is unity, since the electromagnetic wave is confined to that region. In other types of cable, such as twin lead, the fill factor can be much smaller. Regardless, any cable intended for radio frequencies will have its velocity factor (as well as its characteristic impedance) specified by the manufacturer. In the case of coaxial cable, where F=1, the velocity factor is solely determined by the sort of dielectric used as specified here. For example, a typical velocity factor for coaxial cable is .66, corresponding to a dielectric constant of 2.25. Suppose we wish to send a 30 MHz signal down a short section of such a cable, and delay it by a quarter wave (90¬∞). In free space, this frequency corresponds to a wavelength of Œª0=10m, so a delay of .25Œª would require an electrical length of 2.5 m. Applying the velocity factor of .66, this results in a physical length of cable 1.67 m long. The velocity factor likewise applies to antennas in cases where the antenna conductors are (partly) surrounded by a dieletric. This particularly applies to microstrip antennas such as the patch antenna. Waves on microstrip are affected mostly by the dielectric of the circuit board beneath them, but also on the air above them (because of trace edge effects). Their velocity factors thus depend not directly on the permittivity of the circuit board material but on the effective permittivity \\\\epsilon_\\\\text{eff} which is often specified for a circuit board material (or can be calculated). Note that the fill factor and therefore \\\\epsilon_\\\\text{eff} are somewhat dependent on the width of the trace compared to the thickness of the board. Antennas While there are certain wideband antenna designs, many antennas are classified as resonant and perform according to design around a particular frequency. This applies especially to broadcasting stations and communication systems which are confined to one frequency or narrow frequency band. This includes the dipole and monopole antennas and all of the designs based on them (Yagi, dipole or monopole arrays, folded dipole, etc.). In addition to the directive gain in beam antennas suffering away from the design frequency, the antenna feedpoint impedance is very sensitive to frequency offsets. Especially for transmitting, the antenna is often intended to operate at the resonant frequency. At the resonant frequency, by definition, that impedance is a pure resistance which matches the characteristic impedance of the transmission line and the output (or input) impedance of the transmitter (or receiver). At frequencies away from the resonant frequency, the impedance includes some reactance (capacitance or inductance). It is possible for an antenna tuner to be used to cancel that reactance (and to change the resistance to match the transmission line), however that is often avoided as an extra complication (and needs to be controlled at the antenna side of the transmission line). The condition for resonance in a monopole antenna is for the element to be an odd multiple of a quarter-wavelength, Œª/4. In a dipole antenna both driven conductors must be that long, for a total dipole length of (2N+1)Œª/2. The electrical length of an antenna element is, in general, different from its physical length For example, increasing the diameter of the conductor, or the presence of nearby metal objects, will decrease the velocity of the waves in the element, increasing the electrical length. An antenna which is shorter than its resonant length is described as \\"electrically short\\" Slyusar V. I. 60 Years of Electrically Small Antennas Theory.//Proceedings of the 6-th International Conference on Antenna Theory and Techniques, 17-21 September, 2007, Sevastopol, Ukraine. - Pp. 116 - 118. , and exhibits capacitive reactance. Similarly, an antenna which is longer than its resonant length is described as \\"electrically long\\" and exhibits inductive reactance. =Changing electrical length by loading= Loading coil in a cellphone antenna mounted on the roof of a car. The coil allows the antenna to be shorter than a quarter wavelength and still be resonant. An antenna's effective electrical length can be changed without changing its physical length by adding reactance, (inductance or capacitance) in series with it. This is called lumped-impedance matching or loading. For example, a monopole antenna such as a metal rod fed at one end, will be resonant when its electrical length is equal to a quarter wavelength, Œª/4, of the frequency used. If the antenna is shorter than a quarter wavelength, the feedpoint impedance will include capacitive reactance; this causes reflections on the feedline and a mismatch at the transmitter or receiver, even if the resistive component of the impedance is correct. To cancel the capacitive reactance, an inductance, called a loading coil, is inserted in between the feedline and the antenna terminal. Selecting an inductance with the same reactance as the (negative) capacitative reactance seen at the antenna terminal, cancels that capacitance, and the antenna system (antenna and coil) will again be resonant. The feedline sees a purely resistive impedance. Since an antenna which had been too short now appears as if it were resonant, the addition of the loading coil is sometimes referred to as \\"electrically lengthening\\" the antenna. Similarly, the feedpoint impedance of a monopole antenna longer than Œª/4 (or a dipole with arms longer than Œª/4) will include inductive reactance. A capacitor in series with the antenna can cancel this reactance to make it resonant, which can be referred to as \\"electrically shortening\\" the antenna. Inductive loading is widely used to reduce the length of whip antennas on portable radios such as walkie-talkies and short wave antennas on cars, to meet physical requirements. Vertical antenna which may be of any desired height : less than about one-half wavelength of the frequency at which the antenna operates. These antennas may operate either as transmitting or receiving antennas =Advantages= The electrical lengthening allows the construction of shorter aerials. It is applied in particular for aerials for VLF, longwave and medium-wave transmitters. Because those radio waves are several hundred meters to many kilometers long, mast radiators of the necessary height cannot be realised economically. It is also used widely for whip antennas on portable devices such as walkie-talkies to allow antennas much shorter than the standard quarter-wavelength to be used. The most widely used example is the rubber ducky antenna. =Disadvantages= The electrical lengthening reduces the bandwidth of the antenna if other phase control measures are not undertaken. An electrically extended aerial is less efficient than the equivalent, full- length antenna. =Technical realization= There are two possibilities for the realisation of the electric lengthening. # switching in inductive coils in series with the aerial # switching in metal surfaces, known as roof capacitance, at the aerial ends which form capacitors to earth. Often both measures are combined. The coils switched in series must sometimes be placed in the middle of the aerial construction. The cabin installed at a height of 150-metres on the Blosenbergturm in Berom√ºnster is such a construction, in which a lengthening coil is installed for the supply of the upper tower part (the Blosenbergturm has in addition a ring-shaped roof capacitor on its top) Application Transmission aerials of transmitters working at frequencies below the longwave broadcasting band always apply electric lengthening. Broadcasting aerials of longwave broadcasting stations apply it often. However, for transmission aerials of NDBs electrical lengthening is extensively applied, because these use antennas which are considerably less tall than a quarter of the radiated wavelength. File:US Patent 2101674 Antenna.pngOn the left, characteristics plotted from experimentally obtained data on coordinates with logarithmic abscissa. On the right, an antenna with increased effective inductance between the two points in accordance with the well known operation of shunt tuned circuits adjusted somewhat off resonance. See also * Antenna tuner * Electrically small antenna * Loading coil * Monopole antenna References  Further reading *A. Nickle, , \\"Antenna\\". (Filed May 25, 1934; Issued Aug 2, 1938) *William W. Brown, , \\"Antenna structure\\". (Filed May 25, 1934; Issued Oct 27, 1936). * Robert B. Dome, , \\"Antenna\\". (Filed May 25, 1934; Issued Dec 7, 1937) * Slyusar V. I. 60 Years of Electrically Small Antennas Theory.//Proceedings of the 6-th International Conference on Antenna Theory and Techniques, 17-21 September, 2007, Sevastopol, Ukraine. - Pp. 116 - 118. Category:Telecommunication theory Category:Antennas ","title":"Electrical length"},{"id":"41092","text":"An electric field (sometimes E-field) is the physical field that surrounds each electric charge and exerts force on all other charges in the field, either attracting or repelling them.Browne, p 225: \\"... around every charge there is an aura that fills all space. This aura is the electric field due to the charge. The electric field is a vector field... and has a magnitude and direction.\\" Electric fields originate from electric charges, or from time- varying magnetic fields. Electric fields and magnetic fields are both manifestations of the electromagnetic force, one of the four fundamental forces (or interactions) of nature. Electric fields are important in many areas of physics, and are exploited practically in electrical technology. In atomic physics and chemistry, for instance, the electric field is used to model the attractive force holding the atomic nucleus and electrons together in atoms. It also models the forces in chemical bonding between atoms that result in molecules. The electric field is defined mathematically as a vector field that associates to each point in space the (electrostatic or Coulomb) force per unit of charge exerted on an infinitesimal positive test charge at rest at that point. The derived SI units for the electric field are volts per meter (V/m), exactly equivalent to newtons per coulomb (N/C), p. 23. Description Electric field of a positive point electric charge suspended over an infinite sheet of conducting material. The field is depicted by electric field lines, lines which follow the direction of the electric field in space. The electric field is defined at each point in space as the force (per unit charge) that would be experienced by a vanishingly small positive test charge if held at that point. As the electric field is defined in terms of force, and force is a vector (i.e. having both magnitude and direction), it follows that an electric field is a vector field. Vector fields of this form are sometimes referred to as force fields. The electric field acts between two charges similarly to the way the gravitational field acts between two masses, as they both obey an inverse-square law with distance. This is the basis for Coulomb's law, which states that, for stationary charges, the electric field varies with the source charge and varies inversely with the square of the distance from the source. This means that if the source charge were doubled, the electric field would double, and if you move twice as far away from the source, the field at that point would be only one-quarter its original strength. The electric field can be visualized with a set of lines whose direction at each point is the same as the field's, a concept introduced by Michael Faraday, whose term 'lines of force' is still sometimes used. This illustration has the useful property that the field's strength is proportional to the density of the lines. The field lines are the paths that a point positive charge would follow as it is forced to move within the field, similar to trajectories that masses follow within a gravitational field. Field lines due to stationary charges have several important properties, including always originating from positive charges and terminating at negative charges, they enter all good conductors at right angles, and they never cross or close in on themselves. The field lines are a representative concept; the field actually permeates all the intervening space between the lines. More or fewer lines may be drawn depending on the precision to which it is desired to represent the field. The study of electric fields created by stationary charges is called electrostatics. Faraday's law describes the relationship between a time- varying magnetic field and the electric field. One way of stating Faraday's law is that the curl of the electric field is equal to the negative time derivative of the magnetic field. In the absence of time-varying magnetic field, the electric field is therefore called conservative (i.e. curl-free). This implies there are two kinds of electric fields: electrostatic fields and fields arising from time-varying magnetic fields. While the curl-free nature of the static electric field allows for a simpler treatment using electrostatics, time-varying magnetic fields are generally treated as a component of a unified electromagnetic field. The study of time varying magnetic and electric fields is called electrodynamics. Mathematical formulation Electric fields are caused by electric charges, described by Gauss's law,Purcell, p 25: \\"Gauss's Law: the flux of the electric field E through any closed surface... equals 1/e times the total charge enclosed by the surface.\\" and time varying magnetic fields, described by Faraday's law of induction.Purcell, p 356: \\"Faraday's Law of Induction.\\" Together, these laws are enough to define the behavior of the electric field. However, since the magnetic field is described as a function of electric field, the equations of both fields are coupled and together form Maxwell's equations that describe both fields as a function of charges and currents. =Electrostatics= In the special case of a steady state (stationary charges and currents), the Maxwell- Faraday inductive effect disappears. The resulting two equations (Gauss's law abla \\\\cdot \\\\mathbf{E} = \\\\frac{\\\\rho}{\\\\varepsilon_0} and Faraday's law with no induction term abla \\\\times \\\\mathbf{E} = 0), taken together, are equivalent to Coulomb's law, which states that a particle with electric charge q_1 at position \\\\boldsymbol{x}_1 exerts a force on a particle with charge q_0 at position \\\\boldsymbol{x}_0 of:Purcell, p7: \\"... the interaction between electric charges at rest is described by Coulomb's Law: two stationary electric charges repel or attract each other with a force proportional to the product of the magnitude of the charges and inversely proportional to the square of the distance between them. : \\\\boldsymbol{F} = {1\\\\over 4\\\\pi\\\\varepsilon_0}{q_1q_0 \\\\over (\\\\boldsymbol{x}_1-\\\\boldsymbol{x}_0)^2}\\\\hat \\\\boldsymbol{r}_{1,0} :where \\\\boldsymbol{r}_{1,0} is the unit vector in the direction from point \\\\boldsymbol{x}_1 to point \\\\boldsymbol{x}_0, and is the electric constant (also known as \\"the absolute permittivity of free space\\") with units C2 m‚àí2 N‚àí1 Note that \\\\varepsilon_0, the vacuum electric permittivity, must be substituted with \\\\varepsilon, permittivity, when charges are in non-empty media. When the charges q_0 and q_1 have the same sign this force is positive, directed away from the other charge, indicating the particles repel each other. When the charges have unlike signs the force is negative, indicating the particles attract. To make it easy to calculate the Coulomb force on any charge at position \\\\boldsymbol{x}_0 this expression can be divided by q_0 leaving an expression that only depends on the other charge (the source charge) : \\\\boldsymbol{E}(\\\\boldsymbol{x}_0) = {\\\\boldsymbol{F} \\\\over q_0} = {1\\\\over 4\\\\pi\\\\varepsilon_0}{q_1 \\\\over (\\\\boldsymbol{x}_1-\\\\boldsymbol{x}_0)^2}\\\\hat \\\\boldsymbol{r}_{1,0} This is the electric field at point \\\\boldsymbol{x}_0 due to the point charge q_1; it is a vector-valued function equal to the Coulomb force per unit charge that a positive point charge would experience at the position \\\\boldsymbol{x}_0. Since this formula gives the electric field magnitude and direction at any point \\\\boldsymbol{x}_0 in space (except at the location of the charge itself, \\\\boldsymbol{x}_1, where it becomes infinite) it defines a vector field. From the above formula it can be seen that the electric field due to a point charge is everywhere directed away from the charge if it is positive, and toward the charge if it is negative, and its magnitude decreases with the inverse square of the distance from the charge. The Coulomb force on a charge of magnitude q at any point in space is equal to the product of the charge and the electric field at that point :\\\\boldsymbol{F} = q\\\\boldsymbol{E} The units of the electric field in the SI system are newtons per coulomb (N/C), or volts per meter (V/m); in terms of the SI base units they are kg‚ãÖm‚ãÖs‚àí3‚ãÖA‚àí1 =Superposition principle= Due to the linearity of Maxwell's equations, electric fields satisfy the superposition principle, which states that the total electric field, at a point, due to a collection of charges is equal to the vector sum of the electric fields at that point due to the individual charges. This principle is useful in calculating the field created by multiple point charges. If charges q_1, q_2, ..., q_n are stationary in space at points \\\\mathbf{x}_1,\\\\mathbf{x}_2,...\\\\mathbf{x}_n, in the absence of currents, the superposition principle says that the resulting field is the sum of fields generated by each particle as described by Coulomb's law: : \\\\boldsymbol{E}(\\\\boldsymbol{x}) = \\\\boldsymbol{E}_1(\\\\boldsymbol{x}) + \\\\boldsymbol{E}_2(\\\\boldsymbol{x}) + \\\\boldsymbol{E}_3(\\\\boldsymbol{x}) + \\\\cdots = {1\\\\over 4\\\\pi\\\\varepsilon_0}{q_1 \\\\over (\\\\boldsymbol{x}_1-\\\\boldsymbol{x})^2}\\\\hat \\\\boldsymbol{r}_1 \\\\+ {1\\\\over 4\\\\pi\\\\varepsilon_0}{q_2 \\\\over (\\\\boldsymbol{x}_2-\\\\boldsymbol{x})^2}\\\\hat \\\\boldsymbol{r}_2 + {1\\\\over 4\\\\pi\\\\varepsilon_0}{q_3 \\\\over (\\\\boldsymbol{x}_3-\\\\boldsymbol{x})^2}\\\\hat \\\\boldsymbol{r}_3 + \\\\cdots : \\\\boldsymbol{E}(\\\\boldsymbol{x}) = {1\\\\over 4\\\\pi\\\\varepsilon_0} \\\\sum_{k=1}^N {q_k \\\\over (\\\\boldsymbol{x}_k-\\\\boldsymbol{x})^2}\\\\hat \\\\boldsymbol{r}_k :where \\\\boldsymbol{\\\\hat r_k} is the unit vector in the direction from point \\\\boldsymbol{x}_k to point \\\\boldsymbol{x}. = Continuous Charge Distributions = The superposition principle allows for the calculation of the electric field due to a continuous distribution of charge \\\\rho(\\\\boldsymbol{x}) (where \\\\rho is the charge density in coulombs per cubic meter). By considering the charge \\\\rho(\\\\boldsymbol{x}')dV in each small volume of space dV at point \\\\boldsymbol{x}' as a point charge, the resulting electric field, d\\\\boldsymbol{E}(\\\\boldsymbol{x}), at point \\\\boldsymbol{x} can be calculated as : d\\\\boldsymbol{E}(\\\\boldsymbol{x}) = {1\\\\over 4\\\\pi\\\\varepsilon_0}{\\\\rho(\\\\boldsymbol{x}')dV \\\\over (\\\\boldsymbol{x}'-\\\\boldsymbol{x})^2}\\\\hat \\\\boldsymbol{r}' where \\\\hat \\\\boldsymbol{r}' is the unit vector pointing from \\\\boldsymbol{x}' to \\\\boldsymbol{x}. The total field is then found by \\"adding up\\" the contributions from all the increments of volume by integrating over the volume of the charge distribution V: : \\\\boldsymbol{E}(\\\\boldsymbol{x}) = {1\\\\over 4\\\\pi\\\\varepsilon_0}\\\\iiint\\\\limits_V \\\\,{\\\\rho(\\\\boldsymbol{x}')dV \\\\over (\\\\boldsymbol{x}'-\\\\boldsymbol{x})^2}\\\\hat \\\\boldsymbol{r}' Similar equations follow for a surface charge with continuous charge distribution \\\\sigma(\\\\boldsymbol{x}) where \\\\sigma is the charge density in coulombs per square meter : \\\\boldsymbol{E}(\\\\boldsymbol{x}) = {1\\\\over 4\\\\pi\\\\varepsilon_0}\\\\iint\\\\limits_S \\\\,{\\\\sigma(\\\\boldsymbol{x}')dA \\\\over (\\\\boldsymbol{x}'-\\\\boldsymbol{x})^2}\\\\hat \\\\boldsymbol{r}' and for line charges with continuous charge distribution \\\\lambda(\\\\boldsymbol{x}) where \\\\lambda is the charge density in coulombs per meter. : \\\\boldsymbol{E}(\\\\boldsymbol{x}) = {1\\\\over 4\\\\pi\\\\varepsilon_0}\\\\int\\\\limits_P \\\\,{\\\\lambda(\\\\boldsymbol{x}')dL \\\\over (\\\\boldsymbol{x}'-\\\\boldsymbol{x})^2}\\\\hat \\\\boldsymbol{r}' =Electric potential= If a system is static, such that magnetic fields are not time- varying, then by Faraday's law, the electric field is curl-free. In this case, one can define an electric potential, that is, a function \\\\Phi such that \\\\mathbf{E} = - abla \\\\Phi . This is analogous to the gravitational potential. The difference between the electric potential at two points in space is called the potential difference (or voltage) between the two points. In general, however, the electric field cannot be described independently of the magnetic field. Given the magnetic vector potential, A, defined so that \\\\mathbf{B} = abla \\\\times \\\\mathbf{A} , one can still define an electric potential \\\\Phi such that: : \\\\mathbf{E} = - abla \\\\Phi - \\\\frac { \\\\partial \\\\mathbf{A} } { \\\\partial t } Where abla \\\\Phi is the gradient of the electric potential and \\\\frac { \\\\partial \\\\mathbf{A} } { \\\\partial t } is the partial derivative of A with respect to time. Faraday's law of induction can be recovered by taking the curl of that equation : abla \\\\times \\\\mathbf{E} = -\\\\frac{\\\\partial ( abla \\\\times \\\\mathbf{A})} {\\\\partial t}= -\\\\frac{\\\\partial \\\\mathbf{B}} {\\\\partial t} which justifies, a posteriori, the previous form for E. = Continuous vs. discrete charge representation = The equations of electromagnetism are best described in a continuous description. However, charges are sometimes best described as discrete points; for example, some models may describe electrons as point sources where charge density is infinite on an infinitesimal section of space. A charge q located at \\\\mathbf{r_0} can be described mathematically as a charge density \\\\rho(\\\\mathbf{r})=q\\\\delta(\\\\mathbf{r-r_0}), where the Dirac delta function (in three dimensions) is used. Conversely, a charge distribution can be approximated by many small point charges. Electrostatic fields Illustration of the electric field surrounding a positive (red) and a negative (blue) charge Electrostatic fields are electric fields which do not change with time, which happens when charges and currents are stationary. In that case, Coulomb's law fully describes the field.Purcell, pp. 5-7. =Parallels between electrostatic and gravitational fields= Coulomb's law, which describes the interaction of electric charges: : \\\\mathbf{F}=q\\\\left(\\\\frac{Q}{4\\\\pi\\\\varepsilon_0}\\\\frac{\\\\mathbf{\\\\hat{r}}}{\\\\mathbf{r}^2}\\\\right)=q\\\\mathbf{E} is similar to Newton's law of universal gravitation: : \\\\mathbf{F}=m\\\\left(-GM\\\\frac{\\\\mathbf{\\\\hat{r}}}{\\\\mathbf{r}^2}\\\\right)=m\\\\mathbf{g} (where \\\\mathbf{\\\\hat{r}}=\\\\mathbf{\\\\frac{r}{r}}). This suggests similarities between the electric field E and the gravitational field g, or their associated potentials. Mass is sometimes called \\"gravitational charge\\". Electrostatic and gravitational forces both are central, conservative and obey an inverse-square law. =Uniform fields= Illustration of the electric field between two parallel conductive plates of finite size (known as a parallel plate capacitor). In the middle of the plates, far from any edges, the electric field is very nearly uniform. A uniform field is one in which the electric field is constant at every point. It can be approximated by placing two conducting plates parallel to each other and maintaining a voltage (potential difference) between them; it is only an approximation because of boundary effects (near the edge of the planes, electric field is distorted because the plane does not continue). Assuming infinite planes, the magnitude of the electric field E is: : E = - \\\\frac{\\\\Delta V}{d} where ŒîV is the potential difference between the plates and d is the distance separating the plates. The negative sign arises as positive charges repel, so a positive charge will experience a force away from the positively charged plate, in the opposite direction to that in which the voltage increases. In micro- and nano- applications, for instance in relation to semiconductors, a typical magnitude of an electric field is in the order of , achieved by applying a voltage of the order of 1 volt between conductors spaced 1 ¬µm apart. Electrodynamic fields The electric field (lines with arrows) of a charge (+) induces surface charges (red and blue areas) on metal objects due to electrostatic induction. Electrodynamic fields are electric fields which do change with time, for instance when charges are in motion. In this case, a magnetic field is produced in accordance with Amp√®re's circuital law (with Maxwell's addition), which, along with Maxwell's other equations, defines the magnetic field, \\\\mathbf{B}, in terms of its curl: : abla \\\\times \\\\mathbf{B} = \\\\mu_0\\\\left(\\\\mathbf{J} + \\\\varepsilon_0 \\\\frac{\\\\partial \\\\mathbf{E}} {\\\\partial t} \\\\right) , where \\\\mathbf{J} is the current density, \\\\mu_0 is the vacuum permeability, and \\\\varepsilon_0 is the vacuum permittivity. That is, both electric currents (i.e. charges in uniform motion) and the (partial) time derivative of the electric field directly contributes to the magnetic field. In addition, the Maxwell‚ÄìFaraday equation states : abla \\\\times \\\\mathbf{E} = -\\\\frac{\\\\partial \\\\mathbf{B}} {\\\\partial t} These represent two of Maxwell's four equations and they intricately link the electric and magnetic fields together, resulting in the electromagnetic field. The equations represent a set of four coupled multi-dimensional partial differential equations which, when solved for a system, describe the combined behavior of the electromagnetic fields. In general, the force experienced by a test charge in an electromagnetic field is given by the Lorentz force law: : \\\\mathbf{F} = q\\\\mathbf{E} + q\\\\mathbf{v} \\\\times \\\\mathbf{B} Energy in the electric field The total energy per unit volume stored by the electromagnetic field isIntroduction to Electrodynamics (3rd Edition), D.J. Griffiths, Pearson Education, Dorling Kindersley, 2007, : u_{EM} = \\\\frac{\\\\varepsilon}{2} \\\\mathbf{E}^2 + \\\\frac{1}{2\\\\mu} \\\\mathbf{B}^2 where Œµ is the permittivity of the medium in which the field exists, \\\\mu its magnetic permeability, and E and B are the electric and magnetic field vectors. As E and B fields are coupled, it would be misleading to split this expression into \\"electric\\" and \\"magnetic\\" contributions. However, in the steady-state case, the fields are no longer coupled (see Maxwell's equations). It makes sense in that case to compute the electrostatic energy per unit volume: : u_{ES} = \\\\frac{1}{2} \\\\varepsilon \\\\mathbf{E}^2 \\\\, , The total energy U stored in the electric field in a given volume V is therefore : U_{ES} = \\\\frac{1}{2} \\\\varepsilon \\\\int_{V} \\\\mathbf{E}^2 \\\\, \\\\mathrm{d}V \\\\, , The electric displacement field =Definitive equation of vector fields= In the presence of matter, it is helpful to extend the notion of the electric field into three vector fields:Electromagnetism (2nd Edition), I.S. Grant, W.R. Phillips, Manchester Physics, John Wiley & Sons, 2008, :\\\\mathbf{D}=\\\\varepsilon_0\\\\mathbf{E}+\\\\mathbf{P}\\\\\\\\! where P is the electric polarization ‚Äì the volume density of electric dipole moments, and D is the electric displacement field. Since E and P are defined separately, this equation can be used to define D. The physical interpretation of D is not as clear as E (effectively the field applied to the material) or P (induced field due to the dipoles in the material), but still serves as a convenient mathematical simplification, since Maxwell's equations can be simplified in terms of free charges and currents. =Constitutive relation= The E and D fields are related by the permittivity of the material, Œµ.Electricity and Modern Physics (2nd Edition), G.A.G. Bennet, Edward Arnold (UK), 1974, For linear, homogeneous, isotropic materials E and D are proportional and constant throughout the region, there is no position dependence: :\\\\mathbf{D(r)}=\\\\varepsilon\\\\mathbf{E(r)} For inhomogeneous materials, there is a position dependence throughout the material: :\\\\mathbf{D(r)}=\\\\varepsilon (r)\\\\mathbf{E(r)} For anisotropic materials the E and D fields are not parallel, and so E and D are related by the permittivity tensor (a 2nd order tensor field), in component form: :D_i=\\\\varepsilon_{ij}E_j For non-linear media, E and D are not proportional. Materials can have varying extents of linearity, homogeneity and isotropy. See also * Classical electromagnetism * electricity * History of electromagnetic theory * Optical field * Magnetism * Teltron tube * Teledeltos, a conductive paper that may be used as a simple analog computer for modelling fields References * *  External links  * Electric field in \\"Electricity and Magnetism\\", R Nave ‚Äì Hyperphysics, Georgia State University * Frank Wolfs's lectures at University of Rochester, chapters 23 and 24 * Fields ‚Äì a chapter from an online textbook Category:Electrostatics Category:Physical quantities Category:Electromagnetism ","title":"Electric field"},{"id":"41093","text":"Anechoic RF chamber used for EMC testing (radiated emissions and immunity). The furniture has to be made of wood or plastic, not metal. Log-periodic antenna measurement for outdoors Electromagnetic compatibility (EMC) is the ability of electrical equipment and systems to function acceptably in their electromagnetic environment, by limiting the unintentional generation, propagation and reception of electromagnetic energy which may cause unwanted effects such as electromagnetic interference (EMI) or even physical damage in operational equipment. The goal of EMC is the correct operation of different equipment in a common electromagnetic environment. It is also the name given to the associated branch of electrical engineering. EMC pursues three main classes of issue. Emission is the generation of electromagnetic energy, whether deliberate or accidental, by some source and its release into the environment. EMC studies the unwanted emissions and the countermeasures which may be taken in order to reduce unwanted emissions. The second class, susceptibility, is the tendency of electrical equipment, referred to as the victim, to malfunction or break down in the presence of unwanted emissions, which are known as Radio frequency interference (RFI). Immunity is the opposite of susceptibility, being the ability of equipment to function correctly in the presence of RFI, with the discipline of \\"hardening\\" equipment being known equally as susceptibility or immunity. A third class studied is coupling, which is the mechanism by which emitted interference reaches the victim. Interference mitigation and hence electromagnetic compatibility may be achieved by addressing any or all of these issues, i.e., quieting the sources of interference, inhibiting coupling paths and/or hardening the potential victims. In practice, many of the engineering techniques used, such as grounding and shielding, apply to all three issues. Introduction While electromagnetic interference (EMI) is a phenomenon - the radiation emitted and its effects - electromagnetic compatibility (EMC) is an equipment characteristic or property - not to behave unacceptably in the EMI environment. EMC ensures the correct operation, in the same electromagnetic environment, of different equipment items which use or respond to electromagnetic phenomena, and the avoidance of any interference effects. Another way of saying this is that EMC is the control of EMI so that unwanted effects are prevented. Besides understanding the phenomena in themselves, EMC also addresses the countermeasures, such as control regimes, design and measurement, which should be taken in order to prevent emissions from causing any adverse effect.  Types of interference  Electromagnetic interference divides into several categories according to the source and signal characteristics. The origin of interference, often called \\"noise\\" in this context, can be man-made (artificial) or natural. = Continuous interference = Continuous, or continuous wave (CW), interference arises where the source continuously emits at a given range of frequencies. This type is naturally divided into sub-categories according to frequency range, and as a whole is sometimes referred to as \\"DC to daylight\\". * Audio frequency, from very low frequencies up to around 20 kHz. Frequencies up to 100 kHz may sometimes be classified as audio. Sources include: ** Mains hum from: power supply units, nearby power supply wiring, transmission lines and substations. ** Audio processing equipment, such as audio power amplifiers and loudspeakers. ** Demodulation of a high-frequency carrier wave such as an FM radio transmission. * Radio frequency interference (RFI), from typically 20 kHz to an upper limit which constantly increases as technology pushes it higher. Sources include: ** Wireless and radio frequency transmissions ** Television and radio receivers ** Industrial, scientific and medical equipment (ISM) ** Digital processing circuitry such as microcontrollers * Broadband noise may be spread across parts of either or both frequency ranges, with no particular frequency accentuated. Sources include: ** Solar activity ** Continuously operating spark gaps such as arc welders ** CDMA (spread-spectrum) mobile telephony = Pulse or transient interference = An electromagnetic pulse (EMP), sometimes called a transient disturbance, arises where the source emits a short-duration pulse of energy. The energy is usually broadband by nature, although it often excites a relatively narrow-band damped sine wave response in the victim. Sources divide broadly into isolated and repetitive events. *Sources of isolated EMP events include: **Switching action of electrical circuitry, including inductive loads such as relays, solenoids, or electric motors. **Power line surges/pulses **Electrostatic discharge (ESD), as a result of two charged objects coming into close proximity or contact. **Lightning electromagnetic pulse (LEMP), although typically a short series of pulses. ** Nuclear electromagnetic pulse (NEMP), as a result of a nuclear explosion. A variant of this is the high altitude EMP (HEMP) nuclear weapon, designed to create the pulse as its primary destructive effect. **Non-nuclear electromagnetic pulse (NNEMP) weapons. *Sources of repetitive EMP events, sometimes as regular pulse trains, include: **Electric motors **Electrical ignition systems, such as in gasoline engines. **Continual switching actions of digital electronic circuitry.  Coupling mechanisms  Some of the technical words which are employed can be used with differing meanings. These terms are used here in a widely accepted way, which is consistent with other articles in the encyclopedia. The basic arrangement of noise source, coupling path and victim, receptor or sink is shown in the figure below. Source and victim are usually electronic hardware devices, though the source may be a natural phenomenon such as a lightning strike, electrostatic discharge (ESD) or, in one famous case, the Big Bang at the origin of the Universe. The four electromagnetic interference (EMI) coupling modes. There are four basic coupling mechanisms: conductive, capacitive, magnetic or inductive, and radiative. Any coupling path can be broken down into one or more of these coupling mechanisms working together. For example the lower path in the diagram involves inductive, conductive and capacitive modes. = Conductive coupling = Conductive coupling occurs when the coupling path between the source and the receptor is formed by direct electrical contact with a conducting body, for example a transmission line, wire, cable, PCB trace or metal enclosure. Conducted noise is also characterised by the way it appears on different conductors: * Common-mode coupling: noise appears in phase (in the same direction) on two conductors. * Differential-mode coupling: noise appears out of phase (in opposite directions) on two conductors. = Inductive coupling = Inductive coupling occurs where the source and receiver are separated by a short distance (typically less than a wavelength). Strictly, \\"Inductive coupling\\" can be of two kinds, electrical induction and magnetic induction. It is common to refer to electrical induction as capacitive coupling, and to magnetic induction as inductive coupling.  Capacitive coupling  Capacitive coupling occurs when a varying electrical field exists between two adjacent conductors typically less than a wavelength apart, inducing a change in voltage on the receiving conductor.  Magnetic coupling  Inductive coupling or magnetic coupling occurs when a varying magnetic field exists between two parallel conductors typically less than a wavelength apart, inducing a change in voltage along the receiving conductor. = Radiative coupling = Radiative coupling or electromagnetic coupling occurs when source and victim are separated by a large distance, typically more than a wavelength. Source and victim act as radio antennas: the source emits or radiates an electromagnetic wave which propagates across the space in between and is picked up or received by the victim. EMI filter for conducted emission suppression  EMC control  The damaging effects of electromagnetic interference pose unacceptable risks in many areas of technology, and it is necessary to control such interference and reduce the risks to acceptable levels. The control of electromagnetic interference (EMI) and assurance of EMC comprises a series of related disciplines: * Characterising the threat. * Setting standards for emission and susceptibility levels. * Design for standards compliance. * Testing for standards compliance. For a complex or novel piece of equipment, this may require the production of a dedicated EMC control plan summarizing the application of the above and specifying additional documents required. = Characterising the threat = Characterisation of the problem requires understanding of: * The interference source and signal. * The coupling path to the victim. * The nature of the victim both electrically and in terms of the significance of malfunction. The risk posed by the threat is usually statistical in nature, so much of the work in threat characterisation and standards setting is based on reducing the probability of disruptive EMI to an acceptable level, rather than its assured elimination. = Laws and regulators =  Regulatory and standards bodies  Several organizations, both national and international, work to promote international co-operation on standardization (harmonization), including publishing various EMC standards. Where possible, a standard developed by one organization may be adopted with little or no change by others. This helps for example to harmonize national standards across Europe. International standards organizations include: * International Electrotechnical Commission (IEC), which has several committees working full-time on EMC issues. These are: ** Technical Committee 77 (TC77), working on electromagnetic compatibility between equipment including networks. ** Comit√© International Sp√©cial des Perturbations Radio√©lectriques (CISPR), or International Special Committee on Radio Interference. ** The Advisory Committee on Electromagnetic Compatibility (ACEC) co-ordinates the IEC's work on EMC between these committees. * International Organization for Standardization (ISO), which publishes standards for the automotive industry. Among the main national organizations are: * Europe: ** Comit√© Europ√©en de Normalisation (CEN) or European Committee for Standardization). ** Comit√© Europ√©en de Normalisation Electrotechniques (CENELEC) or European Committee for Electrotechnical Standardisation. ** European Telecommunications Standards Institute (ETSI). * United States: ** The Federal Communications Commission (FCC). ** The Society of Automotive Engineers (SAE). ** The Radio Technical Commission for Aeronautics (RTCA); see DO-160 * Britain: The British Standards Institution (BSI). * Germany: The Verband der Elektrotechnik, Elektronik und Informationstechnik (VDE) or Association for Electrical, Electronic and Information Technologies.  Laws  Compliance with national or international standards is usually laid down by laws passed by individual nations. Different nations can require compliance with different standards. In European law, manufacturers of electronic devices are advised to run EMC tests in order to comply with compulsory CE-labeling. EU directive 2004/108/EC (previously 89/336/EEC) on EMC defines the rules for the distribution of electric devices within the European Union. More are given in the list of EMC directives. In 2019, the USA adopted a program for the protection of critical infrastructure against an electromagnetic pulse, whether caused by a geomagnetic storm or a high-altitude nuclear weapon. = EMC design = A TV tuner card showing many small bypass capacitors and three metal shields: the PCI bracket, the metal box with two coax inputs, and the shield for the S-Video connector Electromagnetic noise is produced in the source due to rapid current and voltage changes, and spread via the coupling mechanisms described earlier. Breaking a coupling path is equally effective at either the start or the end of the path, therefore many aspects of good EMC design practice apply equally to potential emitters and to potential victims. A design which easily couples energy to the outside world will equally easily couple energy in and will be susceptible. A single improvement will often reduce both emissions and susceptibility.  Grounding and shielding  Grounding and shielding aim to reduce emissions or divert EMI away from the victim by providing an alternative, low-impedance path. Techniques include: * Grounding or earthing schemes such as star earthing for audio equipment or ground planes for RF. The scheme must also satisfy safety regulations. * Shielded cables, where the signal wires are surrounded by an outer conductive layer that is grounded at one or both ends. * Shielded housings. A conductive metal housing will act as an interference shield. In order to access the interior, such a housing is typically made in sections (such as a box and lid); an RF gasket may be used at the joints to reduce the amount of interference that leaks through. RF gaskets come in various types. A plain metal gasket may be either braided wire or a flat strip slotted to create many springy \\"fingers\\". Where a waterproof seal is required, a flexible elastomeric base may be impregnated with chopped metal fibers dispersed into the interior or long metal fibers covering the surface or both.  Other general measures  * Decoupling or filtering at critical points such as cable entries and high-speed switches, using RF chokes and/or RC elements. A line filter implements these measures between a device and a line. * Transmission line techniques for cables and wiring, such as balanced differential signal and return paths, and impedance matching. * Avoidance of antenna structures such as loops of circulating current, resonant mechanical structures, unbalanced cable impedances or poorly grounded shielding. * Eliminating spurious rectifying junctions that can form between metal structures around and near transmitter installations. Such junctions in combination with unintentional antenna structures can radiate harmonics of the transmitter frequency.  Emissions suppression  waterfall diagram over a few minutes Additional measures to reduce emissions include: * Avoid unnecessary switching operations. Necessary switching should be done as slowly as is technically possible. * Noisy circuits (with a lot of switching activity) should be physically separated from the rest of the design. * High peaks can be avoided by using the spread spectrum method, in which different parts of the circuit emit at different frequencies. * Harmonic wave filters. * Design for operation at lower signal levels, reducing the energy available for emission.  Susceptibility hardening  Additional measures to reduce susceptibility include: * Fuses, trip switches and circuit breakers. * Transient absorbers. * Design for operation at higher signal levels, reducing the relative noise level in comparison. * Error-correction techniques in digital circuitry. These may be implemented in hardware, software or a combination of both. * Differential signaling or other common-mode noise techniques for signal routing = EMC testing = Testing is required to confirm that a particular device meets the required standards. It divides broadly into emissions testing and susceptibility testing. Open-area test sites, or OATS, are the reference sites in most standards. They are especially useful for emissions testing of large equipment systems. However RF testing of a physical prototype is most often carried out indoors, in a specialised EMC test chamber. Types of chamber include anechoic, reverberation and the gigahertz transverse electromagnetic cell (GTEM cell). Sometimes computational electromagnetics simulations are used to test virtual models. Like all compliance testing, it is important that the test equipment, including the test chamber or site and any software used, be properly calibrated and maintained. Typically, a given run of tests for a particular piece of equipment will require an EMC test plan and follow-up test report. The full test program may require the production of several such documents.  Emissions testing  Emissions are typically measured for radiated field strength and where appropriate for conducted emissions along cables and wiring. Inductive (magnetic) and capacitive (electric) field strengths are near-field effects, and are only important if the device under test (DUT) is designed for location close to other electrical equipment. For conducted emissions, typical transducers include the LISN (line impedance stabilisation network) or AMN (artificial mains network) and the RF current clamp. For radiated emission measurement, antennas are used as transducers. Typical antennas specified include dipole, biconical, log-periodic, double ridged guide and conical log-spiral designs. Radiated emissions must be measured in all directions around the DUT. Specialized EMI test receivers or EMI analysers are used for EMC compliance testing. These incorporate bandwidths and detectors as specified by international EMC standards. An EMI receiver may be based on a spectrum analyser to measure the emission levels of the DUT across a wide band of frequencies (frequency domain), or on a tunable narrower-band device which is swept through the desired frequency range. EMI receivers along with specified transducers can often be used for both conducted and radiated emissions. Pre-selector filters may also be used to reduce the effect of strong out-of-band signals on the front-end of the receiver. Some pulse emissions are more usefully characterized using an oscilloscope to capture the pulse waveform in the time domain.  Susceptibility testing  Radiated field susceptibility testing typically involves a high-powered source of RF or EM energy and a radiating antenna to direct the energy at the potential victim or device under test (DUT). Conducted voltage and current susceptibility testing typically involves a high-powered signal generator, and a current clamp or other type of transformer to inject the test signal. Transient or EMP signals are used to test the immunity of the DUT against powerline disturbances including surges, lightning strikes and switching noise.EMC Testing and Standards in Transient Immunity Testing, RF Immunity. Electronics-project-design.com. Retrieved on 2011-07-19. In motor vehicles, similar tests are performed on battery and signal lines.ISO 7637-2:2004/Amd 1:2008. Iso.org (2011-03-01). Retrieved on 2011-07-19.ISO 7637-3:2007 ‚Äì Road vehicles ‚Äì Electrical disturbances from conduction and coupling ‚Äì Part 3: Electrical transient transmission by capacitive and inductive coupling via lines other than supply lines. Iso.org (2010-09-06). Retrieved on 2011-07-19. The transient pulse may be generated digitally and passed through a broadband pulse amplifier, or applied directly to the transducer from a specialised pulse generator. Electrostatic discharge testing is typically performed with a piezo spark generator called an \\"ESD pistol\\". Higher energy pulses, such as lightning or nuclear EMP simulations, can require a large current clamp or a large antenna which completely surrounds the DUT. Some antennas are so large that they are located outdoors, and care must be taken not to cause an EMP hazard to the surrounding environment.  History  =Origins= The earliest EMC issue was lightning strike (lightning electromagnetic pulse, or LEMP) on ships and buildings. Lightning rods or lightning conductors began to appear in the mid-18th century. With the advent of widespread electricity generation and power supply lines from the late 19th century on, problems also arose with equipment short- circuit failure affecting the power supply, and with local fire and shock hazard when the power line was struck by lightning. Power stations were provided with output circuit breakers. Buildings and appliances would soon be provided with input fuses, and later in the 20th century miniature circuit breakers (MCB) would come into use. =Early twentieth century= It may be said that radio interference and its correction arose with the first spark-gap experiment of Marconi in the late 1800s. As radio communications developed in the first half of the 20th century, interference between broadcast radio signals began to occur and an international regulatory framework was set up to ensure interference-free communications. Switching devices became commonplace through the middle of the 20th century, typically in petrol powered cars and motorcycles but also in domestic appliances such as thermostats and refrigerators. This caused transient interference with domestic radio and (after World War II) TV reception, and in due course laws were passed requiring the suppression of such interference sources. ESD problems first arose with accidental electric spark discharges in hazardous environments such as coal mines and when refuelling aircraft or motor cars. Safe working practices had to be developed. =Postwar period= After World War II the military became increasingly concerned with the effects of nuclear electromagnetic pulse (NEMP), lightning strike, and even high-powered radar beams, on vehicle and mobile equipment of all kinds, and especially aircraft electrical systems. When high RF emission levels from other sources became a potential problem (such as with the advent of microwave ovens), certain frequency bands were designated for Industrial, Scientific and Medical (ISM) use, allowing emission levels limited only by thermal safety standards. A variety of issues such as sideband and harmonic emissions, broadband sources, and the ever-increasing popularity of electrical switching devices and their victims, resulted in a steady development of standards and laws. From the late 1970s, the popularity of modern digital circuitry rapidly grew. As the technology developed, with ever-faster switching speeds (increasing emissions) and lower circuit voltages (increasing susceptibility), EMC increasingly became a source of concern. Many more nations became aware of EMC as a growing problem and issued directives to the manufacturers of digital electronic equipment, which set out the essential manufacturer requirements before their equipment could be marketed or sold. Organizations in individual nations, across Europe and worldwide, were set up to maintain these directives and associated standards. In 1979 the American FCC published a regulation that required the electromagnetic emissions of all \\"digital devices\\" to be below certain limits. This regulatory environment led to a sharp growth in the EMC industry supplying specialist devices and equipment, analysis and design software, and testing and certification services. Low-voltage digital circuits, especially CMOS transistors, became more susceptible to ESD damage as they were miniaturised and, despite the development of on-chip hardening techniques, a new ESD regulatory regime had to be developed. =Modern era= From the 1980s on the explosive growth in mobile communications and broadcast media channels put huge pressure on the available airspace. Regulatory authorities began squeezing band allocations closer and closer together, relying on increasingly sophisticated EMC control methods, especially in the digital communications domain, to keep cross-channel interference to acceptable levels. Digital systems are inherently less susceptible than analogue systems, and also offer far easier ways (such as software) to implement highly sophisticated protection and error-correction measures. In 1985 the USA released the ISM bands for low-power mobile digital communications, leading to the development of Wi-Fi and remotely-operated car door keys. This approach relies on the intermittent nature of ISM interference and use of sophisticated error-correction methods to ensure lossless reception during the quiet gaps between any bursts of interference.  EMC test equipment manufacturers (alphabetic)  * Aeroflex * Anritsu * Keysight (formerly Agilent and before that the test and measurement division of Hewlett-Packard) * MILMEGA * National Instruments * Rohde & Schwarz * Tektronix * Teseq (formerly Schaffner Testsystems) * W√ºrth  See also  * Conducted electromagnetic interference * Crosstalk * EMC-aware programming * IEEE Electromagnetic Compatibility Society * International Commission on Non- Ionizing Radiation Protection (ICNIRP) * List of common EMC test standards * Television interference  References   External links  = Web sites = * Automotive EMC Network * EMC-Directive European Commission ‚Äì Harmonised standards for EMC * European EMI and EMC Conformity Assessment * Federal Communications Commission * News and information on Electromagnetic Compatibility regulations * Radio Technical Commission for Aeronautics * Summary of EU standards by equipment type =General introductions= * What is EMC? YouTube video. * Introduction to EMC * Basics in EMC/EMI and Powerquality =Specific topics= * Analog, RF & EMC Considerations in Printed Wiring Board Design * Application Note: Design for EMC Compliance * Design for EMC - Effects of Via Slots, Split Planes,Gaps and Return Paths on Clock Signal * EMC Design Fundamentals * EMC Design Guidelines * EMC engineering practices for panel builders * EMC Resources (Clemson University) * Fundamentals of the Plane Electromagnetic Shield ","title":"Electromagnetic compatibility"},{"id":"41094","text":"In telecommunication, the term electromagnetic environment (EME) has the following meanings: #For a telecommunications system, the spatial distribution of electromagnetic fields surrounding a given site. The electromagnetic environment may be expressed in terms of the spatial and temporal distribution of electric field strength (volts per metre), irradiance (watts per square metre), or energy density (joules per cubic metre). #The resulting product of the power and time distribution, in various frequency ranges, of the radiated or conducted electromagnetic emission levels that may be encountered by a military force, system, or platform when performing its assigned mission in its intended operational environment. It is the sum of electromagnetic interference; electromagnetic pulse; hazards of electromagnetic radiation to personnel, ordnance, and volatile materials; and natural phenomena effects of lightning and p-static. Sources * * Category:Electromagnetic radiation Category:Telecommunications engineering Category:Electromagnetic compatibility Category:Reliability engineering ","title":"Electromagnetic environment"},{"id":"41096","text":"In telecommunication, electromagnetic interference control (EMI) is the control of radiated and conducted energy such that emissions that are unnecessary for system, subsystem, or equipment operation are reduced, minimized, or eliminated. Note: Electromagnetic radiated and conducted emissions are controlled regardless of their origin within the system, subsystem, or equipment. Successful EMI control with effective susceptibility control leads to electromagnetic compatibility. References See also  * Radio resource management Category:Interference ","title":"Electromagnetic interference control"},{"id":"41097","text":"A nuclear electromagnetic pulse (commonly abbreviated as nuclear EMP, or NEMP) is a burst of electromagnetic radiation created by a nuclear explosion. The resulting rapidly varying electric and magnetic fields may couple with electrical and electronic systems to produce damaging current and voltage surges. The specific characteristics of a particular nuclear EMP event vary according to a number of factors, the most important of which is the altitude of the detonation. The term \\"electromagnetic pulse\\" generally excludes optical (infrared, visible, ultraviolet) and ionizing (such as X-ray and gamma radiation) ranges. In military terminology, a nuclear warhead detonated tens to hundreds of miles above the Earth's surface is known as a high-altitude electromagnetic pulse (HEMP) device. Effects of a HEMP device depend on factors including the altitude of the detonation, energy yield, gamma ray output, interactions with the Earth's magnetic field and electromagnetic shielding of targets.  History  The fact that an electromagnetic pulse is produced by a nuclear explosion was known in the earliest days of nuclear weapons testing. The magnitude of the EMP and the significance of its effects, however, were not immediately realized.Broad, William J. \\"Nuclear Pulse (I): Awakening to the Chaos Factor\\", Science. 29 May 1981 212: 1009-1012 During the first United States nuclear test on 16 July 1945, electronic equipment was shielded because Enrico Fermi expected the electromagnetic pulse. The official technical history for that first nuclear test states, \\"All signal lines were completely shielded, in many cases doubly shielded. In spite of this many records were lost because of spurious pickup at the time of the explosion that paralyzed the recording equipment.\\"Bainbridge, K.T., (Report LA-6300-H), Los Alamos Scientific Laboratory. May 1976. p. 53 Trinity During British nuclear testing in 1952‚Äì1953, instrumentation failures were attributed to \\"radioflash\\", which was their term for EMP.Baum, Carl E., IEEE Trans. Electromagn. Compat. Vol. 49, No. 2. pp. 211‚Äì218. May 2007. Reminiscences of High-Power ElectromagneticsBaum, Carl E., Proceedings of the IEEE, Vol. 80, No. 6, pp. 789‚Äì817. June 1992 \\"From the Electromagnetic Pulse to High-Power Electromagnetics\\" The first openly reported observation of the unique aspects of high-altitude nuclear EMP occurred during the helium balloon-lofted Yucca nuclear test of the Hardtack I series on 28 April 1958. In that test, the electric field measurements from the 1.7 kiloton weapon exceeded the range to which the test instruments were adjusted and was estimated to be about five times the limits to which the oscilloscopes were set. The Yucca EMP was initially positive-going, whereas low-altitude bursts were negative going pulses. Also, the polarization of the Yucca EMP signal was horizontal, whereas low-altitude nuclear EMP was vertically polarized. In spite of these many differences, the unique EMP results were dismissed as a possible wave propagation anomaly.Defense Atomic Support Agency. 23 September 1959. \\"Operation Hardtack Preliminary Report. Technical Summary of Military Effects. Report ADA369152\\". pp. 346‚Äì350. The high-altitude nuclear tests of 1962, as discussed below, confirmed the unique results of the Yucca high-altitude test and increased the awareness of high-altitude nuclear EMP beyond the original group of defense scientists. The larger scientific community became aware of the significance of the EMP problem after a three-article series on nuclear EMP was published in 1981 by William J. Broad in Science.Broad, William J. \\"Nuclear Pulse (II): Ensuring Delivery of the Doomsday Signal\\", Science. 5 June 1981 212: 1116-1120Broad, William J. \\"Nuclear Pulse (III): Playing a Wild Card\\", Science. 12 June 1981 212: 1248-1251 = Starfish Prime = In July 1962, the US carried out the Starfish Prime test, exploding a bomb above the mid-Pacific Ocean. This demonstrated that the effects of a high-altitude nuclear explosion were much larger than had been previously calculated. Starfish Prime made those effects known to the public by causing electrical damage in Hawaii, about away from the detonation point, knocking out about 300 streetlights, setting off numerous burglar alarms and damaging a microwave link. Starfish Prime was the first success in the series of United States high-altitude nuclear tests in 1962 known as Operation Fishbowl. Subsequent tests gathered more data on the high-altitude EMP phenomenon. The Bluegill Triple Prime and Kingfish high-altitude nuclear tests of October and November 1962 in Operation Fishbowl provided data that was clear enough to enable physicists to accurately identify the physical mechanisms behind the electromagnetic pulses.Longmire, Conrad L., NBC Report, Fall/Winter, 2004. pp. 47‚Äì51. U.S. Army Nuclear and Chemical Agency \\"Fifty Odd Years of EMP\\" The EMP damage of the Starfish Prime test was quickly repaired due, in part, to the fact that the EMP over Hawaii was relatively weak compared to what could be produced with a more intense pulse, and in part due to the relative ruggedness (compared to today) of Hawaii's electrical and electronic infrastructure in 1962.Theoretical Notes ‚Äì Note 353, March 1985, \\"EMP on Honolulu from the Starfish Event\\" Conrad L. Longmire ‚Äì Mission Research Corporation The relatively small magnitude of the Starfish Prime EMP in Hawaii (about 5.6 kilovolts/metre) and the relatively small amount of damage (for example, only one to three percent of streetlights extinguished)Rabinowitz, Mario (1987) \\"Effect of the Fast Nuclear Electromagnetic Pulse on the Electric Power Grid Nationwide: A Different View\\". IEEE Trans. Power Delivery, PWRD-2, 1199-1222 led some scientists to believe, in the early days of EMP research, that the problem might not be significant. Later calculations showed that if the Starfish Prime warhead had been detonated over the northern continental United States, the magnitude of the EMP would have been much larger (22 to 30 kV/m) because of the greater strength of the Earth's magnetic field over the United States, as well as its different orientation at high latitudes. These calculations, combined with the accelerating reliance on EMP-sensitive microelectronics, heightened awareness that EMP could be a significant problem. = Soviet Test 184 = In 1962, the Soviet Union also performed three EMP-producing nuclear tests in space over Kazakhstan, the last in the \\"Soviet Project K nuclear tests\\".Zak, Anatoly \\"The K Project: Soviet Nuclear Tests in Space\\", The Nonproliferation Review, Volume 13, Issue, 1 March 2006, pp. 143‚Äì150 Although these weapons were much smaller (300 kiloton) than the Starfish Prime test, they were over a populated, large land mass and at a location where the Earth's magnetic field was greater; the damage caused by the resulting EMP was reportedly much greater than in Starfish Prime. The geomagnetic storm‚Äìlike E3 pulse from Test 184 induced a current surge in a long underground power line that caused a fire in the power plant in the city of Karaganda. After the collapse of the Soviet Union, the level of this damage was communicated informally to US scientists.Subject: US-Russian meeting ‚Äì HEMP effects on national power grid & telecommunications From: Howard Seguine, 17 Feb. 1995 Memorandum for Record For a few years US and Russian scientists collaborated on the HEMP phenomenon. Funding was secured to enable Russian scientists to report on some of the Soviet EMP results in international scientific journals.Pfeffer, Robert and Shaeffer, D. Lynn. Combating WMD Journal, (2009) Issue 3. pp. 33‚Äì38. \\"A Russian Assessment of Several USSR and US HEMP Tests\\" As a result, formal documentation of some of the EMP damage in Kazakhstan existsGreetsai, Vasily N., et al. IEEE Trans. Electromagn. Compat. Vol. 40, No. 4, November 1998, \\"Response of Long Lines to Nuclear High- Altitude Electromagnetic Pulse (HEMP)\\"Loborev, Vladimir M. \\"Up to Date State of the NEMP Problems and Topical Research Directions\\", Electromagnetic Environments and Consequences: Proceedings of the EUROEM 94 International Symposium, Bordeaux, France, 30 May ‚Äì 3 June 1994, pp. 15‚Äì21 but is still sparse in the open scientific literature. For one of the K Project tests, Soviet scientists instrumented a section of telephone line in the area that they expected to be affected by the pulse. The monitored telephone line was divided into sub-lines of in length, separated by repeaters. Each sub-line was protected by fuses and by gas-filled overvoltage protectors. The EMP from the 22 October (K-3) nuclear test (also known as Test 184) blew all of the fuses and fired all of the overvoltage protectors in all of the sub-lines. Published reports, including a 1998 IEEE article, have stated that there were significant problems with ceramic insulators on overhead electrical power lines during the tests. A 2010 technical report written for Oak Ridge National Laboratory stated that \\"Power line insulators were damaged, resulting in a short circuit on the line and some lines detaching from the poles and falling to the ground.\\"  Characteristics  Nuclear EMP is a complex multi-pulse, usually described in terms of three components, as defined by the International Electrotechnical Commission (IEC).Electromagnetic compatibility (EMC), Part 2: Environment, Section 9: Description of HEMP environment ‚Äì Radiated disturbance. Basic EMC publication, IEC 61000-2-9 The three components of nuclear EMP, as defined by the IEC, are called \\"E1\\", \\"E2\\" and \\"E3\\".\\"Report of the Commission to Assess the Threat to the United States from Electromagnetic Pulse (EMP) Attack\\" Volume 1: Executive Report 2004 = E1 = The E1 pulse is the very fast component of nuclear EMP. E1 is a brief but intense electromagnetic field that induces high voltages in electrical conductors. E1 causes most of its damage by causing electrical breakdown voltages to be exceeded. E1 can destroy computers and communications equipment and it changes too quickly (nanoseconds) for ordinary surge protectors to provide effective protection from it. Fast-acting surge protectors (such as those using TVS diodes) will block the E1 pulse. The mechanism for a burst EMP: gamma rays hit the atmosphere between altitude, ejecting electrons which are then deflected sideways by the Earth's magnetic field. This makes the electrons radiate EMP over a large area. Because of the curvature and downward tilt of Earth's magnetic field over the USA, the maximum EMP occurs south of the detonation and the minimum occurs to the north.U.S. Army White Sands Missile Range, Nuclear Environment Survivability. Report ADA278230. p. D-7. 15 April 1994. E1 is produced when gamma radiation from the nuclear detonation ionizes (strips electrons from) atoms in the upper atmosphere. This is known as the Compton effect and the resulting current is called the \\"Compton current\\". The electrons travel in a generally downward direction at relativistic speeds (more than 90 percent of the speed of light). In the absence of a magnetic field, this would produce a large, radial pulse of electric current propagating outward from the burst location confined to the source region (the region over which the gamma photons are attenuated). The Earth's magnetic field exerts a force on the electron flow at a right angle to both the field and the particles' original vector, which deflects the electrons and leads to synchrotron radiation. Because the outward traveling gamma pulse is propagating at the speed of light, the synchrotron radiation of the Compton electrons adds coherently, leading to a radiated electromagnetic signal. This interaction produces a large, brief, pulse.Longmire, Conrad L. LLNL-9323905, Lawrence Livermore National Laboratory. June 1986 \\"Justification and Verification of High-Altitude EMP Theory, Part 1\\" (Retrieved 2010-15-12) Several physicists worked on the problem of identifying the mechanism of the HEMP E1 pulse. The mechanism was finally identified by Conrad Longmire of Los Alamos National Laboratory in 1963. Longmire gives numerical values for a typical case of E1 pulse produced by a second-generation nuclear weapon such as those of Operation Fishbowl. The typical gamma rays given off by the weapon have an energy of about 2MeV (mega-electron volts). The gamma rays transfer about half of their energy to the ejected free electrons, giving an energy of about 1MeV. In a vacuum and absent a magnetic field, the electrons would travel with a current density of tens of amperes per square metre. Because of the downward tilt of the Earth's magnetic field at high latitudes, the area of peak field strength is a U-shaped region to the equatorial side of the detonation. As shown in the diagram, for nuclear detonations in the Northern Hemisphere, this U-shaped region is south of the detonation point. Near the equator, where the Earth's magnetic field is more nearly horizontal, the E1 field strength is more nearly symmetrical around the burst location. At geomagnetic field strengths typical of the mid latitudes, these initial electrons spiral around the magnetic field lines with a typical radius of about . These initial electrons are stopped by collisions with air molecules at an average distance of about . This means that most of the electrons are stopped by collisions with air molecules before completing a full spiral around the field lines. This interaction of the negatively charged electrons with the magnetic field radiates a pulse of electromagnetic energy. The pulse typically rises to its peak value in some five nanoseconds. Its magnitude typically decays by half within 200 nanoseconds. (By the IEC definition, this E1 pulse ends 1000 nanoseconds after it begins.) This process occurs simultaneously on about 1025 electrons. The simultaneous action of the electrons causes the resulting pulse from each electron to radiate coherently, adding to produce a single large amplitude, but narrow, radiated pulse. Secondary collisions cause subsequent electrons to lose energy before they reach ground level. The electrons generated by these subsequent collisions have so little energy that they do not contribute significantly to the E1 pulse. These 2 MeV gamma rays typically produce an E1 pulse near ground level at moderately high latitudes that peaks at about 50,000 volts per metre. The ionization process in the mid-stratosphere causes this region to become an electrical conductor, a process that blocks the production of further electromagnetic signals and causes the field strength to saturate at about 50,000 volts per metre. The strength of the E1 pulse depends upon the number and intensity of the gamma rays and upon the rapidity of the gamma ray burst. Strength is also somewhat dependent upon altitude. There are reports of \\"super-EMP\\" nuclear weapons that are able to exceed the 50,000 volt per metre limit by unspecified mechanisms. The reality and possible construction details of these weapons are classified and are, therefore, unconfirmed in the open scientific literatureMarch 8, 2005 \\"Statement, Dr. Peter Vincent Pry, EMP Commission Staff, before the United States Senate Subcommittee on Terrorism, Technology and Homeland Security\\" = E2 = The E2 component is generated by scattered gamma rays and inelastic gammas produced by neutrons. This E2 component is an \\"intermediate time\\" pulse that, by IEC definition, lasts from about one microsecond to one second after the explosion. E2 has many similarities to lightning, although lightning-induced E2 may be considerably larger than a nuclear E2. Because of the similarities and the widespread use of lightning protection technology, E2 is generally considered to be the easiest to protect against. According to the United States EMP Commission, the main problem with E2 is that it immediately follows E1, which may have damaged the devices that would normally protect against E2. The EMP Commission Executive Report of 2004 states, \\"In general, it would not be an issue for critical infrastructure systems since they have existing protective measures for defense against occasional lightning strikes. The most significant risk is synergistic, because the E2 component follows a small fraction of a second after the first component's insult, which has the ability to impair or destroy many protective and control features. The energy associated with the second component thus may be allowed to pass into and damage systems.\\"Report of the Commission to Assess the Threat to the United States from Electromagnetic Pulse (EMP) Attack. Volume 1. Executive Report. 2004. p. 6. = E3 = The E3 component is different from E1 and E2. E3 is a much slower pulse, lasting tens to hundreds of seconds. It is caused by the nuclear detonation's temporary distortion of the Earth's magnetic field. The E3 component has similarities to a geomagnetic storm caused by a solar flare.High-Altitude Electromagnetic Pulse (HEMP): A Threat to Our Way of Life, 09.07, By William A. Radasky, Ph.D., P.E. - IEEEReport of the Commission to Assess the Threat to the United States from Electromagnetic Pulse (EMP) Attack Like a geomagnetic storm, E3 can produce geomagnetically induced currents in long electrical conductors, damaging components such as power line transformers.Report Meta-R-321: \\"The Late-Time (E3) High-Altitude Electromagnetic Pulse (HEMP) and Its Impact on the U.S. Power Grid \\" January 2010. Written by Metatech Corporation for Oak Ridge National Laboratory. Because of the similarity between solar-induced geomagnetic storms and nuclear E3, it has become common to refer to solar- induced geomagnetic storms as \\"Solar EMP\\". \\"Solar EMP\\" does not include E1 or E2 components.  Generation  Factors that control weapon effectiveness include altitude, yield, construction details, target distance, intervening geographical features, and local strength of the Earth's magnetic field. = Weapon altitude = How the peak EMP on the ground varies with the weapon yield and burst altitude. The yield here is the prompt gamma ray output measured in kilotons. This varies from 0.115‚Äì0.5% of the total weapon yield, depending on weapon design. The 1.4 Mt total yield 1962 Starfish Prime test had a gamma output of 0.1%, hence 1.4 kt of prompt gamma rays. (The blue 'pre- ionisation' curve applies to certain types of thermonuclear weapons, for which gamma and x-rays from the primary fission stage ionise the atmosphere and make it electrically conductive before the main pulse from the thermonuclear stage. The pre-ionisation in some situations can literally short out part of the final EMP, by allowing a conduction current to immediately oppose the Compton current of electrons.)Louis W. Seiler, Jr. A Calculational Model for High Altitude EMP. Air Force Institute of Technology. Report ADA009208. pp. 33, 36. March 1975 Glasstone, Samuel and Dolan, Philip J., 'The Effects of Nuclear Weapons.] Chapter 11. 1977. United States Department of Defense. According to an internet primer published by the Federation of American ScientistsFederation of American Scientists. \\"Nuclear Weapon EMP Effects\\" : A high-altitude nuclear detonation produces an immediate flux of gamma rays from the nuclear reactions within the device. These photons in turn produce high energy free electrons by Compton scattering at altitudes between (roughly) 20 and 40 km. These electrons are then trapped in the Earth's magnetic field, giving rise to an oscillating electric current. This current is asymmetric in general and gives rise to a rapidly rising radiated electromagnetic field called an electromagnetic pulse (EMP). Because the electrons are trapped essentially simultaneously, a very large electromagnetic source radiates coherently. : The pulse can easily span continent-sized areas, and this radiation can affect systems on land, sea, and air. ... A large device detonated at 400‚Äì500 km (250 to 312 miles) over Kansas would affect all of the continental U.S. The signal from such an event extends to the visual horizon as seen from the burst point. Thus, for equipment to be affected, the weapon needs to be above the visual horizon. The altitude indicated above is greater than that of the International Space Station and many low Earth orbit satellites. Large weapons could have a dramatic impact on satellite operations and communications such as occurred during Operation Fishbowl. The damaging effects on orbiting satellites are usually due to factors other than EMP. In the Starfish Prime nuclear test, most damage was to the satellites' solar panels while passing through radiation belts created by the explosion. For detonations within the atmosphere, the situation is more complex. Within the range of gamma ray deposition, simple laws no longer hold as the air is ionised and there are other EMP effects, such as a radial electric field due to the separation of Compton electrons from air molecules, together with other complex phenomena. For a surface burst, absorption of gamma rays by air would limit the range of gamma ray deposition to approximately , while for a burst in the lower-density air at high altitudes, the range of deposition would be far greater. = Weapon yield = Typical nuclear weapon yields used during Cold War planning for EMP attacks were in the range of 1 to 10 megatonsU.S. Congressional hearing Transcript H.S.N.C No. 105-18, p. 39 This is roughly 50 to 500 times the size of the Hiroshima and Nagasaki bombs. Physicists have testified at United States Congressional hearings that weapons with yields of 10 kilotons or less can produce a large EMP.U.S. Congressional hearing Transcript H.A.S.C. No. 106-31, p. 48 The EMP at a fixed distance from an explosion increases at most as the square root of the yield (see the illustration to the right). This means that although a 10 kiloton weapon has only 0.7% of the energy release of the 1.44-megaton Starfish Prime test, the EMP will be at least 8% as powerful. Since the E1 component of nuclear EMP depends on the prompt gamma ray output, which was only 0.1% of yield in Starfish Prime but can be 0.5% of yield in low yield pure nuclear fission weapons, a 10 kiloton bomb can easily be 5 x 8% = 40% as powerful as the 1.44 megaton Starfish Prime at producing EMP. The total prompt gamma ray energy in a fission explosion is 3.5% of the yield, but in a 10 kiloton detonation the triggering explosive around the bomb core absorbs about 85% of the prompt gamma rays, so the output is only about 0.5% of the yield. In the thermonuclear Starfish Prime the fission yield was less than 100% and the thicker outer casing absorbed about 95% of the prompt gamma rays from the pusher around the fusion stage. Thermonuclear weapons are also less efficient at producing EMP because the first stage can pre-ionize the air which becomes conductive and hence rapidly shorts out the Compton currents generated by the fusion stage. Hence, small pure fission weapons with thin cases are far more efficient at causing EMP than most megaton bombs. This analysis, however, only applies to the fast E1 and E2 components of nuclear EMP. The geomagnetic storm-like E3 component of nuclear EMP is more closely proportional to the total energy yield of the weapon. = Target distance = In nuclear EMP all of the components of the electromagnetic pulse are generated outside of the weapon. For high-altitude nuclear explosions, much of the EMP is generated far from the detonation (where the gamma radiation from the explosion hits the upper atmosphere). This electric field from the EMP is remarkably uniform over the large area affected. According to the standard reference text on nuclear weapons effects published by the U.S. Department of Defense, \\"The peak electric field (and its amplitude) at the Earth's surface from a high-altitude burst will depend upon the explosion yield, the height of the burst, the location of the observer, and the orientation with respect to the geomagnetic field. As a general rule, however, the field strength may be expected to be tens of kilovolts per metre over most of the area receiving the EMP radiation.\\" The text also states that, \\"... over most of the area affected by the EMP the electric field strength on the ground would exceed 0.5Emax. For yields of less than a few hundred kilotons, this would not necessarily be true because the field strength at the Earth's tangent could be substantially less than 0.5Emax.\\" (Emax refers to the maximum electric field strength in the affected area.) In other words, the electric field strength in the entire area that is affected by the EMP will be fairly uniform for weapons with a large gamma ray output. For smaller weapons, the electric field may fall at a faster rate as distance increases.  Effects  An energetic EMP can temporarily upset or permanently damage electronic equipment by generating high voltage and high current surges; semiconductor components are particularly at risk. The effects of damage can range from imperceptible to the eye, to devices literally blowing apart. Cables, even if short, can act as antennas to transmit pulse energy to equipment. = Vacuum tube vs. solid state electronics = Older, vacuum tube (valve) based equipment is generally much less vulnerable to nuclear EMP than solid state equipment, which is much more susceptible to damage by large, brief voltage and current surges. Soviet Cold War-era military aircraft often had avionics based on vacuum tubes because solid-state capabilities were limited and vacuum-tube gear was believed to be more likely to survive. Other components in vacuum tube circuitry can be damaged by EMP. Vacuum tube equipment was damaged in the 1962 testing. The solid state PRC-77 VHF manpackable two-way radio survived extensive EMP testing.Seregelyi, J.S, et al. Report ADA266412 \\"EMP Hardening Investigation of the PRC-77 Radio Set\\" Retrieved 2009-25-11 The earlier PRC-25, nearly identical except for a vacuum tube final amplification stage, was tested in EMP simulators, but was not certified to remain fully functional. = Electronics in operation vs. inactive = Equipment that is running at the time of an EMP is more vulnerable. Even a low-energy pulse has access to the power source, and all parts of the system are illuminated by the pulse. For example, a high-current arcing path may be created across the power supply, burning out some device along that path. Such effects are hard to predict, and require testing to assess potential vulnerabilities.Report Meta-R-320: \\"The Early-Time (E1) High-Altitude Electromagnetic Pulse (HEMP) and Its Impact on the U.S. Power Grid \\" January 2010. Written by Metatech Corporation for Oak Ridge National Laboratory. Appendix: E1 HEMP Myths = On aircraft = Many nuclear detonations have taken place using aerial bombs. The B-29 aircraft that delivered the nuclear weapons at Hiroshima and Nagasaki did not lose power from electrical damage, because electrons (ejected from the air by gamma rays) are stopped quickly in normal air for bursts below roughly , so they are not significantly deflected by the Earth's magnetic field. If the aircraft carrying the Hiroshima and Nagasaki bombs had been within the intense nuclear radiation zone when the bombs exploded over those cities, then they would have suffered effects from the charge separation (radial) EMP. But this only occurs within the severe blast radius for detonations below about 10 km altitude. During Operation Fishbowl, EMP disruptions were suffered aboard a KC-135 photographic aircraft flying from the detonations at burst altitudes. The vital electronics were less sophisticated than today's and the aircraft was able to land safely. = On cars = An EMP would probably not affect most cars, despite modern cars' heavy use of electronics, because cars' electronic circuits and cabling are likely too short to be affected. In addition, cars' metallic frames provide some protection. However, even a small percentage of cars breaking down due to an electronic malfunction would cause temporary traffic jams. = On small electronics = An EMP has a smaller effect the shorter the length of an electrical conductor; though other factors affect the vulnerability of electronics as well, so no cutoff length determines whether some piece of equipment will survive. However, small electronic devices, such as wristwatches and cell phones, would most likely withstand an EMP. = On humans and animals = Though voltages can accumulate in electrical conductors after an EMP, it will generally not flow out into human or animal bodies, and thus contact is safe.  Post-Cold War attack scenarios  The United States EMP Commission was created by the United States Congress in 2001. The commission is formally known as the Commission to Assess the Threat to the United States from Electromagnetic Pulse (EMP) Attack. The Commission brought together notable scientists and technologists to compile several reports. In 2008, the Commission released the \\"Critical National Infrastructures Report\\". This report describes the likely consequences of a nuclear EMP on civilian infrastructure. Although this report covered the United States, most of the information is applicable to other industrialized countries. The 2008 report was a followup to a more generalized report issued by the commission in 2004. In written testimony delivered to the United States Senate in 2005, an EMP Commission staff member reported: The United States EMP Commission determined that long-known protections are almost completely absent in the civilian infrastructure of the United States and that large parts of US military services were less-protected against EMP than during the Cold War. In public statements, the Commission recommended making electronic equipment and electrical components resistant to EMP ‚Äì and maintaining spare parts inventories that would enable prompt repairs.Ross, Lenard H., Jr. and Mihelic, F. Matthew, \\"Healthcare Vulnerabilities to Electromagnetic Pulse\\" American Journal of Disaster Medicine, Vol. 3, No. 6, pp. 321‚Äì325. November/December 2008. The United States EMP Commission did not look at other nations. In 2011 the Defense Science Board published a report about the ongoing efforts to defend critical military and civilian systems against EMP and other nuclear weapons effects. The United States military services developed, and in some cases published, hypothetical EMP attack scenarios.Miller, Colin R., Major, USAF \\"Electromagnetic Pulse Threats in 2010 \\" Air War College, Air University, United States Air Force, November 2005 In 2016 the Los Alamos Laboratory started phase 0 of a multi-year study (through to phase 3) to investigate EMP's which prepared the strategy to be followed for the rest of the study.Rivera, M.K., Backhaus, S.N., Woodroffe, J.R., Henderson, M.G., Bos, R.J., Nelson, E.M. and Kelic, A., 2016. EMP/GMD Phase 0 Report, A Review of EMP Hazard Environments and Impacts (No. LA-UR-16-28380). Los Alamos National Laboratory (LANL). In 2017 the US department of energy published the \\"DOE Electromagnetic Pulse Resilience Action Plan\\"DOE and partners \\"DOE Electromagnetic Pulse Resilience Action Plan\\" DOE, January, 2017, Edwin Boston published a dissertation on the topicBoston Jr, E.J., 2017. Critical Infrastructure Protection: EMP Impacts on the US Electric Grid (Doctoral dissertation, Utica College). and the EMP Commission published \\"Assessing the threat from electromagnetic pulse (EMP)\\".Assessing the threat from electromagnetic pulse (EMP), the EMP Commission. 2017 The EMP commission was closed in summer 2017.Peter Vincent Pry, Report to the commission to assess the threat to the united states from electromagnetic pulse (EMP) attack life without electricity: storm-induced blackouts and implications for emp attack They found that earlier reports had underestimated the effects of an EMP attack on the national infrastructure and highlighted issues with communications from the DoD due to the classified nature of the material and recommended that the DHS instead of going to the DOE for guidance and direction should directly cooperate with the more knowledgeable parts of the DOE. Several reports are in process of being released to the general public.William Graham, \\"Trump's actions have been critical to defending the US against an EMP attack\\", the Hill, May 2018.  Protecting infrastructure  The problem of protecting civilian infrastructure from electromagnetic pulse has been intensively studied throughout the European Union, and in particular by the United Kingdom.House of Commons Defence Committee, Developing Threats: Electro-Magnetic Pulses (EMP) Tenth Report of Session 2010‚Äì12.Extreme Electromagnetics ‚Äì The Triple Threat to Infrastructure , 14 January 2013 (Proceedings of a seminar) As of 2017, several power utility companies in the United States had been involved in a three-year research program on the impact of HEMP to the United States power grid led by an industry non-profit organization, Electric Power Research Institute (EPRI).  In fiction and popular culture  Especially since the 1980s, nuclear EMP weapons have gained a significant presence in fiction and popular culture. The popular media often depict EMP effects incorrectly, causing misunderstandings among the public and even professionals, and official efforts have been made in the United States to set the record straight. The United States Space Command commissioned science educator Bill Nye to produce a video called \\"Hollywood vs. EMP\\" so that inaccurate Hollywood fiction would not confuse those who must deal with real EMP events. The video is not available to the general public. * Threads, 1984.  See also   References   Sources  * * Vladimir Gurevich \\"Cyber and Electromagnetic Threats in Modern Relay Protection\\" - CRC Press (Taylor & Francis Group), Boca Raton ‚Äì New York ‚Äì London, 2014, 222 p. * Vladimir Gurevich \\"Protection of Substation Critical Equipment Against Intentional Electromagnetic Threats\\" - Wiley, London, 2016, 300 p. * Vladimir Gurevich \\"Protecting Electrical Equipment: Good Practices for Preventing High Altitude Electromagnetic Pulse Impacts\\" - De Gruyter, Berlin, 2019, 400 p.  Further reading  * * A 21st Century Complete Guide to Electromagnetic Pulse (EMP) Attack Threats, Report of the Commission to Assess the Threat to the United States from Electromagnetic ... High-Altitude Nuclear Weapon EMP Attacks (CD-ROM) * Threat posed by electromagnetic pulse (EMP) to U.S. military systems and civil infrastructure: Hearing before the Military Research and Development Subcommittee - first session, hearing held July 16, 1997 (Unknown Binding) * Electromagnetic Pulse Radiation and Protective Techniques * Report of the Commission to Assess the Threat to the United States from Electromagnetic Pulse (EMP) Attack  External links  * * GlobalSecurity.org - Electromagnetic Pulse: From chaos to a manageable solution * Electromagnetic Pulse (EMP) and Tempest Protection for Facilities - U.S. Army Corps of Engineers * EMP data from Starfish nuclear test measured by Richard Wakefield of LANL, and review of evidence pertaining to the effects 1,300 km away in Hawaii, also review of Russian EMP tests of 1962 * Read Congressional Research Service (CRS) Reports regarding HEMP * MIL- STD-188-125-1 * How E-Bombs Work * Commission to Assess the Threat to the United States from Electromagnetic Pulse (EMP) Attack * NEMP and Nuclear plant * U.S. Presidential Executive Order concerning EMP * Protecting Electrical Equipment: good practice for preventing high altitude electromagnetic pulse impacts, De Gruyter, 2019 Category:Electromagnetic radiation Category:Energy weapons Category:Nuclear weapons Category:Electromagnetic compatibility Category:Bombs Category:Electronic warfare Category:Pulsed power ","title":"Nuclear electromagnetic pulse"},{"id":"41098","text":"At sufficiently high flux levels, various bands of electromagnetic radiation have been found to cause deleterious health effects in people. Electromagnetic radiation can be classified into two types: ionizing radiation and non- ionizing radiation, based on the capability of a single photon with more than 10 eV energy to ionize atoms or break chemical bonds. Extreme ultraviolet and higher frequencies, such as X-rays or gamma rays are ionizing, and these pose their own special hazards: see radiation and radiation poisoning. The last quarter of the twentieth century saw a dramatic increase in the number of devices emitting non-ionizing radiation in all segments of society, which resulted in an elevation of health concerns by researchers and clinicians, and an associated interest in government regulation for safety purposes. The most common health hazard of radiation is sunburn, which causes between approximately 100,000 and 1 million new skin cancers annually in the United States. Hazards =Extrinsic= Sufficiently strong electromagnetic radiation (EMR) can cause electric currents in conductive materials that is strong enough to create sparks (electrical arcs) when an induced voltage exceeds the breakdown voltage of the surrounding medium (e.g. air at 3.0 MV/m). These can deliver an electric shock to persons or animals. For example, the radio emissions from transmission lines have occasionally caused shocks to construction workers from nearby equipment, causing OSHA to establish standards for proper handling. EMR-induced sparks can ignite nearby flammable materials or gases, which can be especially hazardous in the vicinity of explosives or pyrotechnics. This risk is commonly referred to as Hazards of Electromagnetic Radiation to Ordnance (HERO) by the United States Navy (USN). United States Military Standard 464A (MIL-STD-464A) mandates assessment of HERO in a system, but USN document OD 30393 provides design principles and practices for controlling electromagnetic hazards to ordnance. The risk related to fueling is known as Hazards of Electromagnetic Radiation to Fuel (HERF). NAVSEA OP 3565 Vol. 1 could be used to evaluate HERF, which states a maximum power density of 0.09 W/m¬≤ for frequencies under 225 MHz (i.e. 4.2 meters for a 40 W emitter). =Intrinsic= Dielectric heating from electromagnetic fields can create a biological hazard. For example, touching or standing around an antenna while a high-power transmitter is in operation can cause severe burns. These are exactly the kind of burns that would be caused inside a microwave oven. The dielectric heating effect varies with the power and the frequency of the electromagnetic energy, as well as the distance to the source. The eyes and testes are particularly susceptible to radio frequency heating due to the paucity of blood flow in these areas that could otherwise dissipate the heat buildup. Radio frequency (RF) energy at power density levels of 1‚Äì10 mW/cm2 or higher can cause measurable heating of tissues. Typical RF energy levels encountered by the general public are well below the level needed to cause significant heating, but certain workplace environments near high power RF sources may exceed safe exposure limits. A measure of the heating effect is the specific absorption rate or SAR, which has units of watts per kilogram (W/kg). The IEEE and many national governments have established safety limits for exposure to various frequencies of electromagnetic energy based on SAR, mainly based on ICNIRP Guidelines, which guard against thermal damage. Low-level exposure The World Health Organization began a research effort in 1996 to study the health effects from the ever-increasing exposure of people to a diverse range of EMR sources. After 30 years of extensive study, science has yet to confirm a health risk from exposure to low-level fields. However, there remain gaps in the understanding of the biological effects, and more research needs to be performed. Studies are being run to examine cells and determine if EM exposure can cause detrimental effects. Animal studies are being used to look for effects impacting more complex physiologies that are similar to humans. Epidemiological studies look for statistical correlations between EM exposure in the field and specific health effects. As of 2019, much of the current work is focused on the study of EM fields in relation to cancer. There are publications which support the existence of complex biological and neurological effects of weaker non-thermal electromagnetic fields (see Bioelectromagnetics), including weak ELF electromagnetic fields and modulated RF and microwave fields. Fundamental mechanisms of the interaction between biological material and electromagnetic fields at non-thermal levels are not fully understood. Effects by frequency Warning sign next to a transmitter with high field strengths While the most acute exposures to harmful levels of electromagnetic radiation are immediately realized as burns, the health effects due to chronic or occupational exposure may not manifest effects for months or years. =Extremely-low frequency= Electric and magnetic fields occur where electricity is generated or distributed in power lines, cables, or electrical appliances. Human responses depend on the field strength, ambient environmental conditions, and individual sensitivity. 7% of volunteers exposed to power-frequency electric fields of high-power, extremely-low-frequency RF with electric field levels in the low kV/m range reported painful currents that flowed to ground through a body contact surface such as the feet, or arced to ground where the body was well insulated.Extremely Low Frequency Fields Environmental Health Criteria Monograph No.238, chapter 5, page 121, WHO A 2002 International Agency for Research on Cancer (IARC) study measured the effect of ELF magnetic fields, and found ‚Äúlimited evidence‚Äù of human carcinogenicity in relation to childhood leukemia, leading the IARC to classify ELF magnetic fields as ‚Äúpossibly carcinogenic to humans‚Äù. The same study found ‚Äúinadequate evidence‚Äù in relation to all other cancers. When IARC measured the effect of ELF electric fields, it found ‚Äúinadequate evidence‚Äù for human carcinogenicity.https://www.cancer.org/cancer/cancer-causes/radiation- exposure/extremely-low-frequency-radiation.html Based on a review of scientific knowledge available in 2020, the ICNIRP commission suggested the further epidemiological and experimental research of neurodegenerative diseases development associated with ELF would be useful. =Shortwave= Shortwave (1.6 to 30 MHz) diathermy can be used as a therapeutic technique for its analgesic effect and deep muscle relaxation, but has largely been replaced by ultrasound. Temperatures in muscles can increase by 4‚Äì6 ¬∞C, and subcutaneous fat by 15 ¬∞C. The FCC has restricted the frequencies allowed for medical treatment, and most machines in the US use 27.12 MHz. Shortwave diathermy can be applied in either continuous or pulsed mode. The latter came to prominence because the continuous mode produced too much heating too rapidly, making patients uncomfortable. The technique only heats tissues that are good electrical conductors, such as blood vessels and muscle. Adipose tissue (fat) receives little heating by induction fields because an electrical current is not actually going through the tissues. Studies have been performed on the use of shortwave radiation for cancer therapy and promoting wound healing, with some success. However, at a sufficiently high energy level, shortwave energy can be harmful to human health, potentially causing damage to biological tissues. The FCC limits for maximum permissible workplace exposure to shortwave radio frequency energy in the range of 3‚Äì30 MHz has a plane-wave equivalent power density of (900/f2) mW/cm2 where f is the frequency in MHz, and 100 mW/cm2 from 0.3‚Äì3.0 MHz. For uncontrolled exposure to the general public, the limit is 180/f2 between 1.34‚Äì30 MHz. =Radio frequency field= The designation of mobile phone signals as \\"possibly carcinogenic to humans\\" by the World Health Organization (WHO) (e.g. its IARC, see below) has often been misinterpreted as indicating that some measure of risk has been observed however the designation indicates only that the possibility could not be conclusively ruled out using the available data. In 2011, International Agency for Research on Cancer (IARC) classified mobile phone radiation as Group 2B \\"possibly carcinogenic\\" (rather than Group 2A \\"probably carcinogenic\\" nor the \\"is carcinogenic\\" Group 1). That means that there \\"could be some risk\\" of carcinogenicity, so additional research into the long-term, heavy use of mobile phones needs to be conducted. The WHO concluded in 2014 that \\"A large number of studies have been performed over the last two decades to assess whether mobile phones pose a potential health risk. To date, no adverse health effects have been established as being caused by mobile phone use.\\"Limits of Human Exposure to Radiofrequency Electromagnetic Fields in the Frequency Range from 3 kHz to 300 GHz, Canada Safety Code 6, p. 63 Since 1962, the microwave auditory effect or tinnitus has been shown from radio frequency exposure at levels below significant heating. Studies during the 1960s in Europe and Russia claimed to show effects on humans, especially the nervous system, from low energy RF radiation; the studies were disputed at the time. In 2019 reporters from the Chicago Tribune tested the level of radiation from smartphones and found it to exceed safe levels. The federal communications commission begun to check the findings. Radio frequency radiation is found to have more thermal related effects. A person's body temperature can be raised which could result in death if exposed to high dosage of RF radiation. ‚ÄúMicrowaves, Radio Waves, and Other Types of Radiofrequency Radiation.‚Äù American Cancer Society, http://www.cancer.org/cancer/cancer-causes/radiation- exposure/radiofrequency-radiation.html Focused RF radiation can also cause burns on the skin or cataracts to form in the eyes. Overall, some health effects are observed at a high levels of RF radiation, but the effects aren't clear at low levels of exposure. =Millimeter waves= In 2009, the US TSA introduced full-body scanners as a primary screening modality in airport security, first as backscatter x-ray scanners, which the European Union banned in 2011 due to health and safety concerns, followed by Millimeter wave scanners . Likewise WiGig for personal area networks have opened the 60 GHz and above microwave band to SAR exposure regulations. Previously, microwave applications in these bands were for point-to-point satellite communication with minimal human exposure.Characterization of 60GHz Millimeter-Wave Focusing Beam for Living-Body Exposure Experiments, Tokyo Institute of Technology, Masaki KOUZAI et al., 2009 =Infrared= Infrared wavelengths longer than 750 nm can produce changes in the lens of the eye. Glassblower's cataract is an example of a heat injury that damages the anterior lens capsule among unprotected glass and iron workers. Cataract-like changes can occur in workers who observe glowing masses of glass or iron without protective eyewear for prolonged periods over many years. Exposing skin to infrared radiation near visible light (IR-A) leads to increased production of free radicals. Short- term exposure can be beneficial (activating protective responses), while prolonged exposure can lead to photoaging. Another important factor is the distance between the worker and the source of radiation. In the case of arc welding, infrared radiation decreases rapidly as a function of distance, so that farther than three feet away from where welding takes place, it does not pose an ocular hazard anymore but, ultraviolet radiation still does. This is why welders wear tinted glasses and surrounding workers only have to wear clear ones that filter UV. =Visible light= Photic retinopathy is damage to the macular area of the eye's retina that results from prolonged exposure to sunlight, particularly with dilated pupils. This can happen, for example, while observing a solar eclipse without suitable eye protection. The Sun's radiation creates a photochemical reaction that can result in visual dazzling and a scotoma. The initial lesions and edema will disappear after several weeks, but may leave behind a permanent reduction in visual acuity. Moderate and high-power lasers are potentially hazardous because they can burn the retina of the eye, or even the skin. To control the risk of injury, various specifications ‚Äì for example ANSI Z136 in the US, EN 60825-1/A2 in Europe, and IEC 60825 internationally ‚Äì define \\"classes\\" of lasers depending on their power and wavelength. Regulations prescribe required safety measures, such as labeling lasers with specific warnings, and wearing laser safety goggles during operation (see laser safety). As with its infrared and ultraviolet radiation dangers, welding creates an intense brightness in the visible light spectrum, which may cause temporary flash blindness. Some sources state that there is no minimum safe distance for exposure to these radiation emissions without adequate eye protection. =Ultraviolet= Sunlight includes sufficient ultraviolet power to cause sunburn within hours of exposure, and the burn severity increases with the duration of exposure. This effect is a response of the skin called erythema, which is caused by a sufficient strong dose of UV-B. The Sun's UV output is divided into UV-A and UV-B: solar UV-A flux is 100 times that of UV-B, but the erythema response is 1,000 times higher for UV-B. This exposure can increase at higher altitudes and when reflected by snow, ice, or sand. The UV-B flux is 2‚Äì4 times greater during the middle 4‚Äì6 hours of the day, and is not significantly absorbed by cloud cover or up to a meter of water. Ultraviolet light, specifically UV-B, has been shown to cause cataracts and there is some evidence that sunglasses worn at an early age can slow its development in later life. Most UV light from the sun is filtered out by the atmosphere and consequently airline pilots often have high rates of cataracts because of the increased levels of UV radiation in the upper atmosphere. It is hypothesized that depletion of the ozone layer and a consequent increase in levels of UV light on the ground may increase future rates of cataracts. Note that the lens filters UV light, so if it is removed via surgery, one may be able to see UV light. Prolonged exposure to ultraviolet radiation from the sun can lead to melanoma and other skin malignancies. Clear evidence establishes ultraviolet radiation, especially the non-ionizing medium wave UVB, as the cause of most non-melanoma skin cancers, which are the most common forms of cancer in the world. UV rays can also cause wrinkles, liver spots, moles, and freckles. In addition to sunlight, other sources include tanning beds, and bright desk lights. Damage is cumulative over one's lifetime, so that permanent effects may not be evident for some time after exposure. Ultraviolet radiation of wavelengths shorter than 300 nm (actinic rays) can damage the corneal epithelium. This is most commonly the result of exposure to the sun at high altitude, and in areas where shorter wavelengths are readily reflected from bright surfaces, such as snow, water, and sand. UV generated by a welding arc can similarly cause damage to the cornea, known as \\"arc eye\\" or welding flash burn, a form of photokeratitis. Fluorescent light bulbs and tubes internally produce ultraviolet light. Normally this is converted to visible light by the phosphor film inside a protective coating. When the film is cracked by mishandling or faulty manufacturing then UV may escape at levels that could cause sunburn or even skin cancer. Regulation In the United States, nonionizing radiation is regulated in the Radiation Control for Health and Safety Act of 1968 and the Occupational Safety and Health Act of 1970.  See also  * Background radiation * BioInitiative Report * Biological effects of radiation on the epigenome * Central nervous system effects from radiation exposure during spaceflight * Cosmic ray * COSMOS cohort study * Electromagnetic hypersensitivity * Electromagnetism * EMF measurements * Health threat from cosmic rays * Light ergonomics * Magnetobiology * Microwave * Mobile phone radiation and health * Personal RF safety monitors * Specific absorption rate * Wireless electronic devices and health  References   Further reading  * (over 100 pages) *  External links  * Information page on electromagnetic fields at the World Health Organization web site * CDC ‚Äì Electric and Magnetic Fields ‚Äì NIOSH Workplace Safety and Health Topic * Category:Environmental controversies Category:Medical physics Category:Radiation health effects Category:Radiobiology ","title":"Electromagnetic radiation and health"},{"id":"41099","text":"In telecommunication, electromagnetic survivability is the ability of a system, subsystem, or equipment to resume functioning without evidence of degradation following temporary exposure to an adverse electromagnetic environment. The system, subsystem, or equipment performance may be degraded during exposure to the adverse electromagnetic environment, but the system will not experience permanent damage, such as component burnout, that will prevent proper operation when the adverse electromagnetic environment is removed. References Category:Telecommunications engineering Category:Fault tolerance ","title":"Electromagnetic survivability"},{"id":"41100","text":"In telecommunication, the term electronic deception means the deliberate radiation, reradiation, alteration, suppression, absorption, denial, enhancement, or reflection of electromagnetic energy in a manner intended to convey misleading information and to deny valid information to an enemy or to enemy electronics-dependent weapons. Among the types of electronic deception are: *Manipulative electronic deception ‚Äì Actions to eliminate revealing or convey misleading, telltale indicators that may be used by hostile forces *Simulative electronic deception ‚Äì Actions to represent friendly notional or actual capabilities to mislead hostile forces *Imitative electronic deception ‚Äì The introduction of electromagnetic energy into enemy systems that imitates enemy emissions. See also *Simulated reality References * Category:Deception ","title":"Electronic deception"},{"id":"41101","text":"In telecommunications, an electronic switching system (ESS) is a telephone switch that uses solid-state electronics, such as digital electronics) and computerized common control, to interconnect telephone circuits for the purpose of establishing telephone calls. The generations of telephone switches before the advent of electronic switching in the 1950s used purely electro- mechanical relay systems and analog voice paths. These early machines typically utilized the step-by-step technique. The first generation of electronic switching systems in the 1960s were not entirely digital in nature, but used reed relay-operated metallic paths or crossbar switches operated by stored program control (SPC) systems. First announced in 1955, the first customer trial installation of an all-electronic central office commenced in Morris, Illinois in November 1960 by Bell Laboratories. The first large-scale electronic switching system was the Number One Electronic Switching System (1ESS) of the Bell System, cut over in Succasunna, New Jersey, in May 1965. The adoption of metal‚Äìoxide‚Äìsemiconductor (MOS) and pulse-code modulation (PCM) technologies in the 1970s led to the transition from analog to digital telephony. Later electronic switching systems implemented the digital representation of the electrical audio signals on subscriber loops by digitizing the analog signals and processing the resulting data for transmission between central offices. Time-division multiplexing (TDM) technology permitted the simultaneous transmission of multiple telephone calls on a single wire connection between central offices or other electronic switches, resulting in dramatic capacity improvements of the telephone network. With the advances of digital electronics starting in the 1960s telephone switches employed semiconductor device components in increasing measure. In the late 20th century most telephone exchanges without TDM processing were eliminated and the term electronic switching system became largely a historical distinction for the older SPC systems. See also *List of telephone switches *Stored program control *5ESS Switching System References * * Category:Telephone exchanges ","title":"Electronic switching system"},{"id":"41102","text":"RAF Menwith Hill, a large ECHELON site in the United Kingdom, and part of the UK-USA Security Agreement. Dupuy de L√¥me, specialised in SIGINT In military telecommunications, the terms electronic support (ES) or electronic support measures (ESM) describe the division of electronic warfare involving actions taken under direct control of an operational commander to detect, intercept, identify, locate, record, and/or analyze sources of radiated electromagnetic energy for the purposes of immediate threat recognition (such as warning that fire control RADAR has locked on a combat vehicle, ship, or aircraft) or longer-term operational planning.Polmar, Norman \\"The U. S. Navy Electronic Warfare (Part 1)\\" United States Naval Institute Proceedings October 1979 p.137 Thus, electronic support provides a source of information required for decisions involving electronic protection (EP), electronic attack (EA), avoidance, targeting, and other tactical employment of forces. Electronic support data can be used to produce signals intelligence (SIGINT), communications intelligence (COMINT) and electronics intelligence (ELINT). Electronic support measures gather intelligence through passive \\"listening\\" to electromagnetic radiations of military interest. Electronic support measures can provide (1) initial detection or knowledge of foreign systems, (2) a library of technical and operational data on foreign systems, and (3) tactical combat information utilizing that library. ESM collection platforms can remain electronically silent and detect and analyze RADAR transmissions beyond the RADAR detection range because of the greater power of the transmitted electromagnetic pulse with respect to a reflected echo of that pulse. United States airborne ESM receivers are designated in the AN/ALR series. Desirable characteristics for electromagnetic surveillance and collection equipment include (1) wide-spectrum or bandwidth capability because foreign frequencies are initially unknown, (2) wide dynamic range because signal strength is initially unknown, (3) narrow bandpass to discriminate the signal of interest from other electromagnetic radiation on nearby frequencies, and (4) good angle-of arrival measurement for bearings to locate the transmitter. The frequency spectrum of interest ranges from 30 MHz to 50 GHz. Multiple receivers are typically required for surveillance of the entire spectrum, but tactical receivers may be functional within a specific signal strength threshold of a smaller frequency range. See also *AWACS *Boeing E-3 Sentry *Boeing E-4 *Electronic countermeasure *Electronic warfare *Lockheed Orion *Low-probability-of-intercept radar  Notes  Category:Military technology Category:Military communications Category:Electronic warfare ","title":"Electronic warfare support measures"},{"id":"41103","text":"* # An electro-optic effect is a change in the optical properties of a material in response to an electric field that varies slowly compared with the frequency of light. The term encompasses a number of distinct phenomena, which can be subdivided into * a) change of the absorption ** Electroabsorption: general change of the absorption constants ** Franz-Keldysh effect: change in the absorption shown in some bulk semiconductors ** Quantum-confined Stark effect: change in the absorption in some semiconductor quantum wells ** Electrochromic effect: creation of an absorption band at some wavelengths, which gives rise to a change in colour * b) change of the refractive index and permittivity ** Pockels effect (or linear electro-optic effect): change in the refractive index linearly proportional to the electric field. Only certain crystalline solids show the Pockels effect, as it requires lack of inversion symmetry ** Kerr effect (or quadratic electro-optic effect, QEO effect): change in the refractive index proportional to the square of the electric field. All materials display the Kerr effect, with varying magnitudes, but it is generally much weaker than the Pockels effect ** electro-gyration: change in the optical activity. ** Electron-refractive effect or EIPM In December 2015, two further electro-optic effects of type (b) were theoretically predicted to exist but have not, as yet, been experimentally observed. Changes in absorption can have a strong effect on refractive index for wavelengths near the absorption edge, due to the Kramers‚ÄìKronig relation. Using a less strict definition of the electro-optic effect allowing also electric fields oscillating at optical frequencies, one could also include nonlinear absorption (absorption depends on the light intensity) to category a) and the optical Kerr effect (refractive index depends on the light intensity) to category b). Combined with the photoeffect and photoconductivity, the electro-optic effect gives rise to the photorefractive effect. The term \\"electro-optic\\" is often erroneously used as a synonym for \\"optoelectronic\\". Main applications =Electro-optic modulators= Electro-optic modulators are usually built with electro-optic crystals exhibiting the Pockels effect. The transmitted beam is phase modulated with the electric signal applied to the crystal. Amplitude modulators can be built by putting the electro-optic crystal between two linear polarizers or in one path of a Mach‚ÄìZehnder interferometer. Additionally, Amplitude modulators can be constructed by deflecting the beam into and out of a small aperture such as a fiber. This design can be low loss (<3 dB) and polarization independent depending on the crystal configuration. =Electro-optic deflectors= Electro-optic deflectors utilize prisms of electro-optic crystals. The index of refraction is changed by the Pockels effect, thus changing the direction of propagation of the beam inside the prism. Electro-optic deflectors have only a small number of resolvable spots, but possess a fast response time. There are few commercial models available at this time. This is because of competing acousto-optic deflectors, the small number of resolvable spots and the relatively high price of electro-optic crystals. =Electro-optic field sensors= The electro-optic Pockels effect in nonlinear crystals (e.g. KDP, BSO, K*DP) can be used for electric field sensing via polarisation state modulation techniques. In this scenario, an unknown electric field results in polarisation rotation of a laser beam propagating through the electro-optic crystal; through inclusion of polarisers to modulate the light intensity incident on a photodiode, a time-resolved electric field measurement can be reconstructed from the obtained voltage trace. As the signals obtained from vgccthe crystalline probes are optical, they are inherently resistant to electrical noise pickup, hence can be used for low-noise field measurement even in areas with high levels of electromagnetic noise in the vicinity of the probe. Furthermore, as the polarisation rotation due to the Pockels effect scales linearly with electric field, absolute field measurements are obtained, with no need for numerical integration to reconstruct electric fields, as is the case with conventional probes sensitive to the time-derivative of the electric field. Electro-optic measurements of strong electromagnetic pulses from intense laser-matter interactions have been demonstrated in both the nanosecond and picosecond (sub-petawatt) laser pulse driver regimes. References External links * AdvR - Electro-optic Devices & Research Category:Nonlinear optics ","title":"Electro-optic effect"},{"id":"41104","text":"An electro-optic phase modulator for free-space beams An optical intensity modulator for optical telecommunications An electro-optic modulator (EOM) is an optical device in which a signal-controlled element exhibiting an electro- optic effect is used to modulate a beam of light. The modulation may be imposed on the phase, frequency, amplitude, or polarization of the beam. Modulation bandwidths extending into the gigahertz range are possible with the use of laser-controlled modulators. The electro-optic effect is the change in the refractive index of a material resulting from the application of a DC or low-frequency electric field. This is caused by forces that distort the position, orientation, or shape of the molecules constituting the material. Generally, a nonlinear optical material (organic polymers have the fastest response rates, and thus are best for this application) with an incident static or low frequency optical field will see a modulation of its refractive index. The simplest kind of EOM consists of a crystal, such as lithium niobate, whose refractive index is a function of the strength of the local electric field. That means that if lithium niobate is exposed to an electric field, light will travel more slowly through it. But the phase of the light leaving the crystal is directly proportional to the length of time it takes that light to pass through it. Therefore, the phase of the laser light exiting an EOM can be controlled by changing the electric field in the crystal. Note that the electric field can be created by placing a parallel plate capacitor across the crystal. Since the field inside a parallel plate capacitor depends linearly on the potential, the index of refraction depends linearly on the field (for crystals where Pockels effect dominates), and the phase depends linearly on the index of refraction, the phase modulation must depend linearly on the potential applied to the EOM. The voltage required for inducing a phase change of \\\\pi is called the half-wave voltage (V_\\\\pi). For a Pockels cell, it is usually hundreds or even thousands of volts, so that a high-voltage amplifier is required. Suitable electronic circuits can switch such large voltages within a few nanoseconds, allowing the use of EOMs as fast optical switches. Liquid crystal devices are electro-optical phase modulators if no polarizers are used. Phase modulation Phase modulation (PM) is a modulation pattern that encodes information as variations in the instantaneous phase of a carrier wave. The phase of a carrier signal is modulated to follow the changing voltage level (amplitude) of modulation signal. The peak amplitude and frequency of the carrier signal remain constant, but as the amplitude of the information signal changes, the phase of the carrier changes correspondingly. The analysis and the final result (modulated signal) are similar to those of frequency modulation. A very common application of EOMs is for creating sidebands in a monochromatic laser beam. To see how this works, first imagine that the strength of a laser beam with frequency \\\\omega entering the EOM is given by :Ae^{i\\\\omega t}. Now suppose we apply a sinusoidally varying potential voltage to the EOM with frequency \\\\Omega and small amplitude \\\\beta. This adds a time dependent phase to the above expression, :Ae^{i\\\\omega t + i\\\\beta\\\\sin(\\\\Omega t)}. Since \\\\beta is small, we can use the Taylor expansion for the exponential :Ae^{i\\\\omega t}\\\\left( 1+i\\\\beta\\\\sin(\\\\Omega t)\\\\right) , to which we apply a simple identity for sine, :Ae^{i\\\\omega t}\\\\left( 1 + \\\\frac{\\\\beta}{2}\\\\left(e^{i\\\\Omega t} - e^{-i\\\\Omega t}\\\\right)\\\\right) = A\\\\left( e^{i\\\\omega t}+\\\\frac{\\\\beta}{2}e^{i(\\\\omega+\\\\Omega) t}-\\\\frac{\\\\beta}{2}e^{i(\\\\omega-\\\\Omega) t}\\\\right) . This expression we interpret to mean that we have the original carrier signal plus two small sidebands, one at \\\\omega+\\\\Omega and another at \\\\omega-\\\\Omega. Notice however that we only used the first term in the Taylor expansion ‚Äì in truth there are an infinite number of sidebands. There is a useful identity involving Bessel functions called the Jacobi‚ÄìAnger expansion which can be used to derive :Ae^{i\\\\omega t + i\\\\beta\\\\sin(\\\\Omega t)} = Ae^{i\\\\omega t}\\\\left( J_0(\\\\beta) + \\\\sum_{k=1}^\\\\infty J_k(\\\\beta)e^{ik\\\\Omega t} + \\\\sum_{k=1}^\\\\infty (-1)^k J_k(\\\\beta)e^{-ik\\\\Omega t}\\\\right) , which gives the amplitudes of all the sidebands. Notice that if one modulates the amplitude instead of the phase, one gets only the first set of sidebands, :\\\\left( 1 + \\\\beta\\\\sin(\\\\Omega t)\\\\right) Ae^{i\\\\omega t} = Ae^{i\\\\omega t} + \\\\frac{A\\\\beta}{2i}\\\\left( e^{i(\\\\omega+\\\\Omega) t} - e^{i(\\\\omega-\\\\Omega)t} \\\\right) . Amplitude modulation A phase modulating EOM can also be used as an amplitude modulator by using a Mach‚ÄìZehnder interferometer. A beam splitter divides the laser light into two paths, one of which has a phase modulator as described above. The beams are then recombined. Changing the electric field on the phase modulating path will then determine whether the two beams interfere constructively or destructively at the output, and thereby control the amplitude or intensity of the exiting light. This device is called a Mach‚ÄìZehnder modulator. Polarization modulation Depending on the type and orientation of the nonlinear crystal, and on the direction of the applied electric field, the phase delay can depend on the polarization direction. A Pockels cell can thus be seen as a voltage- controlled waveplate, and it can be used for modulating the polarization state. For a linear input polarization (often oriented at 45¬∞ to the crystal axis), the output polarization will in general be elliptical, rather than simply a linear polarization state with a rotated direction. Polarization modulation in electro-optic crystals can also be used as a technique for time- resolved measurement of unknown electric fields. Compared to conventional techniques using conductive field probes and cabling for signal transport to read-out systems, electro-optical measurement is inherently noise resistant as signals are carried by fiber-optics, preventing distortion of the signal by electrical noise sources. The polarization change measured by such techniques is linearly dependent on the electric field applied to the crystal, hence provides absolute measurements of the field, without the need for numerical integration of voltage traces, as is the case for conductive probes sensitive to the time-derivative of the electric field. See also *Pockels effect *Acousto-optic modulator *Phase modulation *Dielectric wireless receiver References  ;Notes External links * AdvR ‚Äì Research and custom EO phase and amplitude modulators * Encyclopedia of Laser Physics and Technology * Interactive visualization of the transfer characteristic of a Mach‚ÄìZehnder modulator for phase and amplitude modulation Category:Optical devices Category:Nonlinear optics Category:Optoelectronics ","title":"Electro-optic modulator"},{"id":"41105","text":"Electro-optics is a branch of electrical engineering, electronic engineering, materials science, and material physics involving components, devices (e.g. Lasers, LEDs, waveguides etc.) and systems which operate by the propagation and interaction of light with various tailored materials. It is essentially the same as what is popularly described today as photonics. It is not only concerned with the \\"Electro-Optic effect\\". Thus it concerns the interaction between the electromagnetic (optical) and the electrical (electronic) states of materials.  Electro-optical devices  The electro-optic effect is a change in the optical properties of an optically active material due to interaction with light. This interaction usually results in a change in the birefringence, and not simply the refractive index of the medium. In a Kerr cell, the change in birefringence is proportional to the square of the optical electric field, and the material is usually a liquid. In a Pockels cell, the change in birefringence varies linearly with the electric field, and the material is usually a crystal. Non-crystalline, solid electro-optical materials have generated interest because of their low cost of production. These organic, polymer-based materials are also known as organic EO material, plastic EO material, or polymer EO material. They consist of nonlinear optical chromophores in a polymer lattice. The nonlinear optical chromophores can produce Pockel's effect. References  External links * Introduction to Electro-Optical Systems in Unmanned Vehicle Applications - Unmanned Systems Technology Category:Optoelectronics Category:Nonlinear optics ","title":"Electro-optics"},{"id":"41106","text":"In electrodynamics, elliptical polarization is the polarization of electromagnetic radiation such that the tip of the electric field vector describes an ellipse in any fixed plane intersecting, and normal to, the direction of propagation. An elliptically polarized wave may be resolved into two linearly polarized waves in phase quadrature, with their polarization planes at right angles to each other. Since the electric field can rotate clockwise or counterclockwise as it propagates, elliptically polarized waves exhibit chirality. Other forms of polarization, such as circular and linear polarization, can be considered to be special cases of elliptical polarization. Elliptical polarization diagram Mathematical description The classical sinusoidal plane wave solution of the electromagnetic wave equation for the electric and magnetic fields is (Gaussian units) : \\\\mathbf{E} ( \\\\mathbf{r} , t ) = \\\\mid \\\\mathbf{E} \\\\mid \\\\mathrm{Re} \\\\left \\\\\\\\{ \\\\psi\\\\rangle \\\\exp \\\\left [ i \\\\left ( kz-\\\\omega t \\\\right ) \\\\right ] \\\\right \\\\\\\\} : \\\\mathbf{B} ( \\\\mathbf{r} , t ) = \\\\hat { \\\\mathbf{z} } \\\\times \\\\mathbf{E} ( \\\\mathbf{r} , t ) for the magnetic field, where k is the wavenumber, : \\\\omega_{ }^= c k is the angular frequency of the wave propagating in the +z direction, and c is the speed of light. Here \\\\mid \\\\mathbf{E} \\\\mid is the amplitude of the field and : \\\\psi\\\\rangle \\\\ \\\\stackrel{\\\\mathrm{def}}{=}\\\\ \\\\begin{pmatrix} \\\\psi_x  \\\\psi_y \\\\end{pmatrix} = \\\\begin{pmatrix} \\\\cos\\\\theta \\\\exp \\\\left ( i \\\\alpha_x \\\\right )  \\\\sin\\\\theta \\\\exp \\\\left ( i \\\\alpha_y \\\\right ) \\\\end{pmatrix} is the normalized Jones vector. This is the most complete representation of polarized electromagnetic radiation and corresponds in general to elliptical polarization. Polarization ellipse rightAt a fixed point in space (or for fixed z), the electric vector \\\\mathbf{E} traces out an ellipse in the x-y plane. The semi-major and semi-minor axes of the ellipse have lengths A and B, respectively, that are given by : A=\\\\mathbf{E}\\\\sqrt{\\\\frac{1+\\\\sqrt{1-\\\\sin^2(2\\\\theta)\\\\sin^2\\\\beta}}{2}} and : B=\\\\mathbf{E}\\\\sqrt{\\\\frac{1-\\\\sqrt{1-\\\\sin^2(2\\\\theta)\\\\sin^2\\\\beta}}{2}}, where \\\\beta =\\\\alpha_y-\\\\alpha_x. The orientation of the ellipse is given by the angle \\\\phi the semi-major axis makes with the x-axis. This angle can be calculated from : \\\\tan2\\\\phi=\\\\tan2\\\\theta\\\\cos\\\\beta. If \\\\beta= 0, the wave is linearly polarized. The ellipse collapses to a straight line (A=\\\\mathbf{E}, B=0) oriented at an angle \\\\phi=\\\\theta. This is the case of superposition of two simple harmonic motions (in phase), one in the x direction with an amplitude \\\\mathbf{E} \\\\cos\\\\theta, and the other in the y direction with an amplitude \\\\mathbf{E} \\\\sin\\\\theta . When \\\\beta increases from zero, i.e., assumes positive values, the line evolves into an ellipse that is being traced out in the counterclockwise direction (looking in the direction of the propagating wave); this then corresponds to left-handed elliptical polarization; the semi- major axis is now oriented at an angle \\\\phi eq\\\\theta . Similarly, if \\\\beta becomes negative from zero, the line evolves into an ellipse that is being traced out in the clockwise direction; this corresponds to right-handed elliptical polarization. If \\\\beta=\\\\pm\\\\pi/2 and \\\\theta=\\\\pi/4, A=B=\\\\mathbf{E}/\\\\sqrt{2}, i.e., the wave is circularly polarized. When \\\\beta=\\\\pi/2, the wave is left-circularly polarized, and when \\\\beta=-\\\\pi/2, the wave is right-circularly polarized. =Parameterization= Any fixed polarization can be described in terms of the shape and orientation of the polarization ellipse, which is defined by two parameters: axial ratio AR and tilt angle \\\\tau. The axial ratio is the ratio of the lengths of the major and minor axes of the ellipse, and is always greater than or equal to one. Alternatively, polarization can be represented as a point on the surface of the Poincar√© sphere, with 2\\\\times \\\\tau as the longitude and 2\\\\times \\\\epsilon as the latitude, where \\\\epsilon=\\\\arccot(\\\\pm AR). The sign used in the argument of the \\\\arccot depends on the handedness of the polarization. Positive indicates left hand polarization, while negative indicates right hand polarization, as defined by IEEE. For the special case of circular polarization, the axial ratio equals 1 (or 0 dB) and the tilt angle is undefined. For the special case of linear polarization, the axial ratio is infinite. In nature The reflected light from some beetles (e.g. Cetonia aurata) is elliptical polarized. See also *Ellipsometry *Fresnel rhomb *Photon polarization *Sinusoidal plane-wave solutions of the electromagnetic wave equation References * * Henri Poincar√© (1889) Theorie Mathematique de la Lumiere, volume 1 and Volume 2 (1892) via Internet Archive. * H. Poincare (1901) Electricite et Optique : La Lumiere et les Theories Electrodynamique, via Internet Archive External links *Animation of Elliptical Polarization (on YouTube) *Comparison of Elliptical Polarization with Linear and Circular Polarizations (YouTube Animation) Category:Polarization (waves) ja:Ê•ïÂÜÜÂÅèÂÖâ ","title":"Elliptical polarization"},{"id":"41107","text":"vinyl records Typically, prior to some process, such as transmission over cable, or recording to phonograph record or tape, the input frequency range most susceptible to noise is boosted. This is referred to as \\"pre- emphasis\\"before the process the signal will undergo. Later, when the signal is received, or retrieved from recording, the reverse transformation is applied (\\"de-emphasis\\") so that the output accurately reproduces the original input. Any noise added by transmission or record/playback, to the frequency range previously boosted, is now attenuated in the de-emphasis stage. The high- frequency signal components are emphasized to produce a more equal modulation index for the transmitted frequency spectrum, and therefore a better signal- to-noise ratio for the entire frequency range. Emphasis is commonly used in FM broadcasting and vinyl (e.g. LP) records.  In waveform signals  In processing electronic audio signals, pre-emphasis refers to a system process designed to increase (within a frequency band) the magnitude of some (usually higher) frequencies with respect to the magnitude of other (usually lower) frequencies in order to improve the overall signal-to-noise ratio by minimizing the adverse effects of such phenomena as attenuation distortion or saturation of recording media in subsequent parts of the system. The mirror operation is called de-emphasis, and the system as a whole is called emphasis. Pre-emphasis is achieved with a pre-emphasis network which is essentially a calibrated filter. The frequency response is decided by special time constants. The cutoff frequency can be calculated from that value. Pre- emphasis is commonly used in telecommunications, digital audio recording, record cutting, in FM broadcasting transmissions, and in displaying the spectrograms of speech signals. One example of this is the RIAA equalization curve on 33 rpm and 45 rpm vinyl records. Another is the Dolby noise-reduction system as used with magnetic tape. Pre-emphasis is employed in frequency modulation or phase modulation transmitters to equalize the modulating signal drive power in terms of deviation ratio. The receiver demodulation process includes a reciprocal network, called a de-emphasis network, to restore the original signal power distribution. = De-emphasis = In telecommunication, de-emphasis is the complement of pre-emphasis, in the antinoise system called emphasis. De-emphasis is a system process designed to decrease, (within a band of frequencies), the magnitude of some (usually higher) frequencies with respect to the magnitude of other (usually lower) frequencies in order to improve the overall signal-to-noise ratio by minimizing the adverse effects of such phenomena as attenuation distortion or saturation of recording media in subsequent parts of the system. Special time constants dictate the frequency response curve, from which one can calculate the cutoff frequency. = Red Book audio = Although rarely used, there exists the capability for standardized emphasis in Red Book CD mastering. As CDs were intended to work on 14-bit audio, a specification for 'pre-emphasis' was included to compensate for quantization noise. After production spec was set at 16 bits, quantization noise became less of a concern, but emphasis remained an option through standards revisions. The pre-emphasis is described as a first-order filter with a gain of 10 dB (at 20 dB/decade) and time constants 50 Œºs and 15 Œºs.  In digital transmission  In high speed digital transmission, pre-emphasis is used to improve signal quality at the output of a data transmission. In transmitting signals at high data rates, the transmission medium may introduce distortions, so pre-emphasis is used to distort the transmitted signal to correct for this distortion. When done properly this produces a received signal which more closely resembles the original or desired signal, allowing the use of higher frequencies or producing fewer bit errors. In serial data transmission, de-emphasis has a different meaning, which is to reduce the level of all bits except the first one after a transition. That causes the high frequency content due to the transition to be emphasized compared to the low frequency content which is de-emphasized. This is a form of transmitter equalization; it compensates for losses over the channel which are larger at higher frequencies. Well known serial data standards such as PCI Express, SATA and SAS require transmitted signals to use de-emphasis.  References  *  External links  * EmphasisFrequency response and equalization EQConversion: time constant to cut-off frequency and vice versa * DeemphasisFrequency response and equalization EQConversion: time constant to cut-off frequency and vice versa Category:Signal processing Category:Broadcast engineering ","title":"Emphasis (telecommunications)"},{"id":"41108","text":"Encode or encoding may refer to: * APL (programming language) dyadic Encode function and its symbol ‚ä§ * Binary encoding * Binary-to-text encoding * Character encoding * Encoding, or code * Encoding (memory) * Encoding (semiotics) * ENCODE (Encyclopedia of DNA Elements) * MPEG encoding * Semantics encoding * Text encoding ‚Äî see character encoding applied to textual data * Video encoding See also * Encoder (disambiguation) * ","title":"Encode"},{"id":"41109","text":"In start-stop teletypewriter operation, end distortion refers to the shifting of the end of all marking pulses, except the stop pulse, from their proper positions in relation to the beginning of the next start pulse. Shifting of the end of the stop pulse is a deviation in character time and rate rather than an end distortion. Spacing end distortion is the termination of marking pulses before the proper time. Marking end distortion is the continuation of marking pulses past the proper time. The magnitude of the distortion is expressed as a percentage of an ideal pulse length. References Category:Telegrams ","title":"End distortion"},{"id":"41110","text":"In telecommunication, an end-of-Transmission character (EOT) is a transmission control character. Its intended use is to indicate the conclusion of a transmission that may have included one or more texts and any associated message headings. An EOT is often used to initiate other functions, such as releasing circuits, disconnecting terminals, or placing receive terminals in a standby condition. Its most common use today is to cause a Unix terminal driver to signal end of file and thus exit programs that are awaiting input. In ASCII and Unicode, the character is encoded at . It can be referred to as , in caret notation. Unicode provides the character for when EOT needs to be displayed graphically. In addition, can also be used as a graphic representation of EOT; it is defined in Unicode as \\"symbol for End of Transmission\\".  Meaning in Unix  The EOT character in Unix is different from the Control-Z in DOS. The DOS Control-Z byte is actually sent and/or placed in files to indicate where the text ends. In contrast, the Control-D causes the Unix terminal driver to signal the EOF condition, which is not a character, while the byte has no special meaning if actually read or written from a file or terminal. In Unix, the end-of-file character (by default EOT) causes the terminal driver to make available all characters in its input buffer immediately; normally the driver would collect characters until it sees an end-of-line character. If the input buffer is empty (because no characters have been typed since the last end-of-line or end-of-file), a program reading from the terminal reads a count of zero bytes. In Unix, such a condition is understood as having reached the end of the file. This can be demonstrated with the program on Unix-based operating systems such as Linux: Run the command with no arguments, so it accepts its input from the keyboard and prints output to the screen. Type a few characters without pressing , then type . The characters typed to that point are sent to cat, which then writes them to the screen. If is typed without typing any characters first, the input stream is terminated and the program ends. An actual EOT is obtained by typing then . If the terminal driver is in \\"raw\\" mode, it no longer interprets control characters, and the EOT character is sent unchanged to the program, which is free to interpret it any way it likes. A program may then decide to handle the EOT byte as an indication that it should end the text; this would then be similar to how is handled by DOS programs.  Usage in mainframe computer system communications protocols  The EOT character is used in legacy communications protocols by mainframe computer manufacturers such as IBM, Burroughs Corporation, and the BUNCH. Terminal transmission control protocols such as IBM 3270 Poll/Select, or Burroughs TD830 Contention Mode protocol use the EOT character to terminate a communications sequence between two cooperating stations (such as a host multiplexer or Input/Output terminal). A single Poll (ask the station for data) or Select (send data to the station) operation will include two round-trip send-reply operations between the polling station and the station being polled, the final operation being transmission of a single EOT character to the initiating station. See also *C0 and C1 control codes *ASCII *Keyboard shortcut References * Category:Control characters ","title":"End-of-Transmission character"},{"id":"41111","text":"In telecommunication, endurability is the property of a system, subsystem, equipment, or process that enables it to continue to function within specified performance limits for an extended period of time, usually months, despite a severe natural or man-made disturbance, such as a nuclear attack, or a loss of external logistic or utility support. Endurability is not compromised by temporary failures when the local capability exists to restore and maintain the system, subsystem, equipment, or process to an acceptable performance level. References * Federal Standard 1037C * MIL-STD-188 Category:Telecommunications engineering Category:Fault tolerance ","title":"Endurability"},{"id":"41112","text":"Enhanced service is service offered over commercial carrier transmission facilities used in interstate communications, that employs computer processing applications that act on the format, content, code, protocol, or similar aspects of the subscriber's transmitted information; provides the subscriber with additional, different, or restructured information; or involves subscriber interaction with stored information. References ","title":"Enhanced service"},{"id":"41113","title":"Epoch"},{"id":"41115","text":"In telecommunication, an equivalent noise resistance is a quantitative representation in resistance units of the spectral density of a noise-voltage generator, given by R_n = \\\\frac {\\\\pi W_n}{k T_0} where W_n is the spectral density, k is the Boltzmann's constant, T_0 is the standard noise temperature (290 K), so kT_0 = 4.00 \\\\times 10^{-21}\\\\,[Ws]. Note: The equivalent noise resistance in terms of the mean-square noise-generator voltage, e2, within a frequency increment, Œî f, is given by : R_n = \\\\frac{e^2}{4 k T_0\\\\,\\\\Delta f}.  See also  * Equivalent input noise * Effective input noise temperature Category:Noise (electronics) Category:Equivalent units ","title":"Equivalent noise resistance"},{"id":"41116","text":"In telecommunication, equivalent pulse code modulation (PCM) noise is the amount of noise power on a frequency-division multiplexing (FDM) or wire communication channel necessary to approximate the same judgment of speech quality created by quantizing noise in a PCM channel. :Note 1: The speech quality judgment is based on comparative tests. :Note 2: Generally, 33.5 dBrnC ¬±2.5 dB is considered the approximate equivalent PCM noise of a 7-bit PCM system. References Category:Multiplexing Category:Noise (electronics) ","title":"Equivalent pulse code modulation noise"},{"id":"41118","text":"An error (from the Latin error, meaning \\"wandering\\") is an action which is inaccurate or incorrect. In some usages, an error is synonymous with a mistake. In statistics, \\"error\\" refers to the difference between the value which has been computed and the correct value. An error could result in failure or in a deviation from the intended performance or behaviour. Human behavior One reference differentiates between \\"error\\" and \\"mistake\\" as follows: In human behavior the norms or expectations for behavior or its consequences can be derived from the intention of the actor or from the expectations of other individuals or from a social grouping or from social norms. (See deviance.) Gaffes and faux pas can be labels for certain instances of this kind of error. More serious departures from social norms carry labels such as misbehavior and labels from the legal system, such as misdemeanor and crime. Departures from norms connected to religion can have other labels, such as sin. An individual language user's deviations from standard language norms in grammar, pronunciation and orthography are sometimes referred to as errors. However, in light of the role of language usage in everyday social class distinctions, many feel that linguistics should restrain itself from such prescriptivist judgments to avoid reinforcing dominant class value claims about what linguistic forms should and should not be used. One may distinguish various kinds of linguistic errorsMistakes, Arnold Zwicky, 1980, Advocate Publishing Group, The ISBN printed in the document (0-89894-030-5) is invalid, causing a checksum error ‚Äì some, such as aphasia or speech disorders, where the user is unable to say what they intend to, are generally considered errors, while cases where natural, intended speech is non-standard (as in vernacular dialects), are considered legitimate speech in scholarly linguistics, but might be considered errors in prescriptivist contexts. See also Error analysis (linguistics). Herzliya Airport (Israel) runway location and traffic pattern chart (left) was erroneously printed as a result of \\"black layer\\" 180¬∞ misplacement. The corrected chart is on the right. (Note north is to the right on both charts.) 'Judas' Bible in St Mary's Church, Totnes, Devon. In this edition 'Judas' appears instead of 'Jesus' in Matthew 26:36. This copy has the misprint corrected by a slip of paper pasted over it.According to a note in St Mary's Church, Totnes, Cornwall, UK = Gaffe = A gaffe is usually made in a social environment and may come from saying something that may be true but inappropriate. It may also be an erroneous attempt to reveal a truth. Gaffes can be malapropisms, grammatical errors or other verbal and gestural weaknesses or revelations through body language. Actually revealing factual or social truth through words or body language, however, can commonly result in embarrassment or, when the gaffe has negative connotations, friction between people involved. Philosophers and psychologists interested in the nature of the gaffe include Sigmund Freud (Freudian slip) and Gilles Deleuze. Deleuze, in his The Logic of Sense, places the gaffe in a developmental process that can culminate in stuttering. Sports writers and journalists commonly use \\"gaffe\\" to refer to any kind of mistake, e.g., a dropped ball (baseball error) by a player in a baseball game. Science and engineering Erroneous traffic sign in Israel. The correct sign is depicted on the lower-right corner. In statistics, an error (or residual) is not a \\"mistake\\" but rather a difference between a computed, estimated, or measured value and the accepted true, specified, or theoretically correct value. In science and engineering in general, an error is defined as a difference between the desired and actual performance or behavior of a system or object. This definition is the basis of operation for many types of control systems, in which error is defined as the difference between a set point and the process value. An example of this would be the thermostat in a home heating system‚Äîthe operation of the heating equipment is controlled by the difference (the error) between the thermostat setting and the sensed air temperature. Another approach is related to considering a scientific hypothesis as true or false, giving birth to two types of errors: Type 1 and Type 2. The first one is when a true hypothesis is considered false, while the second is the reverse (a false one is considered true). Engineers seek to design devices, machines and systems and in such a way as to mitigate or preferably avoid the effects of error, whether unintentional or not. Such errors in a system can be latent design errors that may go unnoticed for years, until the right set of circumstances arises that cause them to become active. Other errors in engineered systems can arise due to human error, which includes cognitive bias. Human factors engineering is often applied to designs in an attempt to minimize this type of error by making systems more forgiving or error- tolerant. (In computational mechanics, when solving a system such as Ax = b there is a distinction between the \\"error\\" ‚Äî the inaccuracy in x ‚Äî and residual‚Äîthe inaccuracy in Ax.) Numerical analysis Numerical analysis provides a variety of techniques to represent (store) and compute approximations to mathematical numerical values. Errors arise from a trade-off between efficiency (space and computation time) and precision, which is limited anyway, since (using common floating-point arithmetic) only a finite amount of values can be represented exactly. The discrepancy between the exact mathematical value and the stored/computed value is called the approximation error. Cybernetics The word cybernetics stems from the Greek ŒöœÖŒ≤ŒµœÅŒΩŒÆœÑŒ∑œÇ (kybernƒìtƒìs, steersman, governor, pilot, or rudder ‚Äî the same root as government). In applying corrections to the trajectory or course being steered cybernetics can be seen as the most general approach to error and its correction for the achievement of any goal. The term was suggested by Norbert Wiener to describe a new science of control and information in the animal and the machine. Wiener's early work was on noise. The cybernetician Gordon Pask held that the error that drives a servomechanism can be seen as a difference between a pair of analogous concepts in a servomechanism: the current state and the goal state. Later he suggested error can also be seen as an innovation or a contradiction depending on the context and perspective of interacting (observer) participants. The founder of management cybernetics, Stafford Beer, applied these ideas most notably in his viable system model. Biology In biology, an error is said to occur when perfect fidelity is lost in the copying of information. For example, in an asexually reproducing species, an error (or mutation) has occurred for each DNA nucleotide that differs between the child and the parent. Many of these mutations can be harmful, but unlike other types of errors, some are neutral or even beneficial. Mutations are an important force driving evolution. Mutations that make organisms more adapted to their environment increase in the population through natural selection as organisms with favorable mutations have more offspring. Philately In philately, an error refers to a postage stamp or piece of postal stationery that exhibits a printing or production mistake that differentiates it from a normal specimen or from the intended result. Examples are stamps printed in the wrong color or missing one or more colors, printed with a vignette inverted in relation to its frame, produced without any perforations on one or more sides when the normal stamps are perforated, or printed on the wrong type of paper. Legitimate errors must always be produced and sold unintentionally. Such errors may or may not be scarce or rare. A design error may refer to a mistake in the design of the stamp, such as a mislabeled subject, even if there are no printing or production mistakes. Law In appellate review, error typically refers to mistakes made by a trial court or some other court of first instance in applying the law in a particular legal case. This may involve such mistakes as improper admission of evidence, inappropriate instructions to the jury, or applying the wrong standard of proof.  Stock market  A stock market error is a stock market transaction that was done due to an error, due to human failure or computer errors. Governmental policy Within United States government intelligence agencies, such as Central Intelligence Agency agencies, error refers to intelligence error, as previous assumptions that used to exist at a senior intelligence level within senior intelligence agencies, but has since been disproven, and is sometimes eventually listed as unclassified, and therefore more available to the public and citizenry of the United States. The Freedom of information act provides American citizenry with a means to read intelligence reports that were mired in error. Per United States Central Intelligence Agency's website (as of August, 2008) intelligence error is described as: \\"Intelligence errors are factual inaccuracies in analysis resulting from poor or missing data; intelligence failure is systemic organizational surprise resulting from incorrect, missing, discarded, or inadequate hypotheses.\\"United States Central Intelligence Agency. Analytic Culture in the U.S. Intelligence Community. Retrieved August 30, 2008. Numismatics In numismatics, an error refers to a coin or medal that has a minting mistake, similar to errors found in philately. Because the U.S. Bureau of the Mint keeps a careful eye on all potential errors, errors on U.S. coins are very few and usually very scarce. Examples of numismatic errors: extra metal attached to a coin, a clipped coin caused by the coin stamp machine stamping a second coin too early, double stamping of a coin. A coin that has been overdated, e.g.: 1942/41, is also considered an error. See also * Blooper * Blunder (disambiguation) * Error analysis (disambiguation) * Perfection * Popular errors * Refractive error * Trial and error * Margin of error * Medical error Psychology of error * Absent-mindedness * Lapsus Error in reasoning * Fallacy **Informal fallacy **Formal fallacy Errors in language *Chinglish *Clerical error * Speech error * Typographical error *Barbarism *Solecism Errors in science, technology * Custom error page * Divide by zero * Mathematical fallacy * Infinite loop * Stack overflow * Software bug Error diagnosis, correction and prevention * Error-correcting code memory * Error detection and correction * Error Detection and Handling * Forensic engineering * Root cause * Root cause analysis * Spell checking * Swiss cheese model of accident causation in human systems Production quality terminology * Nonconformity References External links * Errors contained in reference books ‚Äì Internet Accuracy Project Category:Human communication Category:Measurement es:Error ","title":"Error"},{"id":"41119","text":"In telecommunication, a burst error or error burst is a contiguous sequence of symbols, received over a communication channel, such that the first and last symbols are in error and there exists no contiguous subsequence of m correctly received symbols within the error burst. The integer parameter m is referred to as the guard band of the error burst. The last symbol in a burst and the first symbol in the following burst are accordingly separated by m correct bits or more. The parameter m should be specified when describing an error burst. Channel model The Gilbert‚ÄìElliott model is a simple channel model introduced by Edgar Gilbert. and E. O. Elliott . that is widely used for describing burst error patterns in transmission channels and enables simulations of the digital error performance of communications links. It is based on a Markov chain with two states G (for good or gap) and B (for bad or burst). In state G the probability of transmitting a bit correctly is k and in state B it is h. Usually,Lemmon, J.J.: Wireless link statistical bit error model. US National Telecommunications and Information Administration (NTIA) Report 02-394 (2002) it is assumed that k = 1\\\\. Gilbert provided equations for deriving the other three parameters (G and B state transition probabilities and h) from a given success/failure sequence. In his example, the sequence was too short to correctly find h (a negative probability was found) and so Gilbert assumed that h = 0.5.  References   External links  * The Gilbert-Elliott Model for Packet Loss in Real Time Services on the Internet * A Markov-Based Channel Model Algorithm for Wireless Networks * The two-state model for a fading channel Category:Markov models Category:Data transmission ","title":"Burst error"},{"id":"41123","title":"Escape character"},{"id":"41124","text":"In telecommunication, an essential service (critical service) is a network- provided service feature in which a priority dial tone is furnished. Essential service is typically provided to fewer than 10% of network users, and recommended for use in conjunction with NS/EP telecommunications services. References * Category:Telecommunication services ","title":"Essential service (telecommunications)"},{"id":"41125","text":"Exchange may refer to: Places =United States= * Exchange, Indiana, an unincorporated community * Exchange, Missouri, an unincorporated community * Exchange, Pennsylvania, an unincorporated community * Exchange, West Virginia, an unincorporated community =Elsewhere= * Exchange Alley, in London, United Kingdom * Exchange District, a historic area in Winnipeg, Manitoba, Canada Business and economy *Bureau de change, a business whose customers exchange one currency for another *Cryptocurrency exchange, a business that allows customers to trade cryptocurrencies or digital currencies. *Digital currency exchangers (a.k.a. DCEs or Bitcoin exchanges), businesses that allow customers to trade digital currencies for other assets, such as conventional fiat money, or different digital currencies *Exchange (economics) *Exchange (organized market) *Exchange rate (a.k.a. foreign exchange rate), the price for which one currency is exchanged for another *Foreign exchange company, a broker that offers currency exchange and international payments *Foreign exchange controls, controls imposed by a government on the purchase/sale of foreign currencies *Foreign exchange market (a.k.a. forex, FX, or currency market), a global decentralized market where one currency is exchanged for another *Foreign-exchange reserves, holdings of other countries' currencies *Foreign exchange risk, arises from the change in price of one currency against another *Retail foreign exchange platform, speculative trading of foreign exchange by individuals using electronic trading platforms *Trade, the exchange of goods or services for money or other goods or services Military *Post exchange (a.k.a. \\"PX\\" or base exchange), a retail store operated by Army and Air Force Exchange Service on US military installations worldwide; originally akin to trading posts, they now resemble contemporary department stores or strip malls. * Prisoner exchange * , an American Civil War steamer Technology * .exchange, an ICANN-era generic Internet top- level domain * Internet exchange point (IX), physical infrastructure connecting Internet service providers' networks * Microsoft Exchange (disambiguation) * Telephone exchange, a system that connects telephone calls Art, entertainment, and media =Games= * Exchange (chess), closely related or sequential captures of pieces of both players in a chess game **The exchange (chess), a specific type of exchange where a player exchanges a minor piece for an opponent's rook =Music= * Exchange (song), a 2015 song by Bryson Tiller * Exchange, a new-age/atmospheric instrumental band composed of Steve Sexton and Gerald O'Brien and also their 1992 self-titled album * Exchange (album), a 1999 split EP by the punk bands Against All Authority and The Criminals * \\"Exchange\\" or \\"(Exchange)\\", two songs on Massive Attack's Mezzanine (album) Other uses * Student exchange program  See also  * Columbian exchange * The Exchange (disambiguation) * Exchange Building (disambiguation) * Exchange Hotel (disambiguation) * Interchange (disambiguation) * X-Change (disambiguation) ","title":"Exchange"},{"id":"41126","text":"In telecommunication, an exempted addressee is an organization, activity, or person included in the collective address group of a message and deemed by the message originator as having no need for the information in the message. Exempted addressees may be explicitly excluded from the collective address group for the particular message to which the exemption applies. References Category:Data transmission ","title":"Exempted addressee"},{"id":"41128","text":"In telecommunications, extended superframe (ESF) is a T1 framing standard. ESF is sometimes called D5 Framing because it was first used in the D5 channel bank, invented in the 1980s. It is preferred to its predecessor, superframe, because it includes a cyclic redundancy check (CRC) and 4000 bit/s channel capacity for a data link channel (used to pass out-of-band data between equipment.) It requires less frequent synchronization than the earlier superframe format, and provides on-line, real-time monitoring of circuit capability and operating condition. Structure An extended superframe is 24 frames long, and the framing bit of each frame is used in the following manner: * All odd-numbered frames (1, 3, ..., 23) are used for the data link (totalling 4000 bits per second), * Frames 2, 6, 10, 14, 18, and 22 are used to pass the CRC total of the previous extended superframe (all 4632 bits, framing and data), and * Frames 4, 8, 12, 16, 20, and 24 are used to send the fixed framing pattern, 001011. The CRC is computed using the polynomial over all 24√ó193 = 4632 bits (framing and data) of the previous superframe, but with its framing bits forced to 1 for the purpose of CRC computation. The purpose of this small CRC is not to take any immediate action, but to keep statistics on the performance of the link. Like the predecessor superframe, every sixth frame's least-significant data bit can be used for robbed-bit signaling of call supervision state. However, there are four such bits (ABCD) per channel per extended superframe, rather than the two bits (AB) provided per superframe. (Specifically, the robbed bits follow framing bits 6, 12, 18 and 24.) Unlike the superframe, it is possible to avoid robbed-bit signalling and send call supervision over the data link instead. References * Category:Multiplexing Category:Telephony signals Category:Synchronization ","title":"Extended superframe"},{"id":"41130","text":"Eye diagram showing an example of two power levels in an OOK modulation scheme, which can be used to calculate extinction ratio. P1 and P0 are represented by (binary 1) and (binary 0) respectively. In telecommunications, extinction ratio (re) is the ratio of two optical power levels of a digital signal generated by an optical source, e.g., a laser diode. The extinction ratio may be expressed as a fraction, in dB, or as a percentage. It may be given by :r_e = \\\\frac{P_1}{P_0}, where P1 is the optical power level generated when the light source is on, and P0 is the power level generated when the light source is off. The polarization extinction ratio (PER) is the ratio of optical powers of perpendicular polarizations, usually called TE (transverse electric) and TM (transverse magnetic). In telecommunications, the PER is used to characterize the degree of polarization in a polarization-maintaining device or fiber. For coherent transmitter and receiver, the PER is a key parameter, since X polarization and Y polarization are coded with different signals. References * * Material also incorporated from MIL-STD-2196. Category:Data transmission Category:Telecommunication theory Category:Engineering ratios Category:Laser science ","title":"Extinction ratio"},{"id":"41132","text":"In telecommunications, a facility is defined by Federal Standard 1037C as: # A fixed, mobile, or transportable structure, including (a) all installed electrical and electronic wiring, cabling, and equipment and (b) all supporting structures, such as utility, ground network, and electrical supporting structures. # A network-provided service to users or the network operating administration. # A transmission pathway and associated equipment. # In a protocol applicable to a data unit, such as a block or frame, an additional item of information or a constraint encoded within the protocol to provide the required control. # A real property entity consisting of one or more of the following: a building, a structure, a utility system, pavement, and underlying land. In Canada Under Canadian federal and Qu√©b√©cois provincial law, a telecommunications facility, for the purposes of determining whether GST applies, is defined by ¬ß123(1) of the GST Act to be \\"any facility, apparatus, or other thing (including any wire, cable, radio, optical, or other electromagnetic system, or any similar technical system or any part thereof) that is used or is capable of being used for telecommunications\\". This is a very broad definition that includes a wide range of things from satellites and earth stations, to telephones and fax machines. The consequence of its application is that even a simple LAN connector jack can be considered to be a telecommunications facility in Canada, for tax purposes. References Category:Telecommunications buildings ","title":"Telecommunications facility"},{"id":"41133","text":"In telecommunication, the term facsimile converter has the following meanings: 1\\\\. In a facsimile receiver, a device that changes the signal modulation from frequency-shift keying (FSK) to amplitude modulation (AM). 2\\\\. In a facsimile transmitter, a device that changes the signal modulation from amplitude modulation (AM) to frequency-shift keying (FSK). References Category:Communication circuits Category:Computing terminology ","title":"Facsimile converter"},{"id":"41134","text":"In telecommunication, the term fade margin (fading margin) has the following meanings: *A design allowance that provides for sufficient system gain or sensitivity to accommodate expected fading, for the purpose of ensuring that the required quality of service is maintained. *The amount by which a received signal level may be reduced without causing system performance to fall below a specified threshold value. It is mainly used to describe a communication system such as satellite, for example a system like globalstar operates at 25-35 dB Fade margin. See also * Multipath propagation * Link Budget References Category:Radio frequency propagation fading Attila Hilt, \\"Availability and Fade Margin Calculations for 5G Microwave and Millimeter- Wave Anyhaul Links\\", Applied Sciences, 2019, 9(23), 5240; https://doi.org/10.3390/app9235240., Trevor Manning, \\"Microwave Radio Transmission Design Guide\\", 2nd edition; Artech House: London, UK, 2009. ","title":"Fade margin"},{"id":"41135","text":"is the probability distribution of the value of signal fading, relative to a specified reference level. In the case of phase interference fading, the time distribution of the instantaneous field strength usually approximates a Rayleigh distribution when several signal components of equal amplitude are present. The field strength is usually measured in volts per meter. The fading distribution may also be measured in terms of power level, where the unit of measure is usually watts per square meter and the expression is in decibels. References * Category:Radio frequency propagation fading ","title":"Fading distribution"},{"id":"41136","text":"In engineering, a fail-safe is a design feature or practice that in the event of a specific type of failure, inherently responds in a way that will cause minimal or no harm to other equipment, to the environment or to people. Unlike inherent safety to a particular hazard, a system being \\"fail-safe\\" does not mean that failure is impossible or improbable, but rather that the system's design prevents or mitigates unsafe consequences of the system's failure. That is, if and when a \\"fail-safe\\" system fails, it remains at least as safe as it was before the failure.\\"Fail-safe\\". AudioEnglich.net. Accessed 2009.12.31e.g., David B. Rutherford Jr., What Do You Mean It\\\\'s Fail Safe? . 1990 Rapid Transit Conference Since many types of failure are possible, failure mode and effects analysis is used to examine failure situations and recommend safety design and procedures. Some systems can never be made fail-safe, as continuous availability is needed. Redundancy, fault tolerance, or contingency plans are used for these situations (e.g. multiple independently controlled and fuel-fed engines). Examples =Mechanical or physical= Globe control valve with pneumatic diaphragm actuator. Such a valve can be designed to fail to safety using spring pressure if the actuating air is lost. Examples include: *Roller- shutter fire doors that are activated by building alarm systems or local smoke detectors must close automatically when signaled regardless of power. In case of power outage the coiling fire door does not need to close, but must be capable of automatic closing when given a signal from the building alarm systems or smoke detectors. A temperature sensitive fusible link may be employed to hold the fire doors open against gravity or a closing spring. In case of fire, the link melts and releases the doors, and they close. *Some airport baggage carts require that the person hold down a given cart's handbrake switch at all times; if the handbrake switch is released, the brake will activate, and assuming that all other portions of the braking system are working properly, the cart will stop. The handbrake-holding requirement thus both operates according to the principles of \\"fail-safety\\" and contributes to (but does not necessarily ensure) the fail-security of the system. This is an example of a dead man's switch. *Lawnmowers and snow blowers have a hand- closed lever that must be held down at all times. If it is released, it stops the blade's or rotor's rotation. This also functions as a dead man's switch. *Air brakes on railway trains and air brakes on trucks. The brakes are held in the \\"off\\" position by air pressure created in the brake system. Should a brake line split, or a carriage become de-coupled, the air pressure will be lost and the brakes applied, by springs in the case of trucks, or by a local air reservoir in trains. It is impossible to drive a truck with a serious leak in the air brake system. (Trucks may also employ wig wags to indicate low air pressure.) *Motorized gates ‚Äì In case of power outage the gate can be pushed open by hand with no crank or key required. However, as this would allow virtually anyone to go through the gate, a fail-secure design is used: In a power outage, the gate can only be opened by a hand crank that is usually kept in a safe area or under lock and key. When such a gate provides vehicle access to homes, a fail-safe design is used, where the door opens to allow fire department access. *Safety valves ‚Äì Various devices that operate with fluids use fuses or safety valves as fail-safe mechanisms. Railway semaphore signals. \\"Stop\\" or \\"caution\\" is a horizontal arm, \\"Clear to Proceed\\" is 45 degrees upwards, so failure of the actuating cable releases the signal arm to safety under gravity. *A railway semaphore signal is specially designed so that, should the cable controlling the signal break, the arm returns to the \\"danger\\" position, preventing any trains passing the inoperative signal. *Isolation valves, and control valves, that are used for example in systems containing hazardous substances, can be designed to close upon loss of power, for example by spring force. This is known as fail-closed upon loss of power. *An elevator has brakes that are held off brake pads by the tension of the elevator cable. If the cable breaks, tension is lost and the brakes latch on the rails in the shaft, so that the elevator cabin does not fall. * Vehicle air conditioning ‚Äì Defrost controls require vacuum for diverter damper operation for all functions except defrost. If vacuum fails, defrost is still available. =Electrical or electronic= Examples include: *Many devices are protected from short circuit by fuses, circuit breakers, or current limiting circuits. The electrical interruption under overload conditions will prevent damage or destruction of wiring or circuit devices due to overheating. *Avionics using redundant systems to perform the same computation using three different systems. Different results indicate a fault in the system. *Drive-by-wire and fly-by-wire controls such as an Accelerator Position Sensor typically have two potentiometers which read in opposite directions, such that moving the control will result in one reading becoming higher, and the other generally equally lower. Mismatches between the two readings indicates a fault in the system, and the ECU can often deduce which of the two readings is faulty. *Traffic light controllers use a Conflict Monitor Unit to detect faults or conflicting signals and switch an intersection to an all flashing error signal, rather than displaying potentially dangerous conflicting signals, e.g. showing green in all directions.Manual on Uniform Traffic Control Devices, Federal Highway Administration, 2003 *The automatic protection of programs and/or processing systems when a computer hardware or software failure is detected in a computer system. A classic example is a watchdog timer. See Fail-safe (computer). *A control operation or function that prevents improper system functioning or catastrophic degradation in the event of circuit malfunction or operator error; for example, the failsafe track circuit used to control railway block signals. The fact that a flashing amber is more permissive than a solid amber on many railway lines is a sign of a failsafe, as the relay, if not working, will revert to a more restrictive setting. *The iron pellet ballast on the Bathyscaphe is dropped to allow the submarine to ascend. The ballast is held in place by electromagnets. If electrical power fails, the ballast is released, and the submarine then ascends to safety. *Many nuclear reactor designs have neutron absorbing control rods suspended by electromagnets. If the power fails, they drop under gravity into the core and shut down the chain reaction in seconds by absorbing the neutrons needed for fission to continue. *In industrial automation, alarm circuits are usually \\"normally closed\\". This ensures that in case of a wire break the alarm will be triggered. If the circuit were normally open, a wire failure would go undetected, while blocking actual alarm signals. *Analog sensors and modulating actuators can usually be installed and wired such that the circuit failure results in an out-of-bound reading ‚Äì see current loop. For example, a potentiometer indicating pedal position might only travel from 20% to 80% of its full range, such that a cable break or short results in a 0% or 100% reading. *In control systems, critically important signals can be carried by a complementary pair of wires ( and ). Only states where the two signals are opposite (one is high, the other low) are valid. If both are high or both are low the control system knows that something is wrong with the sensor or connecting wiring. Simple failure modes (dead sensor, cut or unplugged wires) are thereby detected. An example would be a control system reading both the normally open (NO) and normally closed (NC) poles of a SPDT selector switch against common, and checking them for coherency before reacting to the input. *In HVAC control systems, actuators that control dampers and valves may be fail-safe, for example, to prevent coils from freezing or rooms from overheating. Older pneumatic actuators were inherently fail-safe because if the air pressure against the internal diaphragm failed, the built-in spring would push the actuator to its home position ‚Äì of course the home position needed to be the \\"safe\\" position. Newer electrical and electronic actuators need additional components (springs or capacitors) to automatically drive the actuator to home position upon loss of electrical power. *Programmable logic controllers (PLCs). To make a PLC fail- safe the system does not require energization to stop the drives associated. For example, usually, an emergency stop is a normally closed contact. In the event of a power failure this would remove the power directly from the coil and also the PLC input. Hence, a fail-safe system. *If a voltage regulator fails, it can destroy connected equipment. A crowbar (circuit) prevents damage by short-circuiting the power supply as soon as it detects overvoltage. =Procedural safety= An aircraft lights its afterburners to maintain full power during an arrested landing aboard an aircraft carrier. If the arrested landing fails, the aircraft can safely take off again. As well as physical devices and systems fail-safe procedures can be created so that if a procedure is not carried out or carried out incorrectly no dangerous action results. For example: *Spacecraft trajectory - During early Apollo program missions to the Moon, the spacecraft was put on a free return trajectory ‚Äî if the engines had failed at lunar orbit insertion, the craft would have safely coasted back to Earth. *The pilot of an aircraft landing on an aircraft carrier increases the throttle to full power at touchdown. If the arresting wires fail to capture the aircraft, it is able to take off again; this is an example of fail-safe practice. *In railway signalling signals which are not in active use for a train are required to be kept in the 'danger' position. The default position of every controlled absolute signal is therefore \\"danger\\", and therefore a positive action ‚Äî setting signals to \\"clear\\" ‚Äî is required before a train may pass. This practice also ensures that, in case of a fault in the signalling system, an incapacitated signalman, or the unexpected entry of a train, that a train will never be shown an erroneous \\"clear\\" signal. *Railroad engineers are instructed that a railway signal showing a confusing, contradictory or unfamiliar aspect (for example a colour light signal that has suffered an electrical failure and is showing no light at all) must be treated as showing \\"danger\\". In this way, the driver contributes to the fail-safety of the system. Other terminology Fail-safe (foolproof) devices are also known as poka-yoke devices. Poka-yoke, a Japanese term, was coined by Shigeo Shingo, a quality expert.Shingo, Shigeo; Andrew P. Dillon (1989). A study of the Toyota production system from an industrial engineering viewpoint. Portland, Oregon: Productivity Press. p. 22. . John R. Grout, Brian T. Downs. \\"A Brief Tutorial on Mistake-proofing, Poka-Yoke, and ZQC\\", MistakeProofing.com \\"Safe to fail\\" refers to civil engineering designs such as the Room for the River project in Netherlands and the Thames Estuary 2100 Plan which incorporate flexible adaptation strategies or climate change adaptation which provide for, and limit, damage, should severe events such as 500-year floods occur. =Fail safe and fail secure= Fail-safe and fail-secure are distinct concepts. Fail- safe means that a device will not endanger lives or property when it fails. Fail-secure, also called fail-closed, means that access or data will not fall into the wrong hands in a security failure. Sometimes the approaches suggest opposite solutions. For example, if a building catches fire, fail-safe systems would unlock doors to ensure quick escape and allow firefighters inside, while fail-secure would lock doors to prevent unauthorized access to the building. The opposite of fail-closed is called fail-open. =Fail Active Operational= Fail active operational can be installed on systems that have a high degree of redundancy so that a single failure of any part of the system can be tolerated (fail active operational) and a second failure can be detected ‚Äì at which point the system will turn itself off (uncouple, fail passive). One way of accomplishing this is to have three identical systems installed, and a control logic which detects discrepancies. An example for this are many aircraft systems, among them inertial navigation systems and Pitot tubes. See also *Fail-fast *Control theory *Dead man's switch *EIA-485 *Elegant degradation *Failing badly *Fail-deadly *Fault tolerance *IEC 61508 *Interlock *Safe-life design *Safety engineering References Category:Safety Category:Fault tolerance Category:Fault-tolerant computer systems ","title":"Fail-safe"},{"id":"41138","text":"In electronics, fall time (pulse decay time) \\\\scriptstyle t_f\\\\, is the time taken for the amplitude of a pulse to decrease (fall) from a specified value (usually 90% of the peak value exclusive of overshoot or undershoot) to another specified value (usually 10% of the maximum value exclusive of overshoot or undershoot). Limits on undershoot and oscillation (also known as ringing and hunting) are sometimes additionally stated when specifying fall time limits.  See also  *Rise time *Transition time  References  * Category:Transient response characteristics ","title":"Fall time"},{"id":"41142","text":"In telecommunications, fast packet switching is a variant of packet switching that increases the throughput by eliminating overhead associated with flow control and error correction functions, which are either offloaded to upper layer networking protocols or removed altogether. ATM and Frame Relay are two major implementations of fast packet switching. References * Category:Packets (information technology) ","title":"Fast packet switching"},{"id":"41143","text":"Fault commonly refers to: *Fault (geology), planar rock fractures showing evidence of relative movement *Fault (law), blameworthiness or responsibility Fault(s) may also refer to: Arts, entertainment, and media  * \\"Fault\\", a song by Taproot from Welcome *Faults (film), 2014 *Fault Milestone One, a video game **Fault Milestone Two, video game sequel to the above Science and technology *Fault (computing), also called a trap or an exception, a type of interrupt in software or operating systems *Fault (technology), an abnormal condition or defect that may lead to a failure *Electrical fault, an abnormal current Sport and competition *Fault (breeding), an undesirable aspect of structure or appearance of an animal *Fault, in tennis jargon, a serve that fails to place a tennis ball in the correct area of play *Fault, a penalty in show jumping See also *Blame *Defect (disambiguation) *Error *Mistake (disambiguation) *Software bug ","title":"Fault"},{"id":"41144","text":"In network management, fault management is the set of functions that detect, isolate, and correct malfunctions in a telecommunications network, compensate for environmental changes, and include maintaining and examining error logs, accepting and acting on error detection notifications, tracing and identifying faults, carrying out sequences of diagnostics tests, correcting faults, reporting error conditions, and localizing and tracing faults by examining and manipulating database information. When a fault or event occurs, a network component will often send a notification to the network operator using a protocol such as SNMP. An alarm is a persistent indication of a fault that clears only when the triggering condition has been resolved. A current list of problems occurring on the network component is often kept in the form of an active alarm list such as is defined in RFC 3877, the Alarm MIB. A list of cleared faults is also maintained by most network management systems. Fault management systems may use complex filtering systems to assign alarms to severity levels. These can range in severity from debug to emergency, as in the syslog protocol.RFC 3164 Alternatively, they could use the ITU X.733 Alarm Reporting Function's perceived severity field. This takes on values of cleared, indeterminate, critical, major, minor or warning. Note that the latest version of the syslog protocol draft under development within the IETF includes a mapping between these two different sets of severities. It is considered good practice to send a notification not only when a problem has occurred, but also when it has been resolved. The latter notification would have a severity of clear. A fault management console allows a network administrator or system operator to monitor events from multiple systems and perform actions based on this information. Ideally, a fault management system should be able to correctly identify events and automatically take action, either launching a program or script to take corrective action, or activating notification software that allows a human to take proper intervention (i.e. send e-mail or SMS text to a mobile phone). Some notification systems also have escalation rules that will notify a chain of individuals based on availability and severity of alarm. Types There are two primary ways to perform fault management - these are active and passive. Passive fault management is done by collecting alarms from devices (normally via SNMP traps) when something happens in the devices. In this mode, the fault management system only knows if a device it is monitoring is intelligent enough to generate an error and report it to the management tool. However, if the device being monitored fails completely or locks up, it won't throw an alarm and the problem will not be detected. Active fault management addresses this issue by actively monitoring devices via tools such as ping to determine if the device is active and responding. If the device stops responding, active monitoring will throw an alarm showing the device as unavailable and allows for the proactive correction of the problem. Fault management includes any tools or procedure for testing, diagnosing or repairing the network when a failure occurs. See also *Alarm management *Alarm fatigue Notes References * Category:Network management ","title":"Fault management"},{"id":"41145","text":"The FCC, or Federal Communications Commission, is an independent agency of the United States government. FCC may also refer to: Christianity * Federated Colored Catholics * Free Church of Scotland (disambiguation) * Franciscan Clarist Congregation Education * Faujdarhat Cadet College, in Bangladesh * Federal City College, now merged into the University of the District of Columbia * Felpham Community College, in England * Florida Christian College, now Johnson University Florida, in Kissimmee, Florida, United States * Forman Christian College, in Lahore, Pakistan * Frederick Community College, in Maryland, United States * Fresno City College, in Fresno, California, United States * Footscray City College, a high school in Melbourne, Australia * freeCodeCamp, a non-profit online course which teaches computer programming Science and technology * Face-centered cubic * Female cosmetic coalitions, a theory about the emergence of art, ritual and symbolic culture * Fibrocystic change * Flash column chromatography * Fluid catalytic cracking * Food Chemicals Codex * Future Circular Collider, a proposed particle collider * A hypothetical 3-in-one vaccine, for the flu, common cold, and COVID-19. Sport * Chilean Cycling Federation (Spanish: ') * Colombian Cycling Federation (Spanish: ') * Cuban Cycling Federation (Spanish: ') * FC Carl Zeiss Jena, a German association football club * FC Chartres, a French association football club * FC Cincinnati, an American soccer club who currently play in MLS ** FC Cincinnati (2016‚Äì18), predecessor to the above, which played in the league now known as the USL Championship * FIFA Confederations Cup, international association football tournament for men's national teams organised by FIFA * Four Continents Championships, a figure skating competition Transport * Ferrocarriles de Cuba, the National Railways of Cuba * First Capital Connect, a defunct United Kingdom train operator Other uses * Fairfield Community Connection, an American bulletin board system * Falling Creek Camp, in North Carolina, United States * Farm Credit Canada, formerly the Farm Credit Corporation, a Canadian crown corporation * The F.C.C. (band), an American band * FCC Environment, a British waste management firm * \\"FCC Song\\", by Eric Idle * Federal Correctional Complex; see List of U.S. federal prisons * Five Country Conference, a conference of the immigration authorities for English speaking countries * Fomento de Construcciones y Contratas, a Spanish construction firm * Foreign Correspondents' Club, a group of clubs for correspondents and journalists * Foreign Correspondents' Club, Hong Kong * Civil Forum for Change (FCC in French), an alliance of civil society groups created in Algeria in 2019 * The Future Cities Catapult, which in April 2019 became the Connected Places Catapult ","title":"FCC (disambiguation)"},{"id":"41146","text":"In telecommunication, FCC registration program is the Federal Communications Commission (FCC) program and associated directives intended to assure that all connected terminal equipment and protective circuitry will not harm the public switched telephone network or certain private line services. Note 1: The FCC registration program requires the registering of terminal equipment and protective circuitry in accordance with Subpart C of part 68, Title 47 of the Code of Federal Regulations. This includes the assignment of identification numbers to the equipment and the testing of the equipment. Note 2: The FCC registration program contains no requirement that accepted terminal equipment be compatible with, or function with, the network. External links * FCC Equipment Authorization Database Search Facility Registration program ","title":"FCC registration program"},{"id":"41147","text":"Feed or The Feed may refer to:  Animal foodstuffs  * Animal feed, food given to domestic animals in the course of animal husbandry ** Fodder, foodstuffs manufactured for animal consumption ** Forage, foodstuffs that animals gather themselves, such as by grazing * Compound feed, foodstuffs that are blended from various raw materials and additives  Arts, entertainment, and media  =Film= * Feed (2005 film), a 2005 film directed by Brett Leonard * Feed (2017 film), a 2017 film directed by Tommy Bertelsen =Literature= * Feed (Anderson novel), a 2002 dystopian novel of the cyberpunk genre by M. T. (Matthew Tobin) Anderson * Feed (Grant novel), a 2010 novel about bloggers in a post-zombie apocalypse Earth by Seanan McGuire under the name \\"Mira Grant\\" =Online media= * Feed Magazine, one of the earliest e-zines that relied entirely on its original online content * \\"The Feed\\", video game news and blogs, published by G4 Media, an NBCUniversal subsidiary * \\"Instagram Feed\\" or abbreviated \\"Feed\\", a term to distinguish Instagram normal posts from stories =Television= * The Feed (Australian TV series), an Australian news TV series * The Feed (British TV series), a 2019 psychological thriller drama television series * The Feed, a recurring segment on the American TV series Attack of the Show! =Video games= * In video game terminology, to die repeatedly  Computing and telecommunications  * Antenna feed, the components of an antenna which feed the radio waves to the rest of the antenna structure * Data feed, a mechanism for users to receive updates from data sources * Web feed or news feed, a data format used for providing users with frequently updated content ** feed URI scheme (\`feed:\`), a non-standard URI scheme designed to facilitate subscription to web feeds * Relay (disambiguation), any of several technologies for forwarding messages between stations ** Feed, a broadcasting signal sent from one station to another, or to or from a central facility, intended for retransmission See also  FEED (disambiguation) * Feeder (disambiguation) * Feeding (disambiguation) ","title":"Feed"},{"id":"41148","text":"Optical amplifiers are used to create laser guide stars which provide feedback to the adaptive optics control systems which dynamically adjust the shape of the mirrors in the largest astronomical telescopes. An optical amplifier is a device that amplifies an optical signal directly, without the need to first convert it to an electrical signal. An optical amplifier may be thought of as a laser without an optical cavity, or one in which feedback from the cavity is suppressed. Optical amplifiers are important in optical communication and laser physics. They are used as optical repeaters in the long distance fiberoptic cables which carry much of the world's telecommunication links. There are several different physical mechanisms that can be used to amplify a light signal, which correspond to the major types of optical amplifiers. In doped fiber amplifiers and bulk lasers, stimulated emission in the amplifier's gain medium causes amplification of incoming light. In semiconductor optical amplifiers (SOAs), electron-hole recombination occurs. In Raman amplifiers, Raman scattering of incoming light with phonons in the lattice of the gain medium produces photons coherent with the incoming photons. Parametric amplifiers use parametric amplification. Laser amplifiers Almost any laser active gain medium can be pumped to produce gain for light at the wavelength of a laser made with the same material as its gain medium. Such amplifiers are commonly used to produce high power laser systems. Special types such as regenerative amplifiers and chirped-pulse amplifiers are used to amplify ultrashort pulses. = Solid-state amplifiers = Solid-state amplifiers are optical amplifiers that uses a wide range of doped solid-state materials (Nd:YAG, Yb:YAG, Ti:Sa) and different geometries (disk, slab, rod) to amplify optical signals. The variety of materials allows the amplification of different wavelength while the shape of the medium can distinguish between more suitable for energy of average power scaling. Beside their use in fundamental research from gravitational wave detection to high energy physics at the National Ignition Facility they can also be found in many of today‚Äôs ultra short pulsed lasers. = Doped fiber amplifiers = Schematic diagram of a simple Doped Fiber Amplifier Doped fiber amplifiers (DFAs) are optical amplifiers that use a doped optical fiber as a gain medium to amplify an optical signal. They are related to fiber lasers. The signal to be amplified and a pump laser are multiplexed into the doped fiber, and the signal is amplified through interaction with the doping ions. Amplification is achieved by stimulated emission of photons from dopant ions in the doped fiber. The pump laser excites ions into a higher energy from where they can decay via stimulated emission of a photon at the signal wavelength back to a lower energy level. The excited ions can also decay spontaneously (spontaneous emission) or even through nonradiative processes involving interactions with phonons of the glass matrix. These last two decay mechanisms compete with stimulated emission reducing the efficiency of light amplification. The amplification window of an optical amplifier is the range of optical wavelengths for which the amplifier yields a usable gain. The amplification window is determined by the spectroscopic properties of the dopant ions, the glass structure of the optical fiber, and the wavelength and power of the pump laser. Although the electronic transitions of an isolated ion are very well defined, broadening of the energy levels occurs when the ions are incorporated into the glass of the optical fiber and thus the amplification window is also broadened. This broadening is both homogeneous (all ions exhibit the same broadened spectrum) and inhomogeneous (different ions in different glass locations exhibit different spectra). Homogeneous broadening arises from the interactions with phonons of the glass, while inhomogeneous broadening is caused by differences in the glass sites where different ions are hosted. Different sites expose ions to different local electric fields, which shifts the energy levels via the Stark effect. In addition, the Stark effect also removes the degeneracy of energy states having the same total angular momentum (specified by the quantum number J). Thus, for example, the trivalent erbium ion (Er3+) has a ground state with J = 15/2, and in the presence of an electric field splits into J + 1/2 = 8 sublevels with slightly different energies. The first excited state has J = 13/2 and therefore a Stark manifold with 7 sublevels. Transitions from the J = 13/2 excited state to the J= 15/2 ground state are responsible for the gain at 1500 nm wavelength. The gain spectrum of the EDFA has several peaks that are smeared by the above broadening mechanisms. The net result is a very broad spectrum (30 nm in silica, typically). The broad gain-bandwidth of fiber amplifiers make them particularly useful in wavelength-division multiplexed communications systems as a single amplifier can be utilized to amplify all signals being carried on a fiber and whose wavelengths fall within the gain window. An erbium-doped waveguide amplifier (EDWA) is an optical amplifier that uses a waveguide to boost an optical signal. Basic principle of erbium-doped fiber amplifier (EDFA) A relatively high-powered beam of light is mixed with the input signal using a wavelength selective coupler (WSC). The input signal and the excitation light must be at significantly different wavelengths. The mixed light is guided into a section of fiber with erbium ions included in the core. This high-powered light beam excites the erbium ions to their higher-energy state. When the photons belonging to the signal at a different wavelength from the pump light meet the excited erbium ions, the erbium ions give up some of their energy to the signal and return to their lower-energy state. A significant point is that the erbium gives up its energy in the form of additional photons which are exactly in the same phase and direction as the signal being amplified. So the signal is amplified along its direction of travel only. This is not unusual ‚Äì when an atom \\"lases\\" it always gives up its energy in the same direction and phase as the incoming light. Thus all of the additional signal power is guided in the same fiber mode as the incoming signal. There is usually an isolator placed at the output to prevent reflections returning from the attached fiber. Such reflections disrupt amplifier operation and in the extreme case can cause the amplifier to become a laser. The erbium doped amplifier is a high gain amplifier. Noise The principal source of noise in DFAs is Amplified Spontaneous Emission (ASE), which has a spectrum approximately the same as the gain spectrum of the amplifier. Noise figure in an ideal DFA is 3 dB, while practical amplifiers can have noise figure as large as 6‚Äì8 dB. As well as decaying via stimulated emission, electrons in the upper energy level can also decay by spontaneous emission, which occurs at random, depending upon the glass structure and inversion level. Photons are emitted spontaneously in all directions, but a proportion of those will be emitted in a direction that falls within the numerical aperture of the fiber and are thus captured and guided by the fiber. Those photons captured may then interact with other dopant ions, and are thus amplified by stimulated emission. The initial spontaneous emission is therefore amplified in the same manner as the signals, hence the term Amplified Spontaneous Emission. ASE is emitted by the amplifier in both the forward and reverse directions, but only the forward ASE is a direct concern to system performance since that noise will co-propagate with the signal to the receiver where it degrades system performance. Counter-propagating ASE can, however, lead to degradation of the amplifier's performance since the ASE can deplete the inversion level and thereby reduce the gain of the amplifier and increase the noise produced relative to the desired signal gain. Noise figure can be analyzed in both the optical domain and in the electrical domain.Baney, Douglas, M., Gallion, Philippe, Tucker, Rodney S., ‚ÄùTheory and Measurement Techniques for the Noise Figure of Optical Amplifiers‚Äù, Optical Fiber Technology 6, 122 pp. 122-154 (2000) In the optical domain, measurement of the ASE, the optical signal gain, and signal wavelength using an optical spectrum analyzer permits calculation of the noise figure. For the electrical measurement method, the detected photocurrent noise is evaluated with a low- noise electrical spectrum analyzer, which along with measurement of the amplifier gain permits a noise figure measurement. Generally, the optical technique provides a more simple method, though it is not inclusive of excess noise effects captured by the electrical method such multi-path interference (MPI) noise generation. In both methods, attention to effects such as the spontaneous emission accompanying the input signal are critical to accurate measurement of noise figure. Gain saturation Gain is achieved in a DFA due to population inversion of the dopant ions. The inversion level of a DFA is set, primarily, by the power of the pump wavelength and the power at the amplified wavelengths. As the signal power increases, or the pump power decreases, the inversion level will reduce and thereby the gain of the amplifier will be reduced. This effect is known as gain saturation ‚Äì as the signal level increases, the amplifier saturates and cannot produce any more output power, and therefore the gain reduces. Saturation is also commonly known as gain compression. To achieve optimum noise performance DFAs are operated under a significant amount of gain compression (10 dB typically), since that reduces the rate of spontaneous emission, thereby reducing ASE. Another advantage of operating the DFA in the gain saturation region is that small fluctuations in the input signal power are reduced in the output amplified signal: smaller input signal powers experience larger (less saturated) gain, while larger input powers see less gain. The leading edge of the pulse is amplified, until the saturation energy of the gain medium is reached. In some condition, the width (FWHM) of the pulse is reduced. Inhomogeneous broadening effects Due to the inhomogeneous portion of the linewidth broadening of the dopant ions, the gain spectrum has an inhomogeneous component and gain saturation occurs, to a small extent, in an inhomogeneous manner. This effect is known as spectral hole burning because a high power signal at one wavelength can 'burn' a hole in the gain for wavelengths close to that signal by saturation of the inhomogeneously broadened ions. Spectral holes vary in width depending on the characteristics of the optical fiber in question and the power of the burning signal, but are typically less than 1 nm at the short wavelength end of the C-band, and a few nm at the long wavelength end of the C-band. The depth of the holes are very small, though, making it difficult to observe in practice. Polarization effects Although the DFA is essentially a polarization independent amplifier, a small proportion of the dopant ions interact preferentially with certain polarizations and a small dependence on the polarization of the input signal may occur (typically < 0.5 dB). This is called Polarization Dependent Gain (PDG). The absorption and emission cross sections of the ions can be modeled as ellipsoids with the major axes aligned at random in all directions in different glass sites. The random distribution of the orientation of the ellipsoids in a glass produces a macroscopically isotropic medium, but a strong pump laser induces an anisotropic distribution by selectively exciting those ions that are more aligned with the optical field vector of the pump. Also, those excited ions aligned with the signal field produce more stimulated emission. The change in gain is thus dependent on the alignment of the polarizations of the pump and signal lasers ‚Äì i.e. whether the two lasers are interacting with the same sub-set of dopant ions or not. In an ideal doped fiber without birefringence, the PDG would be inconveniently large. Fortunately, in optical fibers small amounts of birefringence are always present and, furthermore, the fast and slow axes vary randomly along the fiber length. A typical DFA has several tens of meters, long enough to already show this randomness of the birefringence axes. These two combined effects (which in transmission fibers give rise to polarization mode dispersion) produce a misalignment of the relative polarizations of the signal and pump lasers along the fiber, thus tending to average out the PDG. The result is that PDG is very difficult to observe in a single amplifier (but is noticeable in links with several cascaded amplifiers). = Erbium-doped optical fiber amplifiers = The erbium-doped fiber amplifier (EDFA) is the most deployed fiber amplifier as its amplification window coincides with the third transmission window of silica-based optical fiber. The core of a silica fiber is doped with trivalent erbium ions (Er3+) and can be efficiently pumped with a laser at or near wavelengths of 980 nm and 1480 nm, and gain is exhibited in the 1550 nm region. The EDFA amplification region varies from application to application and can be anywhere between few nm up to ~80nm. Typical use of EDFA in telecommunications calls for Conventional, or C-band amplifiers (from ~1525 nm to ~1565 nm) or Long, or L-band amplifiers (from ~1565 nm to ~1610 nm). Both of these bands can be amplified by EDFAs, but it is normal to use two different amplifiers, each optimized for one of the bands. The principal difference between C- and L-band amplifiers is that a longer length of doped fiber is used in L-band amplifiers. The longer length of fiber allows a lower inversion level to be used, thereby giving emission at longer wavelengths (due to the band-structure of Erbium in silica) while still providing a useful amount of gain. EDFAs have two commonly used pumping bands ‚Äì 980 nm and 1480 nm. The 980 nm band has a higher absorption cross-section and is generally used where low-noise performance is required. The absorption band is relatively narrow and so wavelength stabilised laser sources are typically needed. The 1480 nm band has a lower, but broader, absorption cross-section and is generally used for higher power amplifiers. A combination of 980 nm and 1480 nm pumping is generally utilised in amplifiers. Gain and lasing in Erbium-doped fibers were first demonstrated in 1986‚Äì87 by two groups; one including David N. Payne, R. Mears, I.M Jauncey and L. Reekie, from the University of SouthamptonMears, R.J. and Reekie, L. and Poole, S.B. and Payne, D.N.: \\"Low-threshold tunable CW and Q-switched fiber laser operating at 1.55¬µm\\", Electron. Lett., 1986, 22, pp.159‚Äì160R.J. Mears, L. Reekie, I.M. Jauncey and D. N. Payne: ‚ÄúLow-noise Erbium-doped fiber amplifier at 1.54¬µm‚Äù, Electron. Lett., 1987, 23, pp.1026‚Äì1028 and one from AT&T; Bell Laboratories, consisting of E. Desurvire, P. Becker, and J. Simpson.E. Desurvire, J. Simpson, and P.C. Becker, High-gain erbium-doped traveling-wave fiber amplifier,\\" Optics Letters, vol. 12, No. 11, 1987, pp. 888‚Äì890 The dual-stage optical amplifier which enabled Dense Wave Division Multiplexing (DWDM) was invented by Stephen B. Alexander at Ciena Corporation.United States Patent Office #5696615; ‚ÄúWavelength division multiplexed optical communication systems employing uniform gain optical amplifiers.‚Äù =Doped fiber amplifiers for other wavelength ranges= Thulium doped fiber amplifiers have been used in the S-band (1450‚Äì1490 nm) and Praseodymium doped amplifiers in the 1300 nm region. However, those regions have not seen any significant commercial use so far and so those amplifiers have not been the subject of as much development as the EDFA. However, Ytterbium doped fiber lasers and amplifiers, operating near 1 micrometre wavelength, have many applications in industrial processing of materials, as these devices can be made with extremely high output power (tens of kilowatts). Semiconductor optical amplifier Semiconductor optical amplifiers (SOAs) are amplifiers which use a semiconductor to provide the gain medium.M. J. Connolly, Semiconductor Optical Amplifiers. Boston, MA: Springer- Verlag, 2002. These amplifiers have a similar structure to Fabry‚ÄìP√©rot laser diodes but with anti-reflection design elements at the end faces. Recent designs include anti-reflective coatings and tilted wave guide and window regions which can reduce end face reflection to less than 0.001%. Since this creates a loss of power from the cavity which is greater than the gain, it prevents the amplifier from acting as a laser. Another type of SOA consists of two regions. One part has a structure of a Fabry-P√©rot laser diode and the other has a tapered geometry in order to reduce the power density on the output facet. Semiconductor optical amplifiers are typically made from group III-V compound semiconductors such as GaAs/AlGaAs, InP/InGaAs, InP/InGaAsP and InP/InAlGaAs, though any direct band gap semiconductors such as II-VI could conceivably be used. Such amplifiers are often used in telecommunication systems in the form of fiber-pigtailed components, operating at signal wavelengths between 850 nm and 1600 nm and generating gains of up to 30 dB. The semiconductor optical amplifier is of small size and electrically pumped. It can be potentially less expensive than the EDFA and can be integrated with semiconductor lasers, modulators, etc. However, the performance is still not comparable with the EDFA. The SOA has higher noise, lower gain, moderate polarization dependence and high nonlinearity with fast transient time. The main advantage of SOA is that all four types of nonlinear operations (cross gain modulation, cross phase modulation, wavelength conversion and four wave mixing) can be conducted. Furthermore, SOA can be run with a low power laser. This originates from the short nanosecond or less upper state lifetime, so that the gain reacts rapidly to changes of pump or signal power and the changes of gain also cause phase changes which can distort the signals. This nonlinearity presents the most severe problem for optical communication applications. However it provides the possibility for gain in different wavelength regions from the EDFA. \\"Linear optical amplifiers\\" using gain- clamping techniques have been developed. High optical nonlinearity makes semiconductor amplifiers attractive for all optical signal processing like all-optical switching and wavelength conversion. There has been much research on semiconductor optical amplifiers as elements for optical signal processing, wavelength conversion, clock recovery, signal demultiplexing, and pattern recognition. =Vertical-cavity SOA= A recent addition to the SOA family is the vertical-cavity SOA (VCSOA). These devices are similar in structure to, and share many features with, vertical-cavity surface-emitting lasers (VCSELs). The major difference when comparing VCSOAs and VCSELs is the reduced mirror reflectivity used in the amplifier cavity. With VCSOAs, reduced feedback is necessary to prevent the device from reaching lasing threshold. Due to the extremely short cavity length, and correspondingly thin gain medium, these devices exhibit very low single-pass gain (typically on the order of a few percent) and also a very large free spectral range (FSR). The small single-pass gain requires relatively high mirror reflectivity to boost the total signal gain. In addition to boosting the total signal gain, the use of the resonant cavity structure results in a very narrow gain bandwidth; coupled with the large FSR of the optical cavity, this effectively limits operation of the VCSOA to single-channel amplification. Thus, VCSOAs can be seen as amplifying filters. Given their vertical-cavity geometry, VCSOAs are resonant cavity optical amplifiers that operate with the input/output signal entering/exiting normal to the wafer surface. In addition to their small size, the surface normal operation of VCSOAs leads to a number of advantages, including low power consumption, low noise figure, polarization insensitive gain, and the ability to fabricate high fill factor two-dimensional arrays on a single semiconductor chip. These devices are still in the early stages of research, though promising preamplifier results have been demonstrated. Further extensions to VCSOA technology are the demonstration of wavelength tunable devices. These MEMS-tunable vertical-cavity SOAs utilize a microelectromechanical systems (MEMS) based tuning mechanism for wide and continuous tuning of the peak gain wavelength of the amplifier. SOAs have a more rapid gain response, which is in the order of 1 to 100 ps. =Tapered amplifiers= For high output power and broader wavelength range, tapered amplifiers are used. These amplifiers consist of a lateral single-mode section and a section with a tapered structure, where the laser light is amplified. The tapered structure leads to a reduction of the power density at the output facet. Typical parameters: * wavelength range: 633 to 1480 nm * input power: 10 to 50 mW * output power: up to 3 W  Raman amplifier  In a Raman amplifier, the signal is intensified by Raman amplification. Unlike the EDFA and SOA the amplification effect is achieved by a nonlinear interaction between the signal and a pump laser within an optical fiber. There are two types of Raman amplifier: distributed and lumped. A distributed Raman amplifier is one in which the transmission fiber is utilised as the gain medium by multiplexing a pump wavelength with signal wavelength, while a lumped Raman amplifier utilises a dedicated, shorter length of fiber to provide amplification. In the case of a lumped Raman amplifier, a highly nonlinear fiber with a small core is utilised to increase the interaction between signal and pump wavelengths, and thereby reduce the length of fiber required. The pump light may be coupled into the transmission fiber in the same direction as the signal (co-directional pumping), in the opposite direction (contra-directional pumping) or both. Contra-directional pumping is more common as the transfer of noise from the pump to the signal is reduced. The pump power required for Raman amplification is higher than that required by the EDFA, with in excess of 500 mW being required to achieve useful levels of gain in a distributed amplifier. Lumped amplifiers, where the pump light can be safely contained to avoid safety implications of high optical powers, may use over 1 W of optical power. The principal advantage of Raman amplification is its ability to provide distributed amplification within the transmission fiber, thereby increasing the length of spans between amplifier and regeneration sites. The amplification bandwidth of Raman amplifiers is defined by the pump wavelengths utilised and so amplification can be provided over wider, and different, regions than may be possible with other amplifier types which rely on dopants and device design to define the amplification 'window'. Raman amplifiers have some fundamental advantages. First, Raman gain exists in every fiber, which provides a cost-effective means of upgrading from the terminal ends. Second, the gain is nonresonant, which means that gain is available over the entire transparency region of the fiber ranging from approximately 0.3 to 2¬µm. A third advantage of Raman amplifiers is that the gain spectrum can be tailored by adjusting the pump wavelengths. For instance, multiple pump lines can be used to increase the optical bandwidth, and the pump distribution determines the gain flatness. Another advantage of Raman amplification is that it is a relatively broad-band amplifier with a bandwidth > 5 THz, and the gain is reasonably flat over a wide wavelength range. However, a number of challenges for Raman amplifiers prevented their earlier adoption. First, compared to the EDFAs, Raman amplifiers have relatively poor pumping efficiency at lower signal powers. Although a disadvantage, this lack of pump efficiency also makes gain clamping easier in Raman amplifiers. Second, Raman amplifiers require a longer gain fiber. However, this disadvantage can be mitigated by combining gain and the dispersion compensation in a single fiber. A third disadvantage of Raman amplifiers is a fast response time, which gives rise to new sources of noise, as further discussed below. Finally, there are concerns of nonlinear penalty in the amplifier for the WDM signal channels. Note: The text of an earlier version of this article was taken from the public domain Federal Standard 1037C.  Optical parametric amplifier  An optical parametric amplifier allows the amplification of a weak signal-impulse in a noncentrosymmetric nonlinear medium (e.g. Beta barium borate (BBO)). In contrast to the previously mentioned amplifiers, which are mostly used in telecommunication environments, this type finds its main application in expanding the frequency tunability of ultrafast solid-state lasers (e.g. Ti:sapphire). By using a noncollinear interaction geometry optical parametric amplifiers are capable of extremely broad amplification bandwidths.  Recent achievements  The adoption of high power fiber lasers as an industrial material processing tool has been ongoing for several years and is now expanding into other markets including the medical and scientific markets. One key enhancement enabling penetration into the scientific market has been the improvements in high finesse fiber amplifiers, which are now capable of delivering single frequency linewidths (<5 kHz) together with excellent beam quality and stable linearly polarized output. Systems meeting these specifications have steadily progressed in the last few years from a few watts of output power, initially to the tens of watts and now into the hundreds of watts power level. This power scaling has been achieved with developments in the fiber technology, such as the adoption of stimulated brillouin scattering (SBS) suppression/mitigation techniques within the fiber, along with improvements in the overall amplifier design including large mode area (LMA) fibers with a low-aperture core, micro- structured rod-type fiber helical core, or chirally-coupled core fibers, and tapered double-clad fibers (T-DCF). The latest generation of high finesse, high power and pulsed fiber amplifiers now deliver power levels exceeding what is available from commercial solid-state single frequency sources and are opening up new scientific applications as a result of the higher power levels and stable optimized performance. Implementations There are several simulation tools that can be used to design optical amplifiers. Popular commercial tools have been developed by Optiwave Systems and VPI Systems. See also * Regenerative amplification * Nonlinear theory of semiconductor lasers References External links * Overview of commercially available semiconductor tapered amplifiers * Overview of commercially available solid- state amplifiers * Encyclopedia of laser physics and technology on fiber amplifiers and Raman amplifiers Category:Optical devices Category:Amplifiers Category:Laser science Category:Fiber-optic communications ","title":"Optical amplifier"},{"id":"41150","text":"In physics, field strength means the magnitude of a vector-valued field (e.g., in volts per meter, V/m, for an electric field E). For example, an electromagnetic field results in both electric field strength and magnetic field strength. As an application, in radio frequency telecommunications, the signal strength excites a receiving antenna and thereby induces a voltage at a specific frequency and polarization in order to provide an input signal to a radio receiver. Field strength meters are used for such applications as cellular, broadcasting, wi-fi and a wide variety of other radio-related applications. See also * Dipole field strength in free space * Field strength tensor References Category:Electromagnetism Category:Physical quantities ","title":"Field strength"},{"id":"41151","text":"The term server highlights the role of the machine in the traditional client‚Äìserver scheme, where the clients are the workstations using the storage. A file server does not normally perform computational tasks or run programs on behalf of its client workstations. File servers are commonly found in schools and offices, where users use a local area network to connect their client computers. Types of file servers A file server may be dedicated or non-dedicated. A dedicated server is designed specifically for use as a file server, with workstations attached for reading and writing files and databases. File servers may also be categorized by the method of access: Internet file servers are frequently accessed by File Transfer Protocol or by HTTP (but are different from, that often provide dynamic web content in addition to static files). Servers on a LAN are usually accessed by SMB/CIFS protocol (Windows and Unix-like) or NFS protocol (Unix-like systems). Database servers, that provide access to a shared database via a database device driver, are not regarded as file servers even when the database is stored in files, as they are not designed to provide those files to users and tend to have differing technical requirements. Design of file servers In modern businesses, the design of file servers is complicated by competing demands for storage space, access speed, recoverability, ease of administration, security, and budget. This is further complicated by a constantly changing environment, where new hardware and technology rapidly obsolesces old equipment, and yet must seamlessly come online in a fashion compatible with the older machinery. To manage throughput, peak loads, and response time, vendors may utilize queuing theoryFile and Work Transfers in Cyclic Queue Systems, D. Sarkar and W. I. Zangwill, Management Science, Vol. 38, No. 10 (Oct., 1992), pp. 1510‚Äì1523 to model how the combination of hardware and software will respond over various levels of demand. Servers may also employ dynamic load balancing scheme to distribute requests across various pieces of hardware. The primary piece of hardware equipment for servers over the last couple of decades has proven to be the hard disk drive. Although other forms of storage are viable (such as magnetic tape and solid-state drives) disk drives have continued to offer the best fit for cost, performance, and capacity. =Storage= Since the crucial function of a file server is storage, technology has been developed to operate multiple disk drives together as a team, forming a disk array. A disk array typically has cache (temporary memory storage that is faster than the magnetic disks), as well as advanced functions like RAID and storage virtualization. Typically disk arrays increase level of availability by using redundant components other than RAID, such as power supplies. Disk arrays may be consolidated or virtualized in a SAN. =Network-attached storage= Network-attached storage (NAS) is file-level computer data storage connected to a computer network providing data access to a heterogeneous group of clients. NAS devices specifically are distinguished from file servers generally in a NAS being a computer appliance ‚Äì a specialized computer built from the ground up for serving files ‚Äì rather than a general purpose computer being used for serving files (possibly with other functions). In discussions of NASs, the term \\"file server\\" generally stands for a contrasting term, referring to general purpose computers only. NAS devices are gaining popularity, offering a convenient method for sharing files between multiple computers.CDRLab Test (in Polish) Potential benefits of network-attached storage, compared to non-dedicated file servers, include faster data access, easier administration, and simple configuration.InfoStor. NAS Advantages: A VARs View, April 01, 1998. By Ron Levine. NAS systems are networked appliances containing one or more hard drives, often arranged into logical, redundant storage containers or RAID arrays. Network Attached Storage removes the responsibility of file serving from other servers on the network. They typically provide access to files using network file sharing protocols such as NFS, SMB/CIFS (Server Message Block/Common Internet File System), or AFP. =Security= File servers generally offer some form of system security to limit access to files to specific users or groups. In large organizations, this is a task usually delegated to directory services, such as openLDAP, Novell's eDirectory or Microsoft's Active Directory. These servers work within the hierarchical computing environment which treat users, computers, applications and files as distinct but related entities on the network and grant access based on user or group credentials. In many cases, the directory service spans many file servers, potentially hundreds for large organizations. In the past, and in smaller organizations, authentication could take place directly at the server itself. See also * Backup * File Transfer Protocol (FTP) * Server Message Block (SMB) * WebDav (WebDav) * Network-attached storage (NAS) * Enterprise content management References Category:Servers (computing) Category:Computer storage devices ","title":"File server"},{"id":"41152","text":"In telecommunication, a filled cable is a cable that has a non-hygroscopic material, usually a gel called icky-pick, inside the jacket or sheath. The nonhygroscopic material fills the spaces between the interior parts of the cable, preventing moisture from entering minor leaks in the sheath and migrating inside the cable. A metallic cable, such as a coaxial cable or a metal waveguide, filled with a dielectric material, is not considered as a filled cable. References Further reading See Telcordia GR-421-CORE, Generic Requirements for Metallic Telecommunications Cables, for filled, polyolefin-insulated conductor (PIC) cable requirements. Category:Signal cables ","title":"Filled cable"},{"id":"41155","text":"A television remote control is an example of an engineered product that contains firmware. The firmware monitors the buttons, controls the LEDs, and processes the button presses to send the data in a format the receiving device, in this case, a television set, can understand and process. In fact, the television's motherboard has complex firmware too. In computing, firmware is a specific class of computer software that provides the low-level control for a device's specific hardware. Firmware can either provide a standardized operating environment for more complex device software (allowing more hardware-independence), or, for less complex devices, act as the device's complete operating system, performing all control, monitoring and data manipulation functions. Typical examples of devices containing firmware are embedded systems, consumer appliances, computers, computer peripherals, and others. Almost all electronic devices beyond the simplest contain some firmware. Firmware is held in non-volatile memory devices such as ROM, EPROM, or EEPROM (including NOR flash memory). Changing the firmware of a device was rarely or never done during its lifetime in the past but is nowadays a common procedure; some firmware memory devices are permanently installed and cannot be changed after manufacture. Common reasons for updating firmware include fixing bugs or adding features to the device. This requires ROM integrated circuits to be physically replaced, or EPROM or flash memory to be reprogrammed through a special procedure. Firmware such as the BIOS of a personal computer may contain only elementary basic functions of a device and may only provide services to higher-level software. Firmware such as the program of an embedded system may be the only program that will run on the system and provide all of its functions. Before the inclusion of integrated circuits, other firmware devices included a discrete semiconductor diode matrix. The Apollo guidance computer had firmware consisting of a specially manufactured core memory plane, called \\"core rope memory\\", where data was stored by physically threading wires through (1) or around (0) the core storing each data bit.  History  Ascher Opler coined the term \\"firmware\\" in a 1967 Datamation article. Originally, it meant the contents of a writable control store (a small specialized high-speed memory), containing microcode that defined and implemented the computer's instruction set, and that could be reloaded to specialize or modify the instructions that the central processing unit (CPU) could execute. As originally used, firmware contrasted with hardware (the CPU itself) and software (normal instructions executing on a CPU). It was not composed of CPU machine instructions, but of lower-level microcode involved in the implementation of machine instructions. It existed on the boundary between hardware and software; thus the name \\"firmware\\". Over time, popular usage extended the word \\"firmware\\" to denote any computer program that is tightly linked to hardware, including processor machine instructions for BIOS, bootstrap loaders, or the control systems for simple electronic devices such as a microwave oven, remote control, or computer peripheral.  Applications  = Personal computers = ROM BIOS firmware on a Baby AT motherboard In some respects, the various firmware components are as important as the operating system in a working computer. However, unlike most modern operating systems, firmware rarely has a well-evolved automatic mechanism of updating itself to fix any functionality issues detected after shipping the unit. The BIOS may be \\"manually\\" updated by a user, using a small utility program. In contrast, firmware in storage devices (harddisks, DVD drives, flash storage) rarely gets updated, even when flash (rather than ROM) storage is used for the firmware; there are no standardized mechanisms for detecting or updating firmware versions. Most computer peripherals are themselves special-purpose computers. Devices such as printers, scanners, cameras, and USB flash drives have internally stored firmware; some devices may also permit field upgrading of their firmware. Some low-cost peripherals no longer contain non-volatile memory for firmware, and instead rely on the host system to transfer the device control program from a disk file or CD. = Consumer products = , most portable music players support firmware upgrades. Some companies use firmware updates to add new playable file formats (codecs). Other features that may change with firmware updates include the GUI or even the battery life. Most mobile phones have a Firmware Over The Air firmware upgrade capability for much the same reasons; some may even be upgraded to enhance reception or sound quality. = Automobiles = Since 1996, most automobiles have employed an on-board computer and various sensors to detect mechanical problems. , modern vehicles also employ computer-controlled anti- lock braking systems (ABS) and computer-operated transmission control units (TCUs). The driver can also get in-dash information while driving in this manner, such as real-time fuel economy and tire pressure readings. Local dealers can update most vehicle firmware.  Examples  Examples of firmware include: * In consumer products: ** Timing and control systems for washing machines ** Controlling sound and video attributes, as well as the channel list, in modern televisions * In computers: ** The BIOS found in older IBM- compatible PCs ** The (U)EFI-compliant firmware used on Itanium systems, Intel-based Macs, and many newer PCs ** Hard drive or Solid state drive firmware ** Video BIOS of a graphics card ** Open Firmware, used in SPARC- based computers from Sun Microsystems and Oracle Corporation, PowerPC-based computers from Apple, and computers from Genesi ** ARCS, used in computers from Silicon Graphics ** Kickstart, used in the Amiga line of computers (POST, hardware init + Plug and Play auto-configuration of peripherals, kernel, etc.) ** RTAS (Run-Time Abstraction Services), used in computers from IBM ** The Common Firmware Environment (CFE) * In routers and firewalls: ** LibreCMC a 100% free software router distribution based on the Linux-libre kernel ** IPFire an open-source firewall/router distribution based on the Linux kernel ** fli4l an open-source firewall/router distribution based on the Linux kernel ** OpenWrt an open-source firewall/router distribution based on the Linux kernel ** m0n0wall an embedded firewall distribution of FreeBSD * In NAS systems: ** NAS4Free an open-source NAS operating system based on FreeBSD 9.1 ** Openfiler an open-source NAS operating system based on the Linux kernel  Flashing  Flashing involves the overwriting of existing firmware or data, contained in EEPROM (such as NOR flash memory) modules present in an electronic device, with new data. This can be done to upgrade a device or to change the provider of a service associated with the function of the device, such as changing from one mobile phone service provider to another or installing a new operating system. If firmware is upgradable, it is often done via a program from the provider, and will often allow the old firmware to be saved before upgrading so it can be reverted to if the process fails, or if the newer version performs worse. As an alternative to vendor tools, open source alternatives have been developed such as flashrom.  Firmware hacking  Sometimes, third parties create an unofficial new or modified (\\"aftermarket\\") version of firmware to provide new features or to unlock hidden functionality; this is referred to as custom firmware. An example is Rockbox as a firmware replacement for portable media players. There are many homebrew projects for various devices, which often unlock general-purpose computing functionality in previously limited devices (e.g., running Doom on iPods). Firmware hacks usually take advantage of the firmware update facility on many devices to install or run themselves. Some, however, must resort to exploits to run, because the manufacturer has attempted to lock the hardware to stop it from running unlicensed code. Most firmware hacks are free software. = HDD firmware hacks = The Moscow-based Kaspersky Lab discovered that a group of developers it refers to as the \\"Equation Group\\" has developed hard disk drive firmware modifications for various drive models, containing a trojan horse that allows data to be stored on the drive in locations that will not be erased even if the drive is formatted or wiped. Although the Kaspersky Lab report did not explicitly claim that this group is part of the United States National Security Agency (NSA), evidence obtained from the code of various Equation Group software suggests that they are part of the NSA. Researchers from the Kaspersky Lab categorized the undertakings by Equation Group as the most advanced hacking operation ever uncovered, also documenting around 500 infections caused by the Equation Group in at least 42 countries.  Security risks  Mark Shuttleworth, the founder of the company Canonical, which maintains the Ubuntu Linux distribution, has described proprietary firmware as a security risk, saying that \\"firmware on your device is the NSA's best friend\\" and calling firmware \\"a trojan horse of monumental proportions\\". He has asserted that low-quality, closed source firmware is a major threat to system security:Linux Magazine issue 162, May 2014, page 9 \\"Your biggest mistake is to assume that the NSA is the only institution abusing this position of trust in fact, it's reasonable to assume that all firmware is a cesspool of insecurity, courtesy of incompetence of the highest degree from manufacturers, and competence of the highest degree from a very wide range of such agencies\\". As a potential solution to this problem, he has called for declarative firmware, which would describe \\"hardware linkage and dependencies\\" and \\"should not include executable code\\". Firmware should be open-source so that the code can be checked and verified. Custom firmware hacks have also focused on injecting malware into devices such as smartphones or USB devices. One such smartphone injection was demonstrated on the Symbian OS at MalCon, a hacker convention. A USB device firmware hack called BadUSB was presented at the Black Hat USA 2014 conference, demonstrating how a USB flash drive microcontroller can be reprogrammed to spoof various other device types to take control of a computer, exfiltrate data, or spy on the user. Other security researchers have worked further on how to exploit the principles behind BadUSB, releasing at the same time the source code of hacking tools that can be used to modify the behavior of different USB devices.  See also  * Computer hardware * Computer program * Software * Custom firmware * Binary blob * Bootloader * Coreboot * Microcode * ROM image  Notes   References   External links  * Linux Vendor Firmware Service, a secure portal which allows hardware vendors to upload firmware updates * , by Karsten Nohl and Jakob Lell * Phison 2251-03 (2303) Custom Firmware & Existing Firmware Patches (BadUSB) Category:Embedded systems ","title":"Firmware"},{"id":"41156","text":"Fixed access: In personal communications service (PCS), terminal access to a network in which there is a set relationship between a terminal and the access interface. A single \\"identifier\\" serves for both the access interface and the terminal. If the terminal moves to another access interface, that terminal assumes the identity of the new interface. References Category:Network access ","title":"Fixed access"},{"id":"41157","text":"Flag sequence: In data transmission or processing, a sequence of bits used to delimit, i.e. mark the beginning and end of a frame. Note 1: An 8-bit sequence is usually used as the flag sequence; for example, the 8-bit flag sequence 01111110. Note 2: Flag sequences are used in bit-oriented protocols, such as Advanced Data Communication Control Procedures (ADCCP), Synchronous Data Link Control (SDLC), and High-Level Data Link Control (HDLC). References Category:Data transmission ","title":"Flag sequence"},{"id":"41158","text":"In a noise-measuring set, flat weighting is a noise weighting based on an amplitude-frequency characteristic that is flat over a frequency range that must be stated. Notes * Note 1: Flat noise power is expressed in dBrn (f1 ‚àí f2) or in dBm (f1 ‚àí f2). * Note 2: \\"3 kHz flat weighting\\" and \\"15 kHz flat weighting\\" are based on amplitude-frequency characteristics that are flat between 30 Hz and the frequency indicated. References Sources Category:Noise ","title":"Flat weighting"},{"id":"41159","text":"In a telephone network, flood search routing is non-deterministic routing in which a dialed number received at a switch is transmitted to all switches, i.e., flooded, in the area code directly connected to that switch; if the dialed number is not an affiliated subscriber at that switch, the number is then retransmitted to all directly connected switches, and then routed through the switch that has the dialed number corresponding to the particular user end instrument affiliated with it.\\"Federal Standard 1037C\\", United States General Services Administration (1996) All digits of the numbering plan are used to identify a particular subscriber. Flood search routing allows subscribers to have telephone numbers independent of switch codes. Flood search routing provides the highest probability that a telephone call will go through even though a number of switches and links fail. Flood search routing is used in military telecommunication systems, such as the mobile subscriber equipment (MSE) system. See also *Flooding (computer networking) References Category:Telephone exchanges Category:Telecommunications techniques Category:Routing algorithms ","title":"Flood search routing"},{"id":"41160","text":"In electronics and communication, flutter is the rapid variation of signal parameters, such as amplitude, phase, and frequency. Examples of electronic flutter are: *Rapid variations in received signal levels, such as variations that may be caused by atmospheric disturbances, antenna movements in a high wind, or interaction with other signals. *In radio propagation, a phenomenon in which nearly all radio signals that are usually reflected by ionospheric layers in or above the E-region experience partial or complete absorption. *In radio transmission, rapidly changing signal levels, together with variable multipath time delays, caused by reflection and possible partial absorption of the signal by aircraft flying through the radio beam or common scatter volume. *The variation in the transmission characteristics of a loaded telephone line caused by the action of telegraph direct currents on the loading coils. *In recording and reproducing equipment, the deviation of frequency caused by irregular mechanical motion, e.g., that of capstan angular velocity in a tape transport mechanism, during operation. See also Electronic Flutter * Wow (recording) * Wow and flutter measurement References Category:Radio frequency propagation ","title":"Flutter (electronics and communication)"},{"id":"41161","text":"The flywheel effect is the continuation of oscillations in an oscillator circuit after the control stimulus has been removed. This is usually caused by interacting inductive and capacitive elements in the oscillator. Circuits undergoing such oscillations are said to be flywheeling. The flywheel effect may be desirable, such as in phase-locked loops used in synchronous systems, or undesirable, such as in voltage-controlled oscillators. Flywheel effect is used in Class C modulation where efficiency of modulation can be achieved as high as 90%. See also *Thermal flywheel effect References Category:Electronic oscillators ","title":"Flywheel effect"},{"id":"41164","text":"Foreign exchange service may refer to: *Foreign exchange service (finance) *Foreign exchange service (telecommunications) ","title":"Foreign exchange service"},{"id":"41165","text":"Foreign instrumentation signals intelligence, FISINT (Foreign Instrumentation Signals INTelligence) is intelligence from the interception of foreign electromagnetic emissions associated with the testing and operational deployment of foreign aerospace, surface, and subsurface systems.NSA-faq Since it deals with signals that have communicational content, it is a subset of Communications Intelligence (COMINT), which, in turn, is a subset of SIGINT. Unlike general COMINT signals, the content of FISINT signals is not in regular human language, but rather in machine to machine (instrumentation) language or in a combination of regular human language and instrumentation language. FISINT is also considered as a subset of MASINT (measurement and signature intelligence). Typical examples of such communication include: *Telemetry data (TELINT). Missiles, satellites and other remotely monitored devices often transmit streams of data concerning their location, speed, engine status and other metrics. *Video data links. These may be from UAVs or from satellites used for reconnaissance. *Remote access and control transmissions, such as from remote keyless systems and wireless traffic light control systems. *Command signals used in teleoperation, such as the control of aerial vehicles, missiles and remotely-controlled robots. Telecommunication In telecommunication, the term FISINT has the following meanings: 1\\\\. Intelligence information derived from electromagnetic emissions associated with the testing and operational deployment of foreign aerospace, surface, and subsurface systems. 2\\\\. Technical information and intelligence information derived from the intercept of foreign instrumentation signals by other than the intended recipients. Foreign instrumentation signals intelligence is a category of signals intelligence. Foreign instrumentation signals include but are not limited to signals from telemetry, beaconry, electronic interrogators, tracking/fusing/arming/firing command systems, and video data links. See also *SIGINT: Signals intelligence **COMINT: Communications intelligence **ELINT: Electronic intelligence *HUMINT: Human intelligence *IMINT: Imagery intelligence *MASINT: Measurement and signature intelligence *Missile guidance *Intelligence collection management References * * Category:Intelligence gathering disciplines Category:Signals intelligence Category:Applications of cryptography ","title":"Foreign instrumentation signals intelligence"},{"id":"41166","text":"Forward echo: In a transmission line, a reflection propagating in the same direction as the original wave and consisting of energy reflected back by one discontinuity and then forward again by another discontinuity. Forward echoes can be supported by reflections caused by splices or other discontinuities in the transmission medium (e.g. optical fiber, twisted pair, or coaxial tube). In metallic lines, they may be supported by impedance mismatches between the source or load and the characteristic impedance of the transmission medium. They may cause attenuation distortion. See also * Pre-echo References Category:Telecommunications engineering Category:Telephony ","title":"Forward echo"},{"id":"41168","text":"Saturn eclipses the Sun, as seen from the Cassini space probe. The forward scattering of light makes the faint outer rings more visible. In physics, telecommunications, and astronomy, forward scatter is the deflection‚Äîby diffraction, nonhomogeneous refraction, or nonspecular reflection by particulate matter of dimensions that are large with respect to the wavelength in question but small with respect to the beam diameter‚Äîof a portion of an incident electromagnetic wave, in such a manner that the energy so deflected propagates in a direction that is within 90¬∞ of the direction of propagation of the incident wave (i.e., a phase angle greater than 90¬∞). The scattering process may be sensitive to polarization; that is, the polarization of incident waves that are identical in every respect may be scattered differently. Forward scatter differs from backscatter.  Comets  Forward scattering can make a back-lit comet appear significantly brighter because the dust and ice crystals are reflecting and enhancing the apparent brightness of the comet by scattering that light towards the observer. Comets studied forward-scattering in visible-thermal photometry include C/1927 X1 (Skjellerup‚ÄìMaristany), C/1975 V1 (West), and C/1980 Y1 (Bradfield). Comets studied forward-scattering in SOHO non-thermal C3 coronograph photometry include 96P/Machholz and C/2004 F4 (Bradfield). The brightness of the great comets C/2006 P1 (McNaught) and Comet Skjellerup‚ÄìMaristany near perihelion were enhanced by forward scattering. References  External links  *Cassini's Views of Saturn's Rings *Light Scattering Demonstration Category:Radio frequency propagation Category:Scattering, absorption and radiative transfer (optics) ","title":"Forward scatter"},{"id":"41169","text":"Frequency of optimum transmission (FOT), in the transmission of radio waves via ionospheric reflection, is the highest effective (i.e. working) frequency that is predicted to be usable for a specified path and time for 90% of the days of the month. The FOT is normally just below the value of the maximum usable frequency (MUF). In the prediction of usable frequencies, the FOT is commonly taken as 15% below the monthly median value of the MUF for the specified time and path. The FOT is usually the most effective frequency for ionospheric reflection of radio waves between two specified points on Earth. Synonyms for this term include: *frequency of optimum traffic *optimum traffic frequency *optimum transmission frequency *optimum working frequency See also *Lowest usable high frequency  Sources  *Federal Standard 1037C *MIL-STD-188 Category:Radio frequency propagation ","title":"Frequency of optimum transmission"},{"id":"41170","text":"In telecommunication, a four-wire circuit is a two-way circuit using two paths so arranged that the respective signals are transmitted in one direction only by one path and in the other direction by the other path. The four-wire circuit gets its name from the fact that is uses four conductors to create two complete electrical circuits, one for each direction. The two separate circuits (channels) allow full-duplex operation with low crosstalk. In telephony a four-wire circuit was historically used to transport and switch baseband audio signals in the phone company telephone exchange before the advent of digital modulation and the electronic switching system eliminated baseband audio from the telco plant except for the local loop. The local loop is a two-wire circuit for one reason only: to save copper. Using half the number of copper wire conductors per circuit means that the infrastructure cost for wiring each circuit is halved. Although a lower quality circuit, the local loop allows full duplex operation by using a telephone hybrid to keep near and far voice levels equivalent. As the public switched telephone network expanded in size and scope, using many individual wires inside the telco plant became so impractical and labor-intensive that in-office and inter-office signal wiring progressed to high bandwidth coaxial cable (still a popular interconnection method in the 21st century, used with the Lucent 5ESS Class-5 telephone switch to present day), microwave radio relay and ultimately fiber- optic communication for high speed trunk circuits. As the use of the personal computer increased at the end of the 20th century, four-wire circuits saw renewed growth for corporate local loop service for use in dedicated line service for computer modems to interconnect connect company computer networks and to connect networks to an Internet service provider for Internet connectivity before commodity DSL and cable modem connectivity was widely available. References * A History of engineering and science in the Bell System : transmission technology (1925-1975) Category:Communication circuits Category:Telephony ","title":"Four-wire circuit"},{"id":"41171","text":"A four-wire terminating set (4WTS) is a balanced transformer used to perform a conversion between four-wire and two-wire operation in telecommunication systems. For example, a 4-wire circuit may, by means of a 4-wire terminating set, be connected to a 2-wire telephone set. Also, a pair of 4-wire terminating sets may be used to introduce an intermediate 4-wire circuit into a 2-wire circuit, in which loop repeaters may be situated to amplify signals in each direction without positive feedback and oscillation. The 4WTS differs from a simple hybrid coil in being equipped to adjust its impedance to maximize return loss. Four-wire terminating sets were largely supplanted by resistance hybrids in the late 20th century. References Category:Telephony equipment ","title":"Four-wire terminating set"},{"id":"41172","text":"A frame is a digital data transmission unit in computer networking and telecommunication. In packet switched systems, a frame is a simple container for a single network packet. In other telecommunications systems, a frame is a repeating structure supporting time-division multiplexing. A frame typically includes frame synchronization features consisting of a sequence of bits or symbols that indicate to the receiver the beginning and end of the payload data within the stream of symbols or bits it receives. If a receiver is connected to the system during frame transmission, it ignores the data until it detects a new frame synchronization sequence. Packet switching In the OSI model of computer networking, a frame is the protocol data unit at the data link layer. Frames are the result of the final layer of encapsulation before the data is transmitted over the physical layer. A frame is \\"the unit of transmission in a link layer protocol, and consists of a link layer header followed by a packet.\\" Each frame is separated from the next by an interframe gap. A frame is a series of bits generally composed of frame synchronization bits, the packet payload, and a frame check sequence. Examples are Ethernet frames, Point-to-Point Protocol (PPP) frames, Fibre Channel frames, and V.42 modem frames. Often, frames of several different sizes are nested inside each other. For example, when using Point-to-Point Protocol (PPP) over asynchronous serial communication, the eight bits of each individual byte are framed by start and stop bits, David S.Lawyer and Greg Hankins. \\"Serial HOWTO\\". Section \\"20.4 Forming a Byte (Framing)\\". 2011\\\\. quote: \\"... a start bit and a stop bit to mark the beginning and end of a byte. This is called framing ... Don't confuse this type of framing with the framing used for a packet of bytes on a network.\\" MATLAB External Interfaces. Section \\"Serial Data Format\\". quote: \\"... one start bit... parity bit ... stop bit[s] ... called framing bits because they frame the data bits.\\" the payload data bytes in a network packet are framed by the header and footer, and several packets can be framed with frame boundary octets. RFC 1661 \\"The Point-to-Point Protocol (PPP)\\" quote: \\"A packet is usually mapped to a frame; the exceptions are when data link layer fragmentation is being performed, or when multiple packets are incorporated into a single frame.\\" Time-division multiplex In telecommunications, specifically in time-division multiplex (TDM) and time-division multiple access (TDMA) variants, a frame is a cyclically repeated data block that consists of a fixed number of time slots, one for each logical TDM channel or TDMA transmitter. In this context, a frame is typically an entity at the physical layer. TDM application examples are SONET/SDH and the ISDN circuit- switched B-channel, while TDMA examples are Circuit Switched Data used in early cellular voice services. The frame is also an entity for time-division duplex, where the mobile terminal may transmit during some time slots and receive during others.  See also  * Datagram * Jumbo frame * Multiplex techniques * Overhead bit  References  Category:Computer networks Category:Link protocols Category:Packets (information technology) Category:Units of information it:Ethernet#Frame ","title":"Frame (networking)"},{"id":"41173","text":"Frame rate (expressed in ' or FPS) is the frequency (rate) at which consecutive images called frames appear on a display. The term applies equally to film and video cameras, computer graphics, and motion capture systems. Frame rate may also be called the ', and be expressed in hertz. Human vision The temporal sensitivity and resolution of human vision varies depending on the type and characteristics of visual stimulus, and it differs between individuals. The human visual system can process 10 to 12 images per second and perceive them individually, while higher rates are perceived as motion. Modulated light (such as a computer display) is perceived as stable by the majority of participants in studies when the rate is higher than 50 Hz. This perception of modulated light as steady is known as the flicker fusion threshold. However, when the modulated light is non-uniform and contains an image, the flicker fusion threshold can be much higher, in the hundreds of hertz. With regard to image recognition, people have been found to recognize a specific image in an unbroken series of different images, each of which lasts as little as 13 milliseconds. Persistence of vision sometimes accounts for very short single-millisecond visual stimulus having a perceived duration of between 100 ms and 400 ms. Multiple stimuli that are very short are sometimes perceived as a single stimulus, such as a 10 ms green flash of light immediately followed by a 10 ms red flash of light perceived as a single yellow flash of light. Film and video =Silent films= Early silent films had stated frame rates anywhere from 16 to 24 frames per second (fps), but since the cameras were hand-cranked, the rate often changed during the scene to fit the mood. Projectionists could also change the frame rate in the theater by adjusting a rheostat controlling the voltage powering the film- carrying mechanism in the projector. Film companies often intended that theaters show their silent films at higher frame rates than they were filmed at. These frame rates were enough for the sense of motion, but it was perceived as jerky motion. To minimize the perceived flicker, projectors employed dual- and triple-blade shutters, so each frame was displayed two or three times, increasing the flicker rate to 48 or 72 hertz and reducing eye strain. Thomas Edison said that 46 frames per second was the minimum needed for the eye to perceive motion: \\"Anything less will strain the eye.\\" In the mid to late 1920s, the frame rate for silent films increased to between 20 and 26 FPS. =Sound films= When sound film was introduced in 1926, variations in film speed were no longer tolerated, as the human ear is more sensitive than the eye to changes in frequency. Many theaters had shown silent films at 22 to 26 FPS, which is why the industry chose 24 FPS for sound films as a compromise. From 1927 to 1930, as various studios updated equipment, the rate of 24 FPS became standard for 35 mm sound film. At 24 FPS, the film travels through the projector at a rate of per second. This allowed simple two-blade shutters to give a projected series of images at 48 per second, satisfying Edison's recommendation. Many modern 35 mm film projectors use three-blade shutters to give 72 images per second‚Äîeach frame is flashed on screen three times. =Animation= This animated cartoon of a galloping horse is displayed at 12 drawings per second, and the fast motion is on the edge of being objectionably jerky. In drawn animation, moving characters are often shot \\"on twos\\", that is to say, one drawing is shown for every two frames of film (which usually runs at 24 frames per second), meaning there are only 12 drawings per second. Even though the image update rate is low, the fluidity is satisfactory for most subjects. However, when a character is required to perform a quick movement, it is usually necessary to revert to animating \\"on ones\\", as \\"twos\\" are too slow to convey the motion adequately. A blend of the two techniques keeps the eye fooled without unnecessary production cost. Animation for most \\"Saturday morning cartoons\\" was produced as cheaply as possible and was most often shot on \\"threes\\" or even \\"fours\\", i.e. three or four frames per drawing. This translates to only 8 or 6 drawings per second respectively. Anime is also usually drawn on threes. =Modern video standards= Due to the mains frequency of electric grids, analog television broadcast was developed with frame rates of 50 Hz (most of the world) or 60 Hz (Canada, US, Japan, South Korea). Hydroelectric generators, due to their massive size, developed enough to make the power mains frequency extremely stable, so circuits were developed for television cameras to lock onto that frequency as their primary reference. The introduction of color television technology made it necessary to lower that 60 FPS frequency by 0.1% to avoid \\"dot crawl\\", an annoying display artifact appearing on legacy black-and-white displays, showing up on highly-color-saturated surfaces. It was found that by lowering the frame rate by 0.1%, the undesirable effect was minimized. Today, video transmission standards in North America, Japan, and South Korea are still based on 60 / 1.001 ‚âà 59.94 images per second. Two sizes of images are typically used: 1920√ó1080 (\\"1080i\\") and 1280√ó720 (\\"720p\\"). Confusingly, interlaced formats are customarily stated at 1/2 their image rate, 29.97 FPS, and double their image height, but these statements are purely custom; in each format, 60 images per second are produced. 1080i produces 59.94 1920√ó540 images, each squashed to half-height in the photographic process and stretched back to fill the screen on playback in a television set. The 720p format produces 59.94 1280√ó720 images, not squeezed, so that no expansion or squeezing of the image is necessary. This confusion was industry-wide in the early days of digital video software, with much software being written incorrectly, the coders believing that only 29.97 images were expected each second, which was incorrect. While it was true that each picture element was polled and sent only 29.97 times per second, the pixel location immediately below that one was polled 1/60 of a second later, part of a completely separate image for the next 1/60-second frame. Film, at its native 24 FPS rate could not be displayed without the necessary pulldown process, often leading to \\"judder\\": To convert 24 frames per second into 60 frames per second, every odd frame is repeated, playing twice, while every even frame is tripled. This creates uneven motion, appearing stroboscopic. Other conversions have similar uneven frame doubling. Newer video standards support 120, 240, or 300 frames per second, so frames can be evenly multiplied for common frame rates such as 24 FPS film and 30 FPS video, as well as 25 and 50 FPS video in the case of 300 FPS displays. These standards also support video that is natively in higher frame rates and video with interpolated frames between its native frames.High Frame-Rate Television, BBC White Paper WHP 169, September 2008, M. Armstrong, D. Flynn, M. Hammond, PAWAN Jahajpuria S. Jolly, R. Salmon. Some modern films are experimenting with frame rates higher than 24 FPS, such as 48 and 60 FPS. Frame rate in electronic camera specifications may refer to the maximal possible rate, where, in practice, other settings (such as exposure time) may reduce the frequency to a lower number.  See also  *Delta timing *Federal Standard 1037C *Film-out *Flicker fusion threshold *Glossary of video terms *High frame rate *List of film formats *MIL-STD-188 *Movie projector *Moving image formats *Time-lapse photography *Video compression References  External links  *\\"Temporal Rate Conversion\\"‚Äîa very detailed guide about the visual interference of TV, video & PC (Wayback Machine copy) * Compare frames per second: which looks better?‚Äîa web tool to visually compare differences in frame rate and motion blur. Category:Film and video technology Category:Temporal rates ","title":"Frame rate"},{"id":"41174","text":"Vellum manuscript of the Constitution of Vermont, 1777. This constitution was amended in 1786, and replaced in 1793 following Vermont's admission to the federal union in 1791. Marble tablet with a passage from the Constitution of Vermont in the Hall of Inscriptions at the Vermont State House. The Constitution of the State of Vermont is the fundamental body of law of the U.S. state of Vermont, describing and framing its government. It was adopted in 1793 following Vermont's admission to the Union in 1791 and is largely based upon the 1777 Constitution of the Vermont Republic which was drafted at Windsor in the Old Constitution House and amended in 1786. At 8,295 words, it is the shortest U.S. state constitution.\\"State constitutional reform: Is it necessary?\\" Hammonds, C.W. (2001). History = 1777 = From 1777 to 1791, Vermont was an independent country, often referred to in the present day as the Vermont Republic. During that time it was usually called the State of Vermont but sometimes called the Commonwealth of Vermont or the Republic of Vermont. Its first constitution, drafted in 1777, was among the most far- reaching in guaranteeing personal freedoms and individual rights. In particular, it banned adult slavery, saying male slaves become free at the age of 21 and females at 18. The 1777 constitution's Declaration of Rights of the Inhabitants of the State of Vermont anticipated the United States Bill of Rights by a dozen years. The first chapter, a \\"Declaration of Rights of the Inhabitants of the State of Vermont\\", is followed by a \\"Plan or Frame of Government\\" outlining the structure of governance. It provided that the governor would be elected by the freemen of the state, who could vote regardless of whether they owned property, that each town would be represented in the legislative assembly, that there would be a court of law in each county, and that the legislative assembly and the governor's council would jointly hold legislative power. = 1786 = In 1786, the Constitution was extensively revised to establish a far greater separation of powers than what had prevailed under the 1777 Constitution. In particular, it forbade anyone to simultaneously hold more than one of certain offices, including those of judges, legislators, members of the governor's council, the governor, and the surveyor-general. It also provided that the legislature could no longer function as a court of appeals nor otherwise intervene in cases before the courts, as it had often done. The 1786 Constitution continued in effect when, in 1791, Vermont made the transition from independence to the status of one of the states of the Union. In particular, the governor, the members of the governor's council, and other officers of the state, including judges in all courts, simply continued their terms of office that were already underway. = 1793 = The 1793 Constitution was adopted two years after Vermont's admission to the Union and continues in effect, with various later amendments, to this day. It eliminated all mention of grievances against King George III and against the State of New York. In 1790, New York's legislature finally renounced its claims that Vermont was a part of New York, the cessation of those claims being effective if and when Congress decided to admit Vermont to the Union. Council of Censors \\"In order that the freedom of this Commonwealth may be preserved inviolate\\" the 1777 constitution established a Council of Censors. This body consisted of thirteen elected members, chosen every seven years, but not from the Council or General Assembly. They were to check that \\"the legislative and executive branches of government have performed their duty as guardians of the people\\". They also had the power to call a convention, if needed, to amend the constitution. This council had been based on a similar element of the Pennsylvania Constitution of 1776. In 1786, the constitution was amended with language proposed by the 1785 Council of Censors, their first meeting, and adopted by the 1786 Constitutional Convention. The section on the Council of Censors remained generally unchanged, with only an added clarification of scope. In 1793, the constitution was amended with language proposed by the 1792 Council of Censors and adopted by the 1793 Constitutional Convention. The Council now had the \\"power to send for persons, papers, and records\\". In 1870, the constitution was amended with language proposed by the 1869 Council of Censors, their last meeting, and adopted by the 1870 Constitutional Convention. The Council of Censors was abolished and replaced by a new procedure to amend the constitution. Amending the constitution The Vermont Constitution, Chapter 2, Section 72 establishes the procedure for amending the constitution. The Vermont General Assembly, the state's bi-cameral legislature, has the sole power to propose amendments to the Constitution of Vermont. The process must be initiated by a Senate that has been elected in an \\"off-year\\", that is, an election that does not coincide with the election of the U.S. president. An amendment must originate in the Senate and be approved by a two-thirds vote. It must then receive a majority vote in the House. Then, after a newly elected legislature is seated, the amendment must receive a majority vote in each chamber, first in the Senate, then in the House. The proposed amendment must then be presented to the voters as a referendum and receive a majority of the votes cast. 1990s revision to gender-neutral language In 1991 and again in 1993, the Vermont General Assembly approved a constitutional amendment authorizing the justices of the Vermont Supreme Court to revise the Constitution in \\"gender-inclusive\\" language, replacing gender-specific terms. (Examples: \\"men\\" and \\"women\\" were replaced by \\"persons\\" and the \\"Freeman's Oath,\\" required of all newly registered voters in the state, was renamed the \\"Voters' Oath\\"). The revision was ratified by the voters in the general election of November 8, 1994. Vermont is one of six states whose constitutions are written in gender-neutral language. Vermont State Archives: 1991: Proposal 11 Subject: Gender inclusive language References External links * Full text of the Constitution of Vermont * The Vermont State Archives text of the Vermont Republic Constitution, 1777 * The Vermont State Archives text of the 1786 Constitution * The Vermont State Archives text of the 1793 Constitution * Visit the birthplace of Vermont and its Constitution * See the original Constitution manuscript Category:1793 in law Vermont State Constitution Category:Vermont law Category:1793 in American politics Category:1793 in Vermont ","title":"Constitution of Vermont"},{"id":"41175","text":"In the reception of framed data, a frame slip is the loss of synchronization between a received frame and the receiver clock signal, causing a frame misalignment event, and resulting in the loss of the data contained in the received frame. A frame slip should not be confused with a dropped frame where synchronization is not lost, as in the case of buffer overflow, for example. References * Category:Synchronization Category:Data transmission ","title":"Frame slip"},{"id":"41176","text":"In telecommunication, frame synchronization or framing is the process by which, while receiving a stream of framed data, incoming frame alignment signals (i.e., a distinctive bit sequences or syncwords) are identified (that is, distinguished from data bits), permitting the data bits within the frame to be extracted for decoding or retransmission.  Framing  If the transmission is temporarily interrupted, or a bit slip event occurs, the receiver must re-synchronize. Frame synchronized PCM stream ‚Äî telemetry application The transmitter and the receiver must agree ahead of time on which frame synchronization scheme they will use. Common frame synchronization schemes are: ;Framing bit: A common practice in telecommunications, for example in T-carrier, is to insert, in a dedicated time slot within the frame, a noninformation bit or framing bit that is used for synchronization of the incoming data with the receiver. In a bit stream, framing bits indicate the beginning or end of a frame. They occur at specified positions in the frame, do not carry information, and are usually repetitive. ;Syncword framing: Some systems use a special syncword at the beginning of every frame. ;CRC-based framing: Some telecommunications hardware uses CRC-based framing. Frame synchronizer PCM stream prior to frame synchronization In telemetry applications, a frame synchronizer is used to frame-align a serial pulse code- modulated (PCM) binary stream. Different types of commutation within a frame synchronized PCM stream The frame synchronizer immediately follows the bit synchronizer in most telemetry applications. Without frame synchronization, decommutation is impossible. Frame-synchronized PCM stream The frame synchronization pattern is a known binary pattern which repeats at a regular interval within the PCM stream. The frame synchronizer recognizes this pattern and aligns the data into minor frames or sub-frames. Typically the frame sync pattern is followed by a counter (sub-frame ID) which dictates which minor or sub-frame in the series is being transmitted. This becomes increasingly important in the decommutation stage where all data is deciphered as to what attribute was sampled. Different commutations require a constant awareness of which section of the major frame is being decoded. See also * Asynchronous start-stop * Phase synchronization * Self-synchronizing code * Superframe References =Scientific articles= * J. L. Massey. \\"Optimum frame synchronization \\". IEEE trans. comm., com-20(2):115-119, April 1972. * R Scholtz. \\"Frame synchronization techniques\\", IEEE Transactions on Communications, 1980. * P. Robertson. \\"Optimal Frame Synchronization for Continuous and Packet Data Transmission\\", PhD Dissertation, 1995, Fortschrittberichte VDI Reihe 10, Nr. 376 PDF Category:Data transmission Category:Synchronization ","title":"Frame synchronization"},{"id":"41177","text":"Framing may refer to: * Framing (construction), common carpentry work * Framing (law), providing false evidence or testimony to prove someone guilty of a crime * Framing (social sciences) * Framing (visual arts), a technique used to bring the focus to the subject * Framing (World Wide Web), a technique using multiple panes within a web page * Timber framing, a traditional method of building with heavy timbers See also * Frame synchronization, in telecommunications * Frame of reference, a coordinate system * Frame (disambiguation) * Framed (disambiguation) * Framing device, a narrative tool * Framework (disambiguation) * Inertial frame of reference, describes time and space homogeneously, isotropically, independent of time * Picture frame ","title":"Framing"},{"id":"41179","text":"In telecommunication, the free-space path loss (FSPL) is the attenuation of radio energy between the feedpoints of two antennas that results from the combination of the receiving antenna's capture area plus the obstacle-free, line-of-sight path through free space (usually air). The \\"Standard Definitions of Terms for Antennas\\", IEEE Std 145-1993, defines \\"free-space loss\\" as \\"The loss between two isotropic radiators in free space, expressed as a power ratio.\\" It does not include any power loss in the antennas themselves due to imperfections such as resistance. Free space loss increases with the square of distance between the antennas because the radio waves spread out by the inverse square law and decreases with the square of the wavelength of the radio waves. The FSPL is rarely used standalone, but rather as a part of the Friis transmission formula, which includes the gain of antennas. It is a factor that must be included in the power link budget of a radio communication system, to ensure that sufficient radio power reaches the receiver such that the transmitted signal is received intelligibly.  Free-space path loss formula  The free-space path loss (FSPL) formula derives from the Friis transmission formula. This states that in a radio system consisting of a transmitting antenna transmitting radio waves to a receiving antenna, the ratio of radio wave power received P_r to the power transmitted P_t is: :\\\\frac{P_r}{P_t} = D_t D_r \\\\left( \\\\frac{\\\\lambda}{4 \\\\pi d} \\\\right)^2 where *\\\\ D_t is the directivity of the transmitting antenna *\\\\ D_r is the directivity of the receiving antenna *\\\\ \\\\lambda is the signal wavelength, *\\\\ d is the distance between the antennas, The distance between the antennas d must be large enough that the antennas are in the far field of each other \\\\ d\\\\gg\\\\lambda. The free-space path loss is the loss factor in this equation that is due to distance and wavelength, or in other words the ratio of power transmitted to power received assuming the antennas are isotropic and have no directivity (D_t = D_r = 1) \\\\begin{align} \\\\mbox{FSPL} = \\\\left ( \\\\frac{4\\\\pi d} \\\\lambda \\\\right )^2 \\\\end{align} Since the frequency of a radio wave f is equal to the speed of light c divided by the wavelength, the path loss can also be written in terms of frequency \\\\begin{align} \\\\mbox{FSPL} = \\\\left({4\\\\pi df \\\\over c}\\\\right)^2 \\\\end{align} Beside the assumption that the antennas are lossless, this formula assumes that the polarization of the antennas is the same, that there are no multipath effects, and that the radio wave path is sufficiently far away from obstructions that it acts as if it is in free space. This last restriction requires an ellipsoidal area around the line of sight out to 0.6 of the Fresnel zone be clear of obstructions. The Fresnel zone increases in diameter with the wavelength of the radio waves. Often the concept of free space path loss is applied to radio systems that don't completely meet these requirements, but these imperfections can be accounted for by small constant power loss factors that can be included in the link budget. Influence of distance and frequency In free space the intensity of electromagnetic radiation decreases with distance by the inverse square law, because the same amount of power spreads over an area proportional to the square of distance from the source. The free-space loss increases with the distance between the antennas and decreases with the wavelength of the radio waves due to these factors, Section 1.8 *Intensity (I) ‚Äì the power density of the radio waves decreases with the square of distance from the transmitting antenna due to spreading of the electromagnetic energy in space according to the inverse square law *Antenna capture area (A_\\\\text{eff}) ‚Äì the amount of power the receiving antenna captures from the radiation field is proportional to a factor called the antenna aperture or antenna capture area, which increases with the square of wavelength. Since this factor is not related to the radio wave path but comes from the receiving antenna, the term \\"free-space path loss\\" is a little misleading. Derivation The radio waves from the transmitting antenna spread out in a spherical wavefront. The amount of power passing through any sphere centered on the transmitting antenna is equal. The surface area of a sphere of radius d is 4\\\\pi d^2. Thus the intensity or power density of the radiation in any particular direction from the antenna is inversely proportional to the square of distance :I \\\\propto {P_t \\\\over 4\\\\pi d^2} For an isotropic antenna which radiates equal power in all directions, the power density is evenly distributed over the surface of a sphere centered on the antenna :I = {P_t \\\\over 4\\\\pi d^2} \\\\qquad \\\\qquad \\\\qquad \\\\text{(1)} The amount of power the receiving antenna receives from this radiation field is :P_r = A_\\\\text{eff}I \\\\qquad \\\\qquad \\\\qquad \\\\text{(2)} The factor A_\\\\text{eff}, called the effective area or aperture of the receiving antenna, which has the units of area, can be thought of as the amount of area perpendicular to the direction of the radio waves from which the receiving antenna captures energy. Since the linear dimensions of an antenna scale with the wavelength \\\\lambda, the cross sectional area of an antenna and thus the aperture scales with the square of wavelength \\\\lambda^2. The effective area of an isotropic antenna (for a derivation of this see antenna aperture article) is :A_\\\\text{eff} = {\\\\lambda^2 \\\\over 4\\\\pi} Combining the above (1) and (2), for isotropic antennas :P_r = \\\\Big({P_t \\\\over 4\\\\pi d^2}\\\\Big)\\\\Big({\\\\lambda^2 \\\\over 4\\\\pi}\\\\Big) :\\\\text{FSPL} = {P_t \\\\over P_r} = \\\\Big({4\\\\pi d \\\\over \\\\lambda}\\\\Big)^2  Free- space path loss in decibels  A convenient way to express FSPL is in terms of decibels (dB) : \\\\begin{align} \\\\operatorname{FSPL}(\\\\text{dB}) &= 10\\\\log_{10}\\\\left(\\\\left(\\\\frac{4\\\\pi d f}{c}\\\\right)^2\\\\right)  &= 20\\\\log_{10}\\\\left(\\\\frac{4\\\\pi d f}{c}\\\\right)  &= 20\\\\log_{10}(d) + 20\\\\log_{10}(f) + 20\\\\log_{10}\\\\left(\\\\frac{4\\\\pi}{c}\\\\right)  &= 20\\\\log_{10}(d) + 20\\\\log_{10}(f) - 147.55, \\\\end{align} where the units are as before. For typical radio applications, it is common to find \\\\ f measured in units of GHz and \\\\ d in km, in which case the FSPL equation becomes :\\\\operatorname{FSPL}(\\\\text{dB}) = 20\\\\log_{10}(d) + 20\\\\log_{10}(f) + 92.45 For \\\\ d,f in meters and kilohertz, respectively, the constant becomes {-87.55}. For \\\\ d,f in meters and megahertz, respectively, the constant becomes {-27.55}. For \\\\ d,f in kilometers and megahertz, respectively, the constant becomes 32.44. See also *Computation of radiowave attenuation in the atmosphere *Friis transmission equation *Radio propagation model *ITU-R P.525 *Link budget *Two-ray ground reflection model References Further reading *C.A. Balanis, \\"Antenna Theory\\", 2003, John Wiley and Sons Inc. *Derivation of the dB version of the Path Loss Equation *Path loss Pages for free space and real world ‚Äì includes free space loss calculator Category:Telecommunications engineering Category:Radio frequency propagation ","title":"Free-space path loss"},{"id":"41180","text":"Freeze frame television is television in which the frames of the video are transmitted as a sequence of still images at a rate far too slow to be perceived as continuous motion by human vision. The receiving device typically displays each frame until the next complete frame is available. For an image of specified quality, e.g., resolution and color fidelity, freeze-frame television has a lower bandwidth requirement than that of full-motion television. For this reason, NASA, which refers to this technique as sequential still video, uses it on UHF when Ku band full-motion video signals are not available. See also *Slow-scan television References Category:Film and video technology ","title":"Freeze frame television"},{"id":"41181","text":"The F region of the ionosphere is home to the F layer of ionization, also called the Appleton‚ÄìBarnett layer, after the English physicist Edward Appleton and New Zealand physicist and meteorologist Miles Barnett. As with other ionospheric sectors, 'layer' implies a concentration of plasma (physics), while 'region' is the volume that contains the said layer. The F region contains ionized gases at a height of around 150‚Äì800 km (100 to 500 miles) above sea level, placing it in the Earth's thermosphere, a hot region in the upper atmosphere, and also in the heterosphere, where chemical composition varies with height. Generally speaking, the F region has the highest concentration of free electrons and ions anywhere in the atmosphere. It may be thought of as comprising two layers, the F1-and F2-layers. The F-region is located directly above the E region (formerly the Kennelly-Heaviside layer) and below the protonosphere. It acts as a dependable reflector of HF radio signals as it is not affected by atmospheric conditions, although its ionic composition varies with the sunspot cycle. It reflects normal-incident frequencies at or below the critical frequency (approximately 10 MHz) and partially absorbs waves of higher frequency. F1 and F2 layers The F1 layer is the lower sector of the F layer and exists from about 150 to 220 km (100 to 140 miles) above the surface of the Earth and only during daylight hours. It is composed of a mixture of molecular ions O2+ and NO+, and atomic ions O+. Above the F1 region, atomic oxygen becomes the dominant constituent because lighter particles tend to occupy higher altitudes above the turbopause (at ~100 km, 60 miles). This atomic oxygen provides the O+ atomic ions that make up the F2 layer. The F1 layer has approximately 5 √ó 105 e/cm3 (free electrons per cubic centimeter) at noontime and minimum sunspot activity, and increases to roughly 2 √ó 106 e/cm3 during maximum sunspot activity. The density falls off to below 104 e/cm3 at night. * The F1 layer merges into the F2 layer at night. * Though fairly regular in its characteristics, it is not observable everywhere or on all days. The principal reflecting layer during the summer for paths of 2,000 to 3,500 km (1200 to 2200 miles) is the F1 layer. However, this depends upon the frequency of a propagating signal. The E layer electron density and resultant MUF, maximum usable frequency, during high solar activity periods can refract and thus block signals of up to about 15 MHz from reaching the F1 and F2 regions, with the result that distances are much shorter than possible with refractions from the F1 and F2 regions. But extremely low radiation-angle signals (lower than about 6 degrees) can reach distances of 3000 km (1900 miles) via E region refractions.Adrian Weiss, Ionospheric Propagation, Transmission Lines, and Antennas for the QRP DXer, Milliwatt QRP Books, 2011, pp. 1-16, 1-22 to 1-24. * The F2 layer exists from about 220 to 800 km (140 to 500 miles) above the surface of the Earth. The F2 layer is the principal reflecting layer for HF communications during both day and night. The horizon-limited distance for one-hop F2 propagation is usually around 4,000 km (2500 miles). The F2 layer has about 106 e/cm3. However, variations are usually large, irregular, and particularly pronounced during magnetic storms. The F layer behaviour is dominated by the complex thermospheric winds. Usage in radio communication Critical F2 layer frequencies are the ones that will not go through the F2 layer. References * Category:Ionosphere Category:Radio frequency propagation ru:–ò–æ–Ω–æ—Å—Ñ–µ—Ä–∞#–°–ª–æ–π F ","title":"F region"},{"id":"41184","text":"In telecommunication, the term frequency averaging has the following meanings: #The process by which the relative phases of precision clocks are compared for the purpose of defining a single time standard. #A process in which network synchronization is achieved by use, at all nodes, of oscillators that adjust their frequencies to the average frequency of the digital bit streams received from connected nodes. In frequency averaging, all oscillators are assigned equal weight in determining the ultimate network frequency. In terms of musical note frequency, the averaging of the frequency of low or high notes in a solo instrumental piece is a technique used to match different instruments together so they may be played together. The musical note frequency calculation formula is used: F=(2^12/n)*440, where n equals the number of positive or negative steps away from the base note of A4(440 hertz) and F equals the frequency. The formula is used in calculating the frequency of each note in the piece. The values are then added together and divided by the number of notes. This is the average frequency of those notes. It is said that such techniques were used by classical composers, especially those who involved mathematics heavily in their music. References * Category:Telecommunications techniques Category:Synchronization Category:Frequency-domain analysis ","title":"Frequency averaging"},{"id":"41185","text":"In telecommunication, frequency-change signaling is a telegraph signaling method in which one or more particular frequencies correspond to each desired signaling condition of a telegraph code. The transition from one set of frequencies to the other may be a continuous or a discontinuous change in the frequency or phase. See also *Frequency-shift keying *Frequency modulation References Category:Data transmission Category:Telegraphy ","title":"Frequency-change signaling"},{"id":"41186","text":"In telecommunication, the term frequency compatibility has the following meanings: 1\\\\. Of an electronic device, the extent to which it will operate at its designed performance level in its intended operational environment (including the presence of interference) without causing interference to other devices. 2\\\\. The degree to which an electrical or electronic device or devices operating on or responding to a specified frequency or frequencies is capable of functioning with other such devices. See also electromagnetic compatibility References Category:Electromagnetic compatibility ","title":"Frequency compatibility"},{"id":"41187","text":"Frequency deviation (f_{\\\\Delta}) is used in FM radio to describe the maximum difference between an FM modulated frequency and the nominal carrier frequency. The term is sometimes mistakenly used as synonymous with frequency drift, which is an unintended offset of an oscillator from its nominal frequency. The frequency deviation of a radio is of particular importance in relation to bandwidth, because less deviation means that more channels can fit into the same amount of frequency spectrum. The FM broadcasting range (87.5‚Äì108 MHz, NOTE: In some countries the 87.5‚Äì88.0 MHz part of the band is not used) uses a channel spacing of 200 kHz, with a maximum frequency deviation of 75 kHz, leaving a 50 kHz buffer above the highest and below the lowest frequency to reduce interaction with other channels.Radio Broadcast Signals AM broadcasting uses a channel spacing of 10 kHz in the U.S. and 9 kHz in most other countries (such as the UK, Australia and New Zealand), but with amplitude modulation, frequency deviation is irrelevant. FM applications use peak deviations of 75 kHz (200 kHz spacing), 5 kHz (25 kHz spacing or 20 kHz spacing), 2.5 kHz (12.5 kHz spacing), and 2 kHz (8.33 kHz spacing, 7.5 kHz spacing, 6.25 kHz spacing or 5 kHz spacing).  See also  * Frequency modulation * Carson bandwidth rule  References  * Category:Radio modulation modes Category:Frequency-domain analysis ","title":"Frequency deviation"},{"id":"41188","text":"In telegraphy, frequency-exchange signaling or two-source frequency keying is frequency-change signaling in which the change from one significant condition to another is accompanied by decay in amplitude of one or more frequencies and by buildup in amplitude of one or more other frequencies. Frequency-exchange signaling applies to supervisory signaling and user-information transmission. See also *Keying (telecommunications) References Category:Telegraphy ","title":"Frequency-exchange signaling"},{"id":"41189","text":"In telecommunication, the term frequency frogging has the following meanings: # The interchanging of the frequencies of carrier channels to accomplish specific purposes, such as to prevent feedback and oscillation, to reduce crosstalk, and to correct for a high frequency response slope in the transmission line. # In microwave radio relay systems, the alternate use of two frequencies at repeater sites to prevent feedback and oscillation. Note: Frequency frogging is accomplished by having modulators, which are integrated into specially designed repeaters, translate a low-frequency group to a high- frequency group, and vice versa. A frequency channel will appear in the low group for one repeater section and will then be translated to the high group for the next section because of frequency frogging. This results in nearly constant attenuation with frequency over two successive repeater sections, and eliminates the need for large slope equalization and adjustments. Singing and crosstalk are minimized because the high-level output of a repeater is at a different frequency than the low-level input to other repeaters. It also diminishes group delay distortion. A repeater that receives on the high band from both direction and sends on the low band is called Hi-Lo; the other kind Lo-Hi. References Category:Communication circuits ","title":"Frequency frogging"},{"id":"41191","text":"Frequency sharing and Channel-sharing partition electromagnetic spectrum usage. Frequency sharing  = Geographic and temporal partitioning = In telecommunication, frequency sharing is the assignment to or use of the same radio frequency by two or more stations that are separated geographically or that use the frequency at different times. Frequency sharing reduces the potential for mutual interference where the assignment of different frequencies to each user is not practical or possible. In a communications net, frequency sharing does not pertain to stations that use the same frequency. Channel sharing in digital television From 2010 to 2017, U.S. mobile data usage increased by 40 times.https://docs.fcc.gov/public/attachments/DOC-355217A1.pdfhttps://www.cisco.com/c/dam/m/en_us/solutions/service- provider/vni-forecast- highlights/pdf/United_States_2021_Forecast_Highlights.pdf FCC's broadcast incentive auction channel sharing allows two or more stations to share a single 6 MHz TV channel, while retaining their licenses and all their rights (license sale, must-carry, retransmission consent).https://transition.fcc.gov/Daily_Releases/Daily_Business/2017/db0323/DOC-344040A1.pdfhttps://apps.fcc.gov/edocs_public/attachmatch/FCC-17-29A1.pdfnational- broadband-plan.pdf NBC sold three station's frequency spectrum in the (circa) April 4, 2017 FCC incentive auction, WNBC New York and Telemundo WSNS Chicago and WWSI Philadelphia. > \\"Their signals will all channel share with other NBC-owned stations in the > markets.\\" Stations had the option to channel-share with another TV station or go off the air by Jan. 23, 2018. In digital television, a broadcast station may offer several subchannels, for example, a main broadcast on channel 4.1, second on channel 4.2, and a third on channel 4.3. Channel-sharing agreements allow a single channel to be split among multiple broadcasters, with each operating its own set of subchannels. In New York, Comcast is consolidating multiple stations into one, by moving NBC onto Telemundo‚Äôs Channel 35 WNJU, while Channel 28 WNBC's frequency spectrum will go off the air as TV, sold in the 2017 FCC incentive auction, both will broadcast from WNBC's antenna. ATSC 3.0 will use HEVC video and AC4 audio encoding standards, native IP transport, DASH segmentation, and ROUTE encapsulation, unlike ATSC 1.0 with transport streams.  External links  * :* References Category:Bandplans ","title":"Frequency sharing"},{"id":"41192","text":"In the physical sciences and in telecommunication, the term frequency shift may refer to: * Any change in frequency * A Doppler shift * In facsimile, a frequency modulation system where one frequency represents picture black and another frequency represents picture white * Spectrum shifting in signal processing, see Discrete Fourier transform#Shift theorem  See also  * Frequency mixer * Voice inversion ","title":"Frequency shift"},{"id":"41193","text":"An example of binary FSK thumb Frequency-shift keying (FSK) is a frequency modulation scheme in which digital information is transmitted through discrete frequency changes of a carrier signal., p 509 The technology is used for communication systems such as telemetry, weather balloon radiosondes, caller ID, garage door openers, and low frequency radio transmission in the VLF and ELF bands. The simplest FSK is binary FSK (BFSK). BFSK uses a pair of discrete frequencies to transmit binary (0s and 1s) information.FSK: Signals and Demodulation (B. Watson) http://www.xn--sten- cpa.se/share/text/tektext/digital-modulation/FSK_signals_demod.pdf With this scheme, the \\"1\\" is called the mark frequency and the \\"0\\" is called the space frequency. Modulating and demodulating Reference implementations of FSK modems exist and are documented in detail.Teaching DSP through the Practical Case Study of an FSK Modem (TI) http://www.ti.com/lit/an/spra347/spra347.pdf The demodulation of a binary FSK signal can be done using the Goertzel algorithm very efficiently, even on low-power microcontrollers.FSK Modulation and Demodulation With the MSP430 Microcontroller (TI) http://www.ti.com/lit/an/slaa037/slaa037.pdf Variations =Continuous- phase frequency-shift keying= In principle FSK can be implemented by using completely independent free-running oscillators, and switching between them at the beginning of each symbol period. In general, independent oscillators will not be at the same phase and therefore the same amplitude at the switch-over instant, causing sudden discontinuities in the transmitted signal. In practice, many FSK transmitters use only a single oscillator, and the process of switching to a different frequency at the beginning of each symbol period preserves the phase. The elimination of discontinuities in the phase (and therefore elimination of sudden changes in amplitude) reduces sideband power, reducing interference with neighboring channels. =Gaussian frequency-shift keying= Rather than directly modulating the frequency with the digital data symbols, \\"instantaneously\\" changing the frequency at the beginning of each symbol period, Gaussian frequency-shift keying (GFSK) filters the data pulses with a Gaussian filter to make the transitions smoother. This filter has the advantage of reducing sideband power, reducing interference with neighboring channels, at the cost of increasing intersymbol interference. It is used by Improved Layer 2 Protocol, DECT, Bluetooth,Sweeney, D. \\"An introduction to bluetooth a standard for short range wireless networking\\" Proceedings. 15th Annual IEEE International ASIC/SOC Conference, Rochester, NY, US, 25-28 Sept. 2002, pp. 474‚Äì475. 2002. http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1158106 Cypress WirelessUSB, Nordic Semiconductor,Nordic Semiconductor. nRF24LU1+ Preliminary Product Specification v1.2 Texas Instruments LPRF, IEEE 802.15.4, Z-Wave and Wavenis devices. For basic data rate Bluetooth the minimum deviation is 115 kHz. A GFSK modulator differs from a simple frequency-shift keying modulator in that before the baseband waveform (levels ‚àí1 and +1) goes into the FSK modulator, it is passed through a Gaussian filter to make the transitions smoother so to limit its spectral width. Gaussian filtering is a standard way for reducing spectral width; it is called pulse shaping in this application. In ordinary non-filtered FSK, at a jump from ‚àí1 to +1 or +1 to ‚àí1, the modulated waveform changes rapidly, which introduces large out-of-band spectrum. If the pulse is changed going from ‚àí1 to +1 as ‚àí1, ‚àí0.98, ‚àí0.93, ..., +0.93, +0.98, +1, and this smoother pulse is used to determine the carrier frequency, the out-of-band spectrum will be reduced. =Minimum-shift keying= Minimum frequency-shift keying or minimum-shift keying (MSK) is a particular spectrally efficient form of coherent FSK. In MSK, the difference between the higher and lower frequency is identical to half the bit rate. Consequently, the waveforms that represent a 0 and a 1 bit differ by exactly half a carrier period. The maximum frequency deviation is Œ¥ = 0.25 fm, where fm is the maximum modulating frequency. As a result, the modulation index m is 0.5. This is the smallest FSK modulation index that can be chosen such that the waveforms for 0 and 1 are orthogonal. =Gaussian minimum-shift keying= A variant of MSK called Gaussian minimum-shift keying (GMSK) is used in the GSM mobile phone standard. = Audio frequency-shift keying = Audio frequency-shift keying (AFSK) is a modulation technique by which digital data is represented by changes in the frequency (pitch) of an audio tone, yielding an encoded signal suitable for transmission via radio or telephone. Normally, the transmitted audio alternates between two tones: one, the \\"mark\\", represents a binary one; the other, the \\"space\\", represents a binary zero. AFSK differs from regular frequency-shift keying in performing the modulation at baseband frequencies. In radio applications, the AFSK-modulated signal normally is being used to modulate an RF carrier (using a conventional technique, such as AM or FM) for transmission. AFSK is not always used for high-speed data communications, since it is far less efficient in both power and bandwidth than most other modulation modes. In addition to its simplicity, however, AFSK has the advantage that encoded signals will pass through AC- coupled links, including most equipment originally designed to carry music or speech. AFSK is used in the U.S.-based Emergency Alert System to notify stations of the type of emergency, locations affected, and the time of issue without actually hearing the text of the alert. =Continuous 4-level modulation= Phase 1 radios in the Project 25 system use continuous 4-level FM (C4FM) modulation. Essam Atalla et al. \\"A Practical Step Forward Toward Software-Defined Radio Transmitters\\". p. 1. Steve Ford. \\"ARRL's VHF Digital Handbook\\". 2008\\\\. p. 6-2. Applications In 1910, Reginald Fessenden invented a two-tone method of transmitting Morse code. Dots and dashes were replaced with different tones of equal length.; Morse cites British patent 2,617/11. The intent was to minimize transmission time. Some early CW transmitters employed an arc converter that could not be conveniently keyed. Instead of turning the arc on and off, the key slightly changed the transmitter frequency in a technique known as the compensation-wave method. The compensation-wave was not used at the receiver. Spark transmitters used for this method consumed a lot of bandwidth and caused interference, so it was discouraged by 1921. Most early telephone-line modems used audio frequency- shift keying (AFSK) to send and receive data at rates up to about 1200 bits per second. The Bell 103 and Bell 202 modems used this technique. Even today, North American caller ID uses 1200 baud AFSK in the form of the Bell 202 standard. Some early microcomputers used a specific form of AFSK modulation, the Kansas City standard, to store data on audio cassettes. AFSK is still widely used in amateur radio, as it allows data transmission through unmodified voiceband equipment. AFSK is also used in the United States' Emergency Alert System to transmit warning information. It is used at higher bitrates for Weathercopy used on Weatheradio by NOAA in the U.S. The CHU shortwave radio station in Ottawa, Ontario, Canada broadcasts an exclusive digital time signal encoded using AFSK modulation. Caller ID and remote metering standards Frequency-shift keying (FSK) is commonly used over telephone lines for caller ID (displaying callers' numbers) and remote metering applications. There are several variations of this technology. =European Telecommunications Standards Institute= In some countries of Europe, the European Telecommunications Standards Institute (ETSI) standards 200 778-1 and -2 - replacing 300 778-1 & -2 - allow 3 physical transport layers (Telcordia Technologies (formerly Bellcore), British Telecom (BT) and Cable Communications Association (CCA)), combined with 2 data formats Multiple Data Message Format (MDMF) & Single Data Message Format (SDMF), plus the Dual- tone multi-frequency (DTMF) system and a no-ring mode for meter-reading and the like. It's more of a recognition that the different types exist than an attempt to define a single \\"standard\\". =Telcordia Technologies= The Telcordia Technologies (formerly Bellcore) standard is used in the United States, Canada (but see below), Australia, China, Hong Kong and Singapore. It sends the data after the first ring tone and uses the 1200 bits per second Bell 202 tone modulation. The data may be sent in SDMF - which includes the date, time and number - or in MDMF, which adds a NAME field. =British Telecom= British Telecom (BT) in the United Kingdom developed their own standard, which wakes up the display with a line reversal, then sends the data as CCITT v.23 modem tones in a format similar to MDMF. It is used by BT, wireless networks like the late Ionica, and some cable companies. Details are to be found in BT Supplier Information Notes (SINs) 227 and 242; another useful document is Designing Caller Identification Delivery Using XR-2211 for BT from the EXAR website. =Cable Communications Association= The Cable Communications Association (CCA) of the United Kingdom developed their own standard which sends the information after a short first ring, as either Bell 202 or V.23 tones. They developed a new standard rather than change some \\"street boxes\\" (multiplexors) which couldn't cope with the BT standard. The UK cable industry use a variety of switches: most are Nortel DMS-100; some are System X; System Y; and Nokia DX220. Note that some of these use the BT standard instead of the CCA one. The data format is similar to the BT one, but the transport layer is more like Telcordia Technologies, so North American or European equipment is more likely to detect it. See also * Amplitude-shift keying (ASK) * Continuous-phase frequency-shift keying (CPFSK) * Dual-tone multi-frequency (DTMF), another encoding technique representing data by pairs of audio frequencies * Frequency-change signaling * Multiple frequency-shift keying (MFSK) * Orthogonal frequency-division multiplexing (OFDM) * Phase- shift keying (PSK) * Federal Standard 1037C * MIL-STD-188 * Spread frequency- shift keying (S-FSK) References * . Revised to April 24, 1921. * * External links *dFSK: Distributed Frequency Shift Keying Modulation in Dense Sensor Networks * M Nasseri, J Kim, M Alam - Proceedings of the 17th Communications & Networking, 2014, Unified metric calculation of sampling- based turbo-coded noncoherent MFSK for mobile channel * J Kim, P Raorane, M Nasseri, M Alam - Proceedings of the 46th Annual Simulation Symposium, 2013, Performance analysis of sampling-based turbo coded NCQFSK for image data transmission Category:Amateur radio Category:Caller ID Category:Quantized radio modulation modes ","title":"Frequency-shift keying"},{"id":"41194","text":"oven controlled crystal oscillators at the US Bureau of Standards (now NIST) served as the frequency standard for the United States in 1929. A frequency standard is a stable oscillator used for frequency calibration or reference. A frequency standard generates a fundamental frequency with a high degree of accuracy and precision. Harmonics of this fundamental frequency are used to provide reference points. Since time is the reciprocal of frequency, it is relatively easy to derive a time standard from a frequency standard. A standard clock comprises a frequency standard, a device to count off the cycles of the oscillation emitted by the frequency standard, and a means of displaying or outputting the result. Frequency standards in a network or facility are sometimes administratively designated as primary or secondary. The terms primary and secondary, as used in this context, should not be confused with the respective technical meanings of these words in the discipline of precise time and frequency. Frequency reference A frequency reference is an instrument used for providing a stable frequency of some kind. There are different sorts of frequency references, acoustic ones such as tuning forks but also electrical ones that emit a signal of a certain frequency (a frequency standard). Among the most stable frequency references in the world are cesium standards, including cesium fountains, and hydrogen masers. Cesium standards are widely recognized as having better long-term stability, whereas hydrogen masers can attain superior short-term performance; therefore, several national standards laboratories use ensembles of cesium standards and hydrogen masers in order to combine the best attributes of both. The carrier of time signal transmitters, Loran-C transmitters and of several long wave and medium wave broadcasting stations is derived from an atomic clock and can be therefore used as frequency standard. References See also * Rubidium standard * Atomic clock Category:Electronics standards ","title":"Frequency standard"},{"id":"41196","text":"Fresnel zone: D is the distance between the transmitter and the receiver; r is the radius of the first Fresnel zone (n=1) at point P. P is d1 away from the transmitter, and d2 away from the receiver. A Fresnel zone ( ), named after physicist Augustin-Jean Fresnel, is one of a series of confocal prolate ellipsoidal regions of space between and around a transmitter and a receiver. Transmitted radio, sound, or light waves can follow slightly different paths before reaching a receiver, especially if there are obstructions or reflecting objects between the two. The waves can arrive at slightly different times and will be slightly out of phase due to the different path lengths. Depending on the magnitude of the phase shift, the waves can interfere constructively or destructively. The size of the calculated Fresnel zone at any particular distance from the transmitter and receiver can help to predict whether obstructions or discontinuities along the path will cause significant interference. Significance In any wave-propagated transmission between a transmitter and receiver, some amount of the radiated wave propagates off-axis (not on the line-of-sight path between transmitter and receiver). This can then deflect off of objects and then radiate to the receiver. However, the direct-path wave and the deflected-path wave may arrive out of phase, leading to destructive interference when the phase difference is a half-integer multiple of the period. The n-th Fresnel zone is defined as the locus of points in 3D space such that a 2-segment path from the transmitter to the receiver that deflects off a point on that surface will be between n-1 and n half-wavelengths out of phase with the straight-line path. The boundaries of these zones will be ellipsoids with foci at the transmitter and receiver. In order to ensure limited interference, such transmission paths are designed with a certain clearance distance determined by a Fresnel-zone analysis. The dependence on the interference on clearance is the cause of the picket-fencing effect when either the radio transmitter or receiver is moving, and the high and low signal strength zones are above and below the receiver's cut-off threshold. The extreme variations of signal strength at the receiver can cause interruptions in the communications link, or even prevent a signal from being received at all. Fresnel zones are seen in optics, radio communications, electrodynamics, seismology, acoustics, gravitational radiation, and other situations involving the radiation of waves and multipath propagation. Fresnel zone computations are used to anticipate obstacle clearances required when designing highly directive systems such as microwave parabolic antenna systems. Although intuitively, line-of-sight between transmitter and receiver seems to be all that is required for a strong antenna system, because of the complex nature of radio waves, obstructions within the first Fresnel zone can cause significant weakness, even if those obstructions are not blocking the line-of-sight signal path. For this reason, it is valuable to do a calculation of the size of the 1st, or primary, Fresnel zone for a given antenna system. Doing this will enable the antenna installer to decide if an obstacle, such as a tree, is going to make a significant impact on signal strength. The rule of thumb is that the primary Fresnel zone would ideally be 80% clear of obstacles, but must be at least 60% clear. Spatial structure First Fresnel zone avoidance Fresnel zones are confocal prolate ellipsoidal shaped regions in space (e.g. 1, 2, 3), centered around the line of the direct transmission path (path AB on the diagram). The first region includes the ellipsoidal space which the direct line-of-sight signal passes through. If a stray component of the transmitted signal bounces off an object within this region and then arrives at the receiving antenna, the phase shift will be something less than a quarter-length wave, or less than a 90¬∫ shift (path ACB on the diagram). The effect regarding phase-shift alone will be minimal. Therefore, this bounced signal can potentially result in having a positive impact on the receiver, as it is receiving a stronger signal than it would have without the deflection, and the additional signal will potentially be mostly in-phase. However, the positive attributes of this deflection also depends on the polarization of the signal relative to the object (see the section on polarization below). The 2nd region surrounds the 1st region but excludes the first region. If a reflective object is located in the 2nd region, the stray sine-wave which has bounced from this object and has been captured by the receiver will be shifted more than 90¬∫ but less than 270¬∫ because of the increased path length, and will potentially be received out-of-phase. Generally this is unfavorable. But again, this depends on polarization (explained below). The 3rd region surrounds the 2nd region and deflected waves captured by the receiver will have the same effect as a wave in the 1st region. That is, the sine wave will have shifted more than 270¬∫ but less than 450¬∫ (ideally it would be a 360¬∫ shift) and will therefore arrive at the receiver with the same shift as a signal might arrive from the 1st region. A wave deflected from this region has the potential to be shifted precisely one wavelength so that it is exactly in sync with the line-of-sight wave when it arrives at the receiving antenna. The 4th region surrounds the 3rd region and is similar to the 2nd region. And so on. If unobstructed and in a perfect environment, radio waves will travel in a relatively straight line from the transmitter to the receiver. But if there are reflective surfaces that interact with a stray transmitted wave, such as bodies of water, smooth terrain, roof tops, sides of buildings, etc., the radio waves deflecting off those surfaces may arrive either out-of-phase or in-phase with the signals that travel directly to the receiver. Sometimes this results in the counter-intuitive finding that reducing the height of an antenna increases the signal-to-noise ratio at the receiver. Although radio waves generally travel in a straight line, fog and even humidity can cause some of the signal in certain frequencies to scatter or bend before reaching the receiver. This means that objects that are clear of the line of sight path will still potentially block parts of the signal. To maximize signal strength, one needs to minimize the effect of obstruction loss by removing obstacles from both the direct radio frequency line of sight (RF LoS) line and also the area around it within the primary Fresnel zone. The strongest signals are on the direct line between transmitter and receiver and always lie in the first Fresnel zone. In the early 19th century, French scientist Augustin-Jean Fresnel discovered a method to calculate where the zones are ‚Äî that is, whether a given obstacle will cause mostly in-phase or mostly out-of-phase deflections between the transmitter and the receiver. Clearance Several examples of how Fresnel zones can be disrupted The concept of Fresnel zone clearance may be used to analyze interference by obstacles near the path of a radio beam. The first zone must be kept largely free from obstructions to avoid interfering with the radio reception. However, some obstruction of the Fresnel zones can often be tolerated. As a rule of thumb the maximum obstruction allowable is 40%, but the recommended obstruction is 20% or less. For establishing Fresnel zones, first determine the RF line of sight (RF LoS), which in simple terms is a straight line between the transmitting and receiving antennas. Now the zone surrounding the RF LoS is said to be the Fresnel zone. The cross sectional radius of each Fresnel zone is the longest at the midpoint of the RF LoS, shrinking to a point at each vertex (which coincide with the antenna on each end, within the approximation made). =Formulation= Consider an arbitrary point P in the LoS, at a distance d_1 and d_2 with respect to each of the two antennas. To obtain the radius r_n of zone n, note that the volume of the zone is delimited by all points for which the difference in distances, between the direct wave (D=d_1+d_2) and the reflected wave (\\\\overline{AP} + \\\\overline{PB}) is the constant n\\\\frac{\\\\lambda}{2} (multiples of half a wavelength). This effectively defines an ellipsoid with the major axis along \\\\overline{AB} and foci at the antennas (points A and B). So: :\\\\overline{AP} + \\\\overline{PB} - D = n\\\\frac{\\\\lambda}{2} Re-writing the expression with the coordinates of point P and the distance between antennas D, it gives: :\\\\sqrt{d_1^2+r_n^2}+\\\\sqrt{d_2^2+r_n^2}-D=n\\\\frac{\\\\lambda}{2} Assuming the distances between the antennas and the point P are much larger than the radius, expanding the roots in series and retaining the first two terms, the expression simplifies to: :\\\\frac{r_n^2}{2}\\\\left(\\\\frac{1}{d_1}+\\\\frac{1}{d_2}\\\\right)=n\\\\frac{\\\\lambda}{2} which can be solved for r_n: :r_n=\\\\sqrt{n\\\\frac{d_1\\\\ d_2}{D}\\\\lambda},\\\\quad d_1, d_2 \\\\gg n\\\\lambda, For a satellite-to-Earth link, d_2\\\\approx D and: :r_n\\\\approx \\\\sqrt{n d_1 \\\\lambda} Note that when d_1=0 or d_2=0\\\\implies r_n=0, which implies that the foci coincide with the vertices of the ellipsoid. This is not correct and it's a consequence of the approximation made. Setting the point P to one of the vertices it's possible to obtain the error \\\\epsilon of this approximation: :\\\\epsilon + \\\\left(\\\\epsilon+D\\\\right) - D = n\\\\frac{\\\\lambda}{2}\\\\implies\\\\epsilon=n\\\\frac{\\\\lambda}{4} Since the distance between antennas is generally tens of km and \\\\lambda of the order of cm, the error is negligible for a graphical representation. =Maximum clearance= For practical applications, it is often useful to know the maximum radius of the first Fresnel zone. Using n = 1, d_1 = d_2 = D/2, and \\\\lambda = c/f in the above formula gives :F_1 = {1 \\\\over 2} \\\\sqrt{\\\\lambda D} = {1 \\\\over 2} \\\\sqrt{c D \\\\over f}, where :D is the distance between the two antennas, :f is the frequency of the transmitted signal, :c ‚âà is the speed of light in the air. Substitution of the numeric value for c followed by a unit conversion results in an easy way to calculate the radius of the first Fresnel zone F_1, knowing the distance between the two antennas D and the frequency of the transmitted signal f: *F_1 \\\\mathrm{[m]} = 8.656 \\\\sqrt{D \\\\mathrm{[km]} \\\\over f \\\\mathrm{[GHz]}} *F_1 \\\\mathrm{[ft]}= 36.03 \\\\sqrt{D \\\\mathrm{[mi]} \\\\over f \\\\mathrm{[GHz]}} See also * Diversity scheme * Ellipse#Elliptical reflectors and acoustics * Fresnel diffraction * Fresnel integral * Fresnel number * Fresnel zone plate * Fresnel zone antenna * Microwave * Near field * Path loss * Rain fade * Weissberger's model References * External links * Online Fresnel Zone Calculator: Support the global language *Generate 3D Fresnel zone, as a Google Earth KML file *Fresnel zone calculator and elevation chart *Fresnel zone calculator *FEN Fresnel zone calculator *More Fresnel zone details *R.E. Sherriff, Understanding the Fresnel zone *VHF/UHF/Microwave Radio Propagation: A Primer for Digital Experimenters Category:Diffraction Category:Radio frequency propagation ","title":"Fresnel zone"},{"id":"41197","text":"Radiation pattern of an antenna with main lobe (right) in red, and back lobe in blue In telecommunication, the term front-to-back ratio (also known as front-to-rear ratio) can mean: #The ratio of power gain between the front and rear of a directional antenna. #Ratio of signal strength transmitted in a forward direction to that transmitted in a backward direction. For receiving antennas, the ratio of received-signal strength when the antenna is rotated 180¬∞.Radio Shack 1974-75 unabridged Dictionary of Electronics edited by Rudolf F. Graf, cat. no. 68-1030 The ratio compares the antenna gain in a specified direction, i.e., azimuth, usually that of maximum gain, to the gain in a direction 180¬∞ from the specified azimuth. A front-to-back ratio is usually expressed in dB. In point-to-point microwave antennas, a \\"high performance\\" antenna usually has a higher front to back ratio than other antennas. For example, an unshrouded 38 GHz microwave dish may have a front to back ratio of 64 dB, while the same size reflector equipped with a shroud would have a front to back ratio of 70 dB. Other factors affecting the front to back ratio of a parabolic microwave antenna include the material of the dish and the precision with which the reflector itself was formed. In other electrical engineering the front to back ratio is a ratio of parameters used to characterize rectifiers or other devices, in which electric current, signal strength, resistance, or other parameters, in one direction is compared with that in the opposite direction.  References  Category:Antennas Category:Engineering ratios ","title":"Front-to-back ratio"},{"id":"41199","text":"Federal Telecommunications System 2000 (FTS2000) is a long distance telecommunications service for the United States federal government, including services such as switched voice service for voice or data up to 4.8 kbit/s, switched data at 56 kbit/s and 64 kbit/s, switched digital integrated service for voice, data, image, and video up to 1.544 Mbit/s, packet switched service for data in packet form, video transmission for both compressed and wideband video, and dedicated point-to-point private line for voice and data. Note 1: Use of FTS2000 contract services is mandatory for use by U.S. Government agencies for all acquisitions subject to 40 U.S.C. 759. Note 2: No U.S. Government information processing equipment or customer premises equipment other than that which are required to provide an FTS2000 service are furnished. Note 3: The FTS2000 contractors will be required to provide service directly to an agency's terminal equipment interface. For example, the FTS2000 contractor might provide a terminal adapter to an agency location in order to connect FTS2000 ISDN services to the agency's terminal equipment. Note 4: GSA awarded two 10-year, fixed-price contracts covering FTS2000 services on December 7, 1988. Note 5: The Warner Amendment excludes the mandatory use of FTS2000 in instances related to maximum security. FTS2000 was completed in 2000, then replaced by FTS2001, and thereafter, in 2008, by Networx. References *FTS2000 was completed in 2000, and was replaced by FTS2001. Category:Telecommunication services Category:Telecommunications in the United States ","title":"FTS2000"},{"id":"41200","text":"Full width at half maximum Full width at half maximum (FWHM) is an expression of the extent of a function given by the difference between the two extreme values of the independent variable at which the dependent variable is equal to half of its maximum value. In other words, it is the width of a spectrum curve measured between those points on the y-axis which are half the maximum amplitude. Half width at half maximum (HWHM) is half of the FWHM if the function is symmetric. FWHM is applied to such phenomena as the duration of pulse waveforms and the spectral width of sources used for optical communications and the resolution of spectrometers. The term full duration at half maximum (FDHM) is preferred when the independent variable is time. The convention of \\"width\\" meaning \\"half maximum\\" is also widely used in signal processing to define bandwidth as \\"width of frequency range where less than half the signal's power is attenuated\\", i.e., the power is at least half the maximum. In signal processing terms, this is at most ‚àí3 dB of attenuation, called \\"half-power point\\". If the considered function is the density of a normal distribution of the form :f(x) = \\\\frac{1}{\\\\sigma \\\\sqrt{2 \\\\pi} } \\\\exp \\\\left[ -\\\\frac{(x-x_0)^2}{2 \\\\sigma^2} \\\\right] where œÉ is the standard deviation and x0 is the expected value, then the relationship between FWHM and the standard deviation isGaussian Function - from Wolfram MathWorld : \\\\mathrm{FWHM} = 2\\\\sqrt{2 \\\\ln 2 } \\\\; \\\\sigma \\\\approx 2.355 \\\\; \\\\sigma. The width does not depend on the expected value x0; it is invariant under translations. In spectroscopy half the width at half maximum (here Œ≥), HWHM, is in common use. For example, a Lorentzian/Cauchy distribution of height can be defined by :f(x) = \\\\frac{1}{\\\\pi\\\\gamma \\\\left[1 + \\\\left(\\\\frac{x - x_0}{\\\\gamma}\\\\right)^2\\\\right]} \\\\quad \\\\text{ and } \\\\quad \\\\mathrm{FWHM} = 2 \\\\gamma. Another important distribution function, related to solitons in optics, is the hyperbolic secant: :f(x)=\\\\operatorname{sech} \\\\left( \\\\frac{x}{X} \\\\right). Any translating element was omitted, since it does not affect the FWHM. For this impulse we have: :\\\\mathrm{FWHM} = 2 \\\\operatorname{arcsech} (\\\\tfrac12) X = 2 \\\\ln (2 + \\\\sqrt{3}) \\\\; X \\\\approx 2.634 \\\\; X where arcsech is the inverse hyperbolic secant. If the FWHM of a Gaussian function is known, then it can be integrated by simple multiplication.  See also  *Gaussian function *Cutoff frequency  References  *  External links  *FWHM at Wolfram Mathworld Category:Statistical deviation and dispersion Category:Telecommunication theory Category:Waves ","title":"Full width at half maximum"},{"id":"41201","text":"In telecommunication, a functional profile is a standardization document that characterizes the requirements of a standard or group of standards, and specifies how the options and ambiguities in the standard(s) should be interpreted or implemented to (a) provide a particular information technology function, (b) provide for the development of uniform, recognized tests, and (c) promote interoperability among different network elements and terminal equipment that implement a specific profile. Sources Category:Telecommunications standards ","title":"Functional profile"},{"id":"41202","text":"Fuse or FUSE may refer to: Devices * Fuse (electrical), a device used in electrical systems to protect against excessive current ** Fuse (automotive), a class of fuses for vehicles * Fuse (hydraulic), a device used in hydraulic systems to protect against sudden loss of fluid pressure * Fuse (explosives) or fuze, the part of the device that initiates function * Fuze or fuse, a mechanism for exploding military munitions such as bombs, shells, and mines Computing * Fuse ESB, an open-source integration platform based on Apache Camel * Filesystem in Userspace, a virtual file system interface for Unix-like operating systems * Fuse (emulator), the Free Unix Spectrum Emulator of the ZX Spectrum * Fuse Internet Service, a former Cincinnati Bell Internet service provider based in Cincinnati, Ohio, United States * Fuse Universal, a learning platform Science * Far Ultraviolet Spectroscopic Explorer, a space-based ultraviolet telescope and spectroscope * Intramembranous ossification, the fusing of bones of the skeletal system * Cell fusion, several biological cells combining * Fuse (thermonuclear) * Fused compound, a class of multi-ring chemical structures Entertainment * Fuse Games, a game developer * Fuse (film), a 2003 film by Pjer ≈Ωalica, original Bosnian title Gori vatra * Fuse Tepp≈ç Musume no Torimonoch≈ç, a 2012 Japanese animated film * Fuse (magazine), a Canadian arts and culture magazine * Fuse (video game), a video game by Insomniac Games =Music= * Fuse (band) ** Fuse (Fuse album), a 1969 album by the above band * The Fuse (Scottish band), a band from the East of Scotland * Fuse (Joe Henry album), a 1999 album by Joe Henry * Fuse (Colin James album), a 2000 album by Colin James * Fuse (Keith Urban album), a 2013 album by Keith Urban * Fused (album), a 2005 album by Tony Iommi * The Fuse (Pennywise album), a 2005 album by Pennywise * F.U.S.E., an alias for electronic artist Richie Hawtin (born 1970) * Fuse Festival, an Australian contemporary music event * \\"Fuse\\", an instrumental by Chaz Jankel from his 1980 album Chas Jankel * \\"The Fuse\\", a song by Bruce Springsteen from his 2002 album The Rising * \\"The Fuse\\", a song by Jackson Browne from his 1976 album The Pretender * \\"The Fuse\\", a song by Heaven 17 from their 1984 album How Men Are =Radio and television= * Fuse (TV channel), an American cable television station * Fuse (radio program), a musical radio program on CBC * The Fuse (game show), a UK game show broadcast on ITV1 Other uses * Fuse, a consumer electronics company started by Tony Fadell * Fuse (chocolate bar), a brand of chocolate bar made by Cadbury * Fuse (surname), a Japanese surname * Fuse, Shimane, a village located in Oki District, Shimane, Japan * Scion Fuse, a concept car See also * Flare, also known as a fusee * Fusebox (programming) * Fusee (disambiguation) * Fusion (disambiguation) * Fuze (disambiguation) ","title":"Fuse"},{"id":"41203","text":"Garble may refer to: * Garble (My Little Pony), a character in My Little Pony * Garble, a character in Freddy and the Men from Mars See also * Grable, a surname (and list of people with the name) G ","title":"Garble"},{"id":"41204","text":"Gateway often refers to: *A gate or portal Gateway or The Gateway may also refer to: User interfaces *Gateway (web page), a web page designed to attract visitors and search engines to a particular website Computing and telecommunication devices *Default gateway, the node in a computer network that passes traffic from a local network to other networks or the Internet (router) *Gateway (computer program), a link between two computer programs allowing them to share information and bypass certain protocols on a host computer *Gateway (telecommunications), a network node equipped for interfacing with another network that uses different communication protocols *Residential gateway, a home networking device that connects a local computer or network to the Internet (router) *TV gateway, a home television to network UPnP TV router, receiving live DVB and streaming it over an IP network Technology *Payment gateway, the software interface between a web-based shopping cart and a merchant account *Gateway Technology, a cloning system in molecular biology *Gateway 3DS, a flash cartridge for the Nintendo 3DS; see Nintendo 3DS storage devices *Lunar Gateway, a proposed moon orbit space station Companies *Gateway, Inc., a computer manufacturer *Gateway Collegiate Athletic Conference, a women's sports conference that operated from 1983 to 1992 before being absorbed by the Missouri Valley Conference *Gateway Football Conference, a college football league that is now known as the Missouri Valley Football Conference *Gateway Newstands, a Canadian convenience store chain *Gateway Supermarket, a former UK supermarket chain rebranded as Somerfield in the 1990s Places =Australia= *Gateway Bridge, Brisbane, the most eastern crossing of the Brisbane River, Brisbane *Gateway Motorway, a freeway in Brisbane =Canada= *Gateway Boulevard, a major street in Edmonton *Gateway Station on the Vancouver SkyTrain's Expo Line *Greater Vancouver Gateway Program, an infrastructure project for Greater Vancouver =Singapore= *Gateway Monorail Station, a station on the Sentosa Monorail *The Gateway, Singapore, a twin-building office complex =United States= *Gateway, Alaska *Gateway, Arkansas *Gateway, California (disambiguation) **Gateway, Los Angeles County, California, a place in California **Gateway, Nevada County, California **Gateway, San Diego, California *Gateway, Colorado *Gateway, Florida *Gateway International Raceway, a racetrack in Madison, Illinois *Gateway Arch, part of the Gateway Arch National Park in St. Louis, Missouri *Westfield Gateway, an enclosed shopping mall in Lincoln, Nebraska *Gateway National Recreation Area, parks and beaches in New York City and New Jersey *Gateway Project, a rail expansion project between New York City and Newark, New Jersey *Gateway Region, the most urbanized part of northeastern New Jersey *Gateway, Camden, a neighborhood in Camden, New Jersey *Gateway Station (Charlotte, North Carolina), a proposed intermodal transit center in Charlotte, North Carolina *Gateway Sports and Entertainment Complex, a stadium complex in Cleveland, Ohio *Gateway, Oregon *The Gateway (Salt Lake City), a retail, residential and office complex in Salt Lake City, Utah =Elsewhere= *The Gateway, Hong Kong, a shopping centre in Tsim Sha Tsui, Kowloon, Hong Kong *Gateway of India, Mumbai *Gateway Theatre of Shopping, a shopping centre in Durban, South Africa Arts and media =Music= *Gateway (band) a jazz trio featuring John Abercrombie, Jack DeJohnette and Dave Holland **Gateway (Gateway album) (1976) *Gateway (Bongzilla album) *Gateway, an album by Erik W√∏llo *Gateway Worship =Other media= *Gateway (comics), a supporting character in Marvel's X-Men series *Gateway (novel), a 1977 novel by Frederik Pohl **Gateway (computer game), two adventure games based on the novel *Gateway (film), a 1938 dramatic film by Alfred L. Werker *Gateway (video game), an interactive fiction game *Gateway Galaxy, a galaxy in the video game Super Mario Galaxy Other * Gateway Regional High School (Massachusetts) See also *Gateway drug theory, a hypothesis on drug use Gateways (disambiguation) *The Gateway (disambiguation) *Gateway Academy (disambiguation) *Gateway Bridge (disambiguation) *Gateway Center (disambiguation) *Gateway Church (disambiguation) *Gateway Mall (disambiguation) *Gateway station (disambiguation) *Gateway Theatre (disambiguation) *Gateway Tower (disambiguation) *Gate (disambiguation) *Way (disambiguation) *Waygate (disambiguation) ","title":"Gateway"},{"id":"41205","text":"Gating may refer to: Neurobiology *Gating (electrophysiology), the opening (activation) or closing (deactivation) of ion channels *Sensory gating, an automatic process by which the brain adjusts to stimuli *Synaptic gating, neural circuits suppressing inputs through synapses Technology *Gating (telecommunication), a process of selectively modifying signals *Gating system metalwork, a process in casting *Gating signal, a signal that provides a time window *Clock gating, a power-saving techniques used in synchronous circuits *Power gating, a power-saving technique for circuits *Noise gate, a term in audio signal processing *Frequency-resolved optical gating, a term related to auto correlation in optics Other *Gating (punishment), a form of punishment used in educational establishments See also *Gate (disambiguation) *Gates (disambiguation) ","title":"Gating"},{"id":"41206","text":"Intensity of a simulated Gaussian beam around focus at an instant of time, showing two intensity peaks for each wavefront. Top: transverse intensity profile of a Gaussian beam that is propagating out of the page. Blue curve: electric (or magnetic) field amplitude vs. radial position from the beam axis. The black curve is the corresponding intensity. A 5 mW green laser pointer beam profile, showing the TEM00 profile. In optics, a Gaussian beam is a beam of monochromatic electromagnetic radiation whose amplitude envelope in the transverse plane is given by a Gaussian function; this also implies a Gaussian intensity (irradiance) profile. This fundamental (or TEM00) transverse Gaussian mode describes the intended output of most (but not all) lasers, as such a beam can be focused into the most concentrated spot. When such a beam is refocused by a lens, the transverse phase dependence is altered; this results in a different Gaussian beam. The electric and magnetic field amplitude profiles along any such circular Gaussian beam (for a given wavelength and polarization) are determined by a single parameter: the so- called waist . At any position relative to the waist (focus) along a beam having a specified , the field amplitudes and phases are thereby determinedSvelto, pp. 153‚Äì5. as detailed below. The equations below assume a beam with a circular cross-section at all values of ; this can be seen by noting that a single transverse dimension, , appears. Beams with elliptical cross-sections, or with waists at different positions in for the two transverse dimensions (astigmatic beams) can also be described as Gaussian beams, but with distinct values of and of the location for the two transverse dimensions and . Arbitrary solutions of the paraxial Helmholtz equation can be expressed as combinations of Hermite‚ÄìGaussian modes (whose amplitude profiles are separable in and using Cartesian coordinates) or similarly as combinations of Laguerre‚ÄìGaussian modes (whose amplitude profiles are separable in and using cylindrical coordinates).Siegman, p. 642.probably first considered by Goubau and Schwering (1961). At any point along the beam these modes include the same Gaussian factor as the fundamental Gaussian mode multiplying the additional geometrical factors for the specified mode. However different modes propagate with a different Gouy phase which is why the net transverse profile due to a superposition of modes evolves in , whereas the propagation of any single Hermite‚ÄìGaussian (or Laguerre‚ÄìGaussian) mode retains the same form along a beam. Although there are other possible modal decompositions, these families of solutions are the most useful for problems involving compact beams, that is, where the optical power is rather closely confined along an axis. Even when a laser is not operating in the fundamental Gaussian mode, its power will generally be found among the lowest-order modes using these decompositions, as the spatial extent of higher order modes will tend to exceed the bounds of a laser's resonator (cavity). \\"Gaussian beam\\" normally implies radiation confined to the fundamental (TEM00) Gaussian mode. Mathematical form Gaussian beam profile with . The Gaussian beam is a transverse electromagnetic (TEM) mode.Svelto, p. 158. The mathematical expression for the electric field amplitude is a solution to the paraxial Helmholtz equation. Assuming polarization in the direction and propagation in the direction, the electric field in phasor (complex) notation is given by: :{\\\\mathbf E(r,z)} = E_0 \\\\, \\\\hat{\\\\mathbf x} \\\\, \\\\frac{w_0}{w(z)} \\\\exp \\\\left( \\\\frac{-r^2}{w(z)^2}\\\\right ) \\\\exp \\\\left(\\\\\\\\! -i \\\\left(kz +k \\\\frac{r^2}{2R(z)} - \\\\psi(z) \\\\right) \\\\\\\\!\\\\right) where : is the radial distance from the center axis of the beam, : is the axial distance from the beam's focus (or \\"waist\\"), : is the imaginary unit, : is the wave number (in radians per meter) for a free- space wavelength , and is the index of refraction of the medium in which the beam propagates, :, the electric field amplitude (and phase) at the origin at time 0, : is the radius at which the field amplitudes fall to of their axial values (i.e., where the intensity values fall to of their axial values), at the plane along the beam, : is the waist radius, : is the radius of curvature of the beam's wavefronts at , and : is the Gouy phase at , an extra phase term beyond that attributable to the phase velocity of light. There is also an understood time dependence multiplying such phasor quantities; the actual field at a point in time and space is given by the real part of that complex quantity. Since this solution relies on the paraxial approximation, it is not accurate for very strongly diverging beams. The above form is valid in most practical cases, where . The corresponding intensity (or irradiance) distribution is given by : I(r,z) = { E(r,z)^2 \\\\over 2 \\\\eta } = I_0 \\\\left( \\\\frac{w_0}{w(z)} \\\\right)^2 \\\\exp \\\\left( \\\\frac{-2r^2}{w(z)^2}\\\\right), where the constant is the wave impedance of the medium in which the beam is propagating. For free space, ‚âà 377 Œ©. is the intensity at the center of the beam at its waist. If is the total power of the beam, :I_0 = {2P_0 \\\\over \\\\pi w_0^2}. =Evolving beam width= The Gaussian function has a diameter ( as used in the text) about 1.7 times the FWHM. At a position along the beam (measured from the focus), the spot size parameter is given by a hyperbolic relation: :w(z) = w_0 \\\\, \\\\sqrt{ 1+ {\\\\left( \\\\frac{z}{z_\\\\mathrm{R}} \\\\right)}^2 }, where :z_\\\\mathrm{R} = \\\\frac{\\\\pi w_0^2 n}{\\\\lambda} is called the Rayleigh range as further discussed below. The radius of the beam , at any position along the beam, is related to the full width at half maximum (FWHM) at that position according to: :w(z)={\\\\frac {\\\\text{FWHM}(z)}{\\\\sqrt {2\\\\ln2}}}. =Wavefront curvature= The curvature of the wavefronts is largest at the Rayleigh distance, , on either side of the waist, crossing zero at the waist itself. Beyond the Rayleigh distance, , it again decreases in magnitude, approaching zero as . The curvature is often expressed in terms of its reciprocal, , the radius of curvature; for a fundamental Gaussian beam the curvature at position is given by: :\\\\frac{1}{R(z)} = \\\\frac{z} {z^2 + z_\\\\mathrm{R}^2} , so the radius of curvature is :R(z) = z \\\\left[{ 1+ {\\\\left( \\\\frac{z_\\\\mathrm{R}}{z} \\\\right)}^2 } \\\\right]. Being the reciprocal of the curvature, the radius of curvature reverses sign and is infinite at the beam waist where the curvature goes through zero. =Gouy phase= The Gouy phase is a phase advance gradually acquired by a beam around the focal region. At position the Gouy phase of a fundamental Gaussian beam is given by :\\\\psi(z) = \\\\arctan \\\\left( \\\\frac{z}{z_\\\\mathrm{R}} \\\\right). Gouy phase. The Gouy phase results in an increase in the apparent wavelength near the waist (). Thus the phase velocity in that region formally exceeds the speed of light. That paradoxical behavior must be understood as a near-field phenomenon where the departure from the phase velocity of light (as would apply exactly to a plane wave) is very small except in the case of a beam with large numerical aperture, in which case the wavefronts' curvature (see previous section) changes substantially over the distance of a single wavelength. In all cases the wave equation is satisfied at every position. For a fundamental Gaussian beam, the Gouy phase results in a net phase discrepancy with respect to the speed of light amounting to radians (thus a phase reversal) as one moves from the far field on one side of the waist to the far field on the other side. This phase variation is not observable in most experiments. It is, however, of theoretical importance and takes on a greater range for higher-order Gaussian modes. =Elliptical and astigmatic beams= Many laser beams have an elliptical cross-section. Also common are beams with waist positions which are different for the two transverse dimensions, called astigmatic beams. These beams can be dealt with using the above two evolution equations, but with distinct values of each parameter for and and distinct definitions of the point. The Gouy phase is a single value calculated correctly by summing the contribution from each dimension, with a Gouy phase within the range contributed by each dimension. An elliptical beam will invert its ellipticity ratio as it propagates from the far field to the waist. The dimension which was the larger far from the waist, will be the smaller near the waist.  Beam parameters  The geometric dependence of the fields of a Gaussian beam are governed by the light's wavelength (in the dielectric medium, if not free space) and the following beam parameters, all of which are connected as detailed in the following sections. =Beam waist= Gaussian beam width as a function of the distance along the beam, which forms a hyperbola. : beam waist; : depth of focus; : Rayleigh range; : total angular spread The shape of a Gaussian beam of a given wavelength is governed solely by one parameter, the beam waist . This is a measure of the beam size at the point of its focus ( in the above equations) where the beam width (as defined above) is the smallest (and likewise where the intensity on-axis () is the largest). From this parameter the other parameters describing the beam geometry are determined. This includes the Rayleigh range and asymptotic beam divergence , as detailed below. =Rayleigh range and confocal parameter= The Rayleigh distance or Rayleigh range is determined given a Gaussian beam's waist size: :z_\\\\mathrm{R} = \\\\frac{\\\\pi w_0^2 n}{\\\\lambda}. Here is the wavelength of the light, is the index of refraction. At a distance from the waist equal to the Rayleigh range , the width of the beam is larger than it is at the focus where , the beam waist. That also implies that the on-axis () intensity there is one half of the peak intensity (at ). That point along the beam also happens to be where the wavefront curvature () is greatest. The distance between the two points is called the confocal parameter or depth of focus of the beam. =Beam divergence= Although the tails of a Gaussian function never actually reach zero, for the purposes of the following discussion the \\"edge\\" of a beam is considered to be the radius where . That is where the intensity has dropped to of its on-axis value. Now, for the parameter increases linearly with . This means that far from the waist, the beam \\"edge\\" (in the above sense) is cone-shaped. The angle between that cone (whose ) and the beam axis () defines the divergence of the beam: :\\\\theta = \\\\lim_{z\\\\rightarrow\\\\infty}\\\\arctan\\\\Big(\\\\frac{w(z)}{z}\\\\Big). In the paraxial case, as we have been considering, (in radians) is then approximately :\\\\theta = \\\\frac{\\\\lambda}{\\\\pi n w_0} where is the refractive index of the medium the beam propagates through, and is the free-space wavelength. The total angular spread of the diverging beam, or apex angle of the above-described cone, is then given by :\\\\Theta = 2 \\\\theta\\\\ . That cone then contains 86% of the Gaussian beam's total power. Because the divergence is inversely proportional to the spot size, for a given wavelength , a Gaussian beam that is focused to a small spot diverges rapidly as it propagates away from the focus. Conversely, to minimize the divergence of a laser beam in the far field (and increase its peak intensity at large distances) it must have a large cross-section () at the waist (and thus a large diameter where it is launched, since is never less than ). This relationship between beam width and divergence is a fundamental characteristic of diffraction, and of the Fourier transform which describes Fraunhofer diffraction. A beam with any specified amplitude profile also obeys this inverse relationship, but the fundamental Gaussian mode is a special case where the product of beam size at focus and far-field divergence is smaller than for any other case. Since the Gaussian beam model uses the paraxial approximation, it fails when wavefronts are tilted by more than about 30¬∞ from the axis of the beam.Siegman (1986) p. 630. From the above expression for divergence, this means the Gaussian beam model is only accurate for beams with waists larger than about . Laser beam quality is quantified by the beam parameter product (BPP). For a Gaussian beam, the BPP is the product of the beam's divergence and waist size . The BPP of a real beam is obtained by measuring the beam's minimum diameter and far-field divergence, and taking their product. The ratio of the BPP of the real beam to that of an ideal Gaussian beam at the same wavelength is known as (\\"M squared\\"). The for a Gaussian beam is one. All real laser beams have values greater than one, although very high quality beams can have values very close to one. The numerical aperture of a Gaussian beam is defined to be , where is the index of refraction of the medium through which the beam propagates. This means that the Rayleigh range is related to the numerical aperture by :z_\\\\mathrm{R} = n w_0 / \\\\mathrm{NA} . Power and intensity = Power through an aperture = With a beam centered on an aperture, the power passing through a circle of radius in the transverse plane at position isMelles Griot. Gaussian Beam Optics :P(r,z) = P_0 \\\\left[ 1 - e^{-2r^2 / w^2(z)} \\\\right], where :P_0 = { 1 \\\\over 2 } \\\\pi I_0 w_0^2 is the total power transmitted by the beam. For a circle of radius , the fraction of power transmitted through the circle is :{ P(z) \\\\over P_0 } = 1 - e^{-2} \\\\approx 0.865. Similarly, about 90% of the beam's power will flow through a circle of radius , 95% through a circle of radius , and 99% through a circle of radius . = Peak intensity = The peak intensity at an axial distance from the beam waist can be calculated as the limit of the enclosed power within a circle of radius , divided by the area of the circle as the circle shrinks: :I(0,z) = \\\\lim_{r\\\\to 0} \\\\frac {P_0 \\\\left[ 1 - e^{-2r^2 / w^2(z)} \\\\right]} {\\\\pi r^2} . The limit can be evaluated using L'H√¥pital's rule: :I(0,z) = \\\\frac{P_0}{\\\\pi} \\\\lim_{r\\\\to 0} \\\\frac { \\\\left[ -(-2)(2r) e^{-2r^2 / w^2(z)} \\\\right]} {w^2(z)(2r)} = {2P_0 \\\\over \\\\pi w^2(z)} . Complex beam parameter The spot size and curvature of a Gaussian beam as a function of along the beam can also be encoded in the complex beam parameter Siegman, pp. 638‚Äì40.Garg, pp. 165‚Äì168. given by: : q(z) = z + iz_\\\\mathrm{R} . Introducing this complication leads to a simplification of the Gaussian beam field equation as shown below. It can be seen that the reciprocal of contains the wavefront curvature and relative on-axis intensity in its real and imaginary parts, respectively: :{1 \\\\over q(z)} = {1 \\\\over z + iz_\\\\mathrm{R}} = {z \\\\over z^2 + z_\\\\mathrm{R}^2} - i {z_\\\\mathrm{R} \\\\over z^2 + z_\\\\mathrm{R}^2} = {1 \\\\over R(z)} - i {\\\\lambda \\\\over n \\\\pi w^2(z)} . The complex beam parameter simplifies the mathematical analysis of Gaussian beam propagation, and especially in the analysis of optical resonator cavities using ray transfer matrices. Then using this form, the earlier equation for the electric (or magnetic) field is greatly simplified. If we call the relative field strength of an elliptical Gaussian beam (with the elliptical axes in the and directions) then it can be separated in and according to: :u(x,y,z) = u_x(x,z)\\\\, u_y(y,z) , where :\\\\begin{align} u_x(x,z) &= \\\\frac{1}{\\\\sqrt \\\\exp\\\\left(-i k \\\\frac{x^2}{2 {q}_x(z)}\\\\right),  u_y(y,z) &= \\\\frac{1}{\\\\sqrt \\\\exp\\\\left(-i k \\\\frac{y^2}{2 {q}_y(z)}\\\\right), \\\\end{align} where and are the complex beam parameters in the and directions. For the common case of a circular beam profile, and , which yieldsSee Siegman (1986) p. 639. Eq. 29 :u(r,z) = \\\\frac{1}{q(z)}\\\\exp\\\\left( -i k\\\\frac{r^2}{2 q(z)}\\\\right) . Wave equation As a special case of electromagnetic radiation, Gaussian beams (and the higher-order Gaussian modes detailed below) are solutions to the wave equation for an electromagnetic field in free space or in a homogeneous dielectric medium,Svelto, pp. 148‚Äì9. obtained by combining Maxwell's equations for the curl of and the curl of , resulting in: : abla^2 U = \\\\frac{1}{c^2} \\\\frac{\\\\partial^2 U}{\\\\partial t^2}, where is the speed of light in the medium, and could either refer to the electric or magnetic field vector, as any specific solution for either determines the other. The Gaussian beam solution is valid only in the paraxial approximation, that is, where wave propagation is limited to directions within a small angle of an axis. Without loss of generality let us take that direction to be the direction in which case the solution can generally be written in terms of which has no time dependence and varies relatively smoothly in space, with the main variation spatially corresponding to the wavenumber in the direction: : U(x,y,z,t) = u(x,y,z) e^{-i(kz-\\\\omega t)} \\\\, \\\\hat{\\\\mathbf x} \\\\; . Using this form along with the paraxial approximation, can then be essentially neglected. Since solutions of the electromagnetic wave equation only hold for polarizations which are orthogonal to the direction of propagation (), we have without loss of generality considered the polarization to be in the direction so that we now solve a scalar equation for . Substituting this solution into the wave equation above yields the paraxial approximation to the scalar wave equation: :\\\\frac{\\\\partial^2 u}{\\\\partial x^2} + \\\\frac{\\\\partial^2 u}{\\\\partial y^2} = 2ik \\\\frac{\\\\partial u}{\\\\partial z}. It is noteworthy that in the Paul Dirac's light-cone coordinates, x^\\\\pm = \\\\frac{1}{\\\\sqrt{2}}(z\\\\pm ct) , the wave equation of abla^2 U = \\\\frac{1}{c^2} \\\\frac{\\\\partial^2 U}{\\\\partial t^2} converts to: : abla^2 U = 2\\\\frac{\\\\partial^2 U}{\\\\partial x^- \\\\partial x^+} . So for a wave in the form of U(x,y,x^+,x^-) = u(x,y,x^+) e^{ik x^-} \\\\, \\\\hat{\\\\mathbf x} \\\\; one gets the exact equation of :\\\\frac{\\\\partial^2 u}{\\\\partial x^2} + \\\\frac{\\\\partial^2 u}{\\\\partial y^2} = 2ik \\\\frac{\\\\partial u}{\\\\partial x^+} . The paraxial solutions, therefore, are turned exact in the light-cone coordinates. Gaussian beams of any beam waist satisfy this wave equation; this is most easily verified by expressing the wave at in terms of the complex beam parameter as defined above. There are many other solutions. As solutions to a linear system, any combination of solutions (using addition or multiplication by a constant) is also a solution. The fundamental Gaussian happens to be the one that minimizes the product of minimum spot size and far- field divergence, as noted above. In seeking paraxial solutions, and in particular ones that would describe laser radiation that is not in the fundamental Gaussian mode, we will look for families of solutions with gradually increasing products of their divergences and minimum spot sizes. Two important orthogonal decompositions of this sort are the Hermite‚ÄìGaussian or Laguerre-Gaussian modes, corresponding to rectangular and circular symmetry respectively, as detailed in the next section. With both of these, the fundamental Gaussian beam we have been considering is the lowest order mode. Higher-order modes = Hermite-Gaussian modes = Twelve Hermite-Gaussian modes It is possible to decompose a coherent paraxial beam using the orthogonal set of so-called Hermite-Gaussian modes, any of which are given by the product of a factor in and a factor in . Such a solution is possible due to the separability in and in the paraxial Helmholtz equation as written in Cartesian coordinates.Siegman (1986), p645, eq. 54 Thus given a mode of order referring to the and directions, the electric field amplitude at may be given by: : E(x,y,z) = u_l(x,z) \\\\, u_m(y,z) \\\\, \\\\exp(-ikz), where the factors for the and dependence are each given by: : u_J(x,z) = \\\\left(\\\\frac{\\\\sqrt{2/\\\\pi}}{ 2^J \\\\, J! \\\\; w_0}\\\\right)^{\\\\\\\\!\\\\\\\\!1/2} \\\\\\\\!\\\\\\\\! \\\\left( \\\\frac{{q}_0}{{q}(z)}\\\\right)^{\\\\\\\\!\\\\\\\\!1/2} \\\\\\\\!\\\\\\\\! \\\\left(- \\\\frac{{q}^\\\\ast(z)}{{q}(z)}\\\\right)^{\\\\\\\\!\\\\\\\\! J/2} \\\\\\\\!\\\\\\\\! H_J\\\\\\\\!\\\\left(\\\\frac{\\\\sqrt{2}x}{w(z)}\\\\right) \\\\, \\\\exp \\\\left(\\\\\\\\! -i \\\\frac{k x^2}{2 {q}(z)}\\\\right) , where we have employed the complex beam parameter (as defined above) for a beam of waist at from the focus. In this form, the first factor is just a normalizing constant to make the set of orthonormal. The second factor is an additional normalization dependent on which compensates for the expansion of the spatial extent of the mode according to (due to the last two factors). It also contains part of the Gouy phase. The third factor is a pure phase which enhances the Gouy phase shift for higher orders . The final two factors account for the spatial variation over (or ). The fourth factor is the Hermite polynomial of order (\\"physicists' form\\", i.e. ), while the fifth accounts for the Gaussian amplitude fall-off , although this isn't obvious using the complex in the exponent. Expansion of that exponential also produces a phase factor in which accounts for the wavefront curvature () at along the beam. Hermite-Gaussian modes are typically designated \\"TEMlm\\"; the fundamental Gaussian beam may thus be referred to as TEM00 (where TEM stands for Transverse electro-magnetic). Multiplying and to get the 2-D mode profile, and removing the normalization so that the leading factor is just called , we can write the mode in the more accessible form: :\\\\begin{align} E_{l,m}(x,y,z) =& E_0 \\\\frac{w_0}{w(z)} \\\\, H_l \\\\\\\\!\\\\Bigg(\\\\frac{\\\\sqrt{2} \\\\,x}{w(z)}\\\\Bigg) \\\\, H_m \\\\\\\\!\\\\Bigg(\\\\frac{\\\\sqrt{2} \\\\,y}{w(z)}\\\\Bigg) \\\\times  & \\\\exp \\\\Bigg( {-\\\\frac{x^2+y^2}{w^2(z)}} \\\\Bigg) \\\\exp \\\\Bigg( {-i\\\\frac{k(x^2+y^2)}{2R(z)}} \\\\Bigg) \\\\times  & \\\\exp \\\\big(i \\\\psi(z)\\\\big) \\\\exp(-ikz). \\\\end{align} In this form, the parameter , as before, determines the family of modes, in particular scaling the spatial extent of the fundamental mode's waist and all other mode patterns at . Given that , and have the same definitions as for the fundamental Gaussian beam described above. It can be seen that with we obtain the fundamental Gaussian beam described earlier (since ). The only specific difference in the and profiles at any are due to the Hermite polynomial factors for the order numbers and . However, there is a change in the evolution of the modes' Gouy phase over : : \\\\psi(z) = (N+1) \\\\, \\\\arctan \\\\left( \\\\frac{z}{z_\\\\mathrm{R}} \\\\right), where the combined order of the mode is defined as . While the Gouy phase shift for the fundamental (0,0) Gaussian mode only changes by radians over all of (and only by radians between ), this is increased by the factor for the higher order modes. Hermite Gaussian modes, with their rectangular symmetry, are especially suited for the modal analysis of radiation from lasers whose cavity design is asymmetric in a rectangular fashion. On the other hand, lasers and systems with circular symmetry can better be handled using the set of Laguerre-Gaussian modes introduced in the next section. = Laguerre-Gaussian modes = Beam profiles which are circularly symmetric (or lasers with cavities that are cylindrically symmetric) are often best solved using the Laguerre-Gaussian modal decomposition. These functions are written in cylindrical coordinates using generalized Laguerre polynomials. Each transverse mode is again labelled using two integers, in this case the radial index and the azimuthal index which can be positive or negative (or zero): :\\\\begin{align} {u}(r,\\\\phi,z)=&C;^{LG}_{lp}\\\\frac{w_0}{w(z)}\\\\left(\\\\frac{r \\\\sqrt{2}}{w(z)}\\\\right)^{\\\\\\\\! l} \\\\exp\\\\\\\\! \\\\left(\\\\\\\\! -\\\\frac{r^2}{w^2(z)}\\\\right)L_p^{l} \\\\\\\\! \\\\left(\\\\frac{2r^2}{w^2(z)}\\\\right) \\\\times  &\\\\exp \\\\\\\\! \\\\left(\\\\\\\\! - i k \\\\frac{r^2}{2 R(z)}\\\\right) \\\\exp(-i l \\\\phi) \\\\, \\\\exp(i \\\\psi(z)) , \\\\end{align} where are the generalized Laguerre polynomials. is a required normalization constant: :C^{LG}_{lp}=\\\\sqrt{\\\\frac{2 p!}{\\\\pi(p+l)!}} \\\\Rightarrow \\\\int_0^{2\\\\pi}d\\\\phi\\\\int_0^\\\\infty rdru(r,\\\\phi,z)^2=1. and have the same definitions as above. As with the higher-order Hermite-Gaussian modes the magnitude of the Laguerre-Gaussian modes' Gouy phase shift is exaggerated by the factor : :\\\\psi(z) = (N+1) \\\\, \\\\arctan \\\\left( \\\\frac{z}{z_\\\\mathrm{R}} \\\\right) , where in this case the combined mode number . As before, the transverse amplitude variations are contained in the last two factors on the upper line of the equation, which again includes the basic Gaussian drop off in but now multiplied by a Laguerre polynomial. The effect of the rotational mode number , in addition to affecting the Laguerre polynomial, is mainly contained in the phase factor , in which the beam profile is advanced (or retarded) by complete phases in one rotation around the beam (in ). This is an example of an optical vortex of topological charge , and can be associated with the orbital angular momentum of light in that mode. = Ince-Gaussian modes = In elliptic coordinates, one can write the higher-order modes using Ince polynomials. The even and odd Ince-Gaussian modes are given byBandres and Gutierrez-Vega (2004) : u_\\\\varepsilon \\\\left( \\\\xi ,\\\\eta ,z\\\\right) = \\\\frac{w_{0}}{w\\\\left( z\\\\right) }\\\\mathrm{C}_{p}^{m}\\\\left( i\\\\xi ,\\\\varepsilon \\\\right) \\\\mathrm{C} _{p}^{m}\\\\left( \\\\eta ,\\\\varepsilon \\\\right) \\\\exp \\\\left[ -ik\\\\frac{r^{2}}{ 2q\\\\left( z\\\\right) }-\\\\left( p+1\\\\right) \\\\zeta\\\\left( z\\\\right) \\\\right] , where and are the radial and angular elliptic coordinates defined by :\\\\begin{align} x &= \\\\sqrt{\\\\varepsilon /2}\\\\;w(z) \\\\cosh \\\\xi \\\\cos \\\\eta , y &= \\\\sqrt{\\\\varepsilon /2}\\\\;w(z) \\\\sinh \\\\xi \\\\sin \\\\eta . \\\\end{align} are the even Ince polynomials of order and degree where is the ellipticity parameter. The Hermite-Gaussian and Laguerre-Gaussian modes are a special case of the Ince-Gaussian modes for and respectively. = Hypergeometric-Gaussian modes = There is another important class of paraxial wave modes in cylindrical coordinates in which the complex amplitude is proportional to a confluent hypergeometric function. These modes have a singular phase profile and are eigenfunctions of the photon orbital angular momentum. Their intensity profiles are characterized by a single brilliant ring; like Laguerre‚ÄìGaussian modes, their intensities fall to zero at the center (on the optical axis) except for the fundamental (0,0) mode. A mode's complex amplitude can be written in terms of the normalized (dimensionless) radial coordinate and the normalized longitudinal coordinate as follows:Karimi et. al (2007) :\\\\begin{align} u_{{\\\\mathsf p}m}(\\\\rho,\\\\theta,\\\\Zeta)=& \\\\sqrt{\\\\frac{2^{\\\\pi\\\\Gamma({\\\\mathsf p}+m+1)}} \\\\; \\\\frac{\\\\Gamma(1+m+\\\\frac{2})}{\\\\Gamma(m+1)} \\\\,\\\\,i^{m+1} \\\\; \\\\; \\\\times  &\\\\Zeta^{\\\\frac{2}} \\\\; (\\\\Zeta+i)^{-(1+m+\\\\frac{2})} \\\\; \\\\rho^{m} \\\\; \\\\; \\\\times  &\\\\exp\\\\left(-\\\\frac{i\\\\rho^2}{(\\\\Zeta+i)}\\\\right) \\\\; e^{im\\\\phi} \\\\; {}_{1}F_{1}\\\\left(-\\\\frac{2}, m+1;\\\\frac{\\\\rho^2}{\\\\Zeta(\\\\Zeta+i)}\\\\right) \\\\end{align} where the rotational index is an integer, and {\\\\mathsf p}\\\\ge-m is real-valued, is the gamma function and is a confluent hypergeometric function. Some subfamilies of hypergeometric-Gaussian (HyGG) modes can be listed as the modified Bessel-Gaussian modes, the modified exponential Gaussian modes,Karimi et. al (2007) and the modified Laguerre‚ÄìGaussian modes. The set of hypergeometric-Gaussian modes is overcomplete and is not an orthogonal set of modes. In spite of its complicated field profile, HyGG modes have a very simple profile at the beam waist (): :u(\\\\rho,\\\\phi,0) \\\\propto \\\\rho^{{\\\\mathsf p}+m}e^{-\\\\rho^2+im\\\\phi}. See also * Bessel beam * Tophat beam * Laser beam profiler Notes References  * * Chapter 5, \\"Optical Beams,\\" pp. 267\\\\. * * Chapter 3, \\"Beam Optics,\\" pp. 80‚Äì107. * Chapter 16. * * External links * Gaussian Beam Optics Tutorial, Newport Category:Physical optics Category:Laser science Category:Electromagnetic radiation ","title":"Gaussian beam"},{"id":"41207","text":"An upturned vial of hair gel Silica gel A gel is a semi-solid that can have properties ranging from soft and weak to hard and tough. Gels are defined as a substantially dilute cross-linked system, which exhibits no flow when in the steady-state. A gel has been defined phenomenologically as a soft, solid or solid-like material consisting of two or more components, one of which is a liquid, present in substantial quantity. By weight, gels are mostly liquid, yet they behave like solids due to a three-dimensional cross-linked network within the liquid. It is the crosslinking within the fluid that gives a gel its structure (hardness) and contributes to the adhesive stick (tack). In this way, gels are a dispersion of molecules of a liquid within a solid medium. The word gel was coined by 19th-century Scottish chemist Thomas Graham by clipping from gelatine. The process of forming a gel is called gelation.  IUPAC definition  Composition Gels consist of a solid three-dimensional network that spans the volume of a liquid medium and ensnares it through surface tension effects. This internal network structure may result from physical bonds (physical gels) or chemical bonds (chemical gels), as well as crystallites or other junctions that remain intact within the extending fluid. Virtually any fluid can be used as an extender including water (hydrogels), oil, and air (aerogel). Both by weight and volume, gels are mostly fluid in composition and thus exhibit densities similar to those of their constituent liquids. Edible jelly is a common example of a hydrogel and has approximately the density of water. =Polyionic polymers= Polyionic polymers are polymers with an ionic functional group. The ionic charges prevent the formation of tightly coiled polymer chains. This allows them to contribute more to viscosity in their stretched state, because the stretched-out polymer takes up more space. This is also the reason gel hardens. See polyelectrolyte for more information. Types =Hydrogels= Hydrogel of a superabsorbent polymer A hydrogel is a network of polymer chains that are hydrophilic, sometimes found as a colloidal gel in which water is the dispersion medium. A three- dimensional solid results from the hydrophilic polymer chains being held together by cross-links. Because of the inherent cross-links, the structural integrity of the hydrogel network does not dissolve from the high concentration of water. Hydrogels are highly absorbent (they can contain over 90% water) natural or synthetic polymeric networks. Hydrogels also possess a degree of flexibility very similar to natural tissue, due to their significant water content. As responsive \\"smart materials,\\" hydrogels can encapsulate chemical systems which upon stimulation by external factors such as a change of pH may cause specific compounds such as glucose to be liberated to the environment, in most cases by a gel-sol transition to the liquid state. Chemomechanical polymers are mostly also hydrogels, which upon stimulation change their volume and can serve as actuators or sensors. The first appearance of the term 'hydrogel' in the literature was in 1894. =Organogels= An organogel is a non-crystalline, non-glassy thermoreversible (thermoplastic) solid material composed of a liquid organic phase entrapped in a three-dimensionally cross-linked network. The liquid can be, for example, an organic solvent, mineral oil, or vegetable oil. The solubility and particle dimensions of the structurant are important characteristics for the elastic properties and firmness of the organogel. Often, these systems are based on self-assembly of the structurant molecules.Terech P. (1997) \\"Low-molecular weight organogelators\\", pp. 208‚Äì268 in: Robb I.D. (ed.) Specialist surfactants. Glasgow: Blackie Academic and Professional, . (An example of formation of an undesired thermoreversible network is the occurrence of wax crystallization in petroleum.) Organogels have potential for use in a number of applications, such as in pharmaceuticals, cosmetics, art conservation, and food. =Xerogels= A xerogel is a solid formed from a gel by drying with unhindered shrinkage. Xerogels usually retain high porosity (15‚Äì50%) and enormous surface area (150‚Äì900 m2/g), along with very small pore size (1‚Äì10 nm). When solvent removal occurs under supercritical conditions, the network does not shrink and a highly porous, low-density material known as an aerogel is produced. Heat treatment of a xerogel at elevated temperature produces viscous sintering (shrinkage of the xerogel due to a small amount of viscous flow) which results in a denser and more robust solid, the density and porosity achieved depend on the sintering conditions. = Nanocomposite hydrogels = Nanocomposite hydrogels or hybrid hydrogels, are highly hydrated polymeric networks, either physically or covalently crosslinked with each other and/or with nanoparticles or nanostructures. Nanocomposite hydrogels can mimic native tissue properties, structure and microenvironment due to their hydrated and interconnected porous structure. A wide range of nanoparticles, such as carbon-based, polymeric, ceramic, and metallic nanomaterials can be incorporated within the hydrogel structure to obtain nanocomposites with tailored functionality. Nanocomposite hydrogels can be engineered to possess superior physical, chemical, electrical, thermal, and biological properties. Properties Many gels display thixotropy ‚Äì they become fluid when agitated, but resolidify when resting. In general, gels are apparently solid, jelly-like materials. It is a type of non-Newtonian fluid. By replacing the liquid with gas it is possible to prepare aerogels, materials with exceptional properties including very low density, high specific surface areas, and excellent thermal insulation properties. Animal-produced gels Some species secrete gels that are effective in parasite control. For example, the long-finned pilot whale secretes an enzymatic gel that rests on the outer surface of this animal and helps prevent other organisms from establishing colonies on the surface of these whales' bodies. Hydrogels existing naturally in the body include mucus, the vitreous humor of the eye, cartilage, tendons and blood clots. Their viscoelastic nature results in the soft tissue component of the body, disparate from the mineral-based hard tissue of the skeletal system. Researchers are actively developing synthetically derived tissue replacement technologies derived from hydrogels, for both temporary implants (degradable) and permanent implants (non-degradable). A review article on the subject discusses the use of hydrogels for nucleus pulposus replacement, cartilage replacement, and synthetic tissue models. Applications Many substances can form gels when a suitable thickener or gelling agent is added to their formula. This approach is common in manufacture of wide range of products, from foods to paints and adhesives. In fiber optics communications, a soft gel resembling hair gel in viscosity is used to fill the plastic tubes containing the fibers. The main purpose of the gel is to prevent water intrusion if the buffer tube is breached, but the gel also buffers the fibers against mechanical damage when the tube is bent around corners during installation, or flexed. Additionally, the gel acts as a processing aid when the cable is being constructed, keeping the fibers central whilst the tube material is extruded around it.  See also  * 2-Acrylamido-2-methylpropane sulfonic acid * Agarose gel electrophoresis * Food rheology * Gel electrophoresis * Gel filtration chromatography *Gel pack * Gel permeation chromatography * Hydrocolloid * Ouchterlony double immunodiffusion * Paste (rheology) * Polyacrylamide gel electrophoresis * Radial immunodiffusion * Silicone gel * Two-dimensional gel electrophoresis * Void (composites)  References   External links  * Category:Physical chemistry Category:Drug delivery devices Category:Dosage forms Category:Colloids Category:Articles containing video clips ","title":"Gel"},{"id":"41210","text":"Two geostationary satellites in the same orbit inclinations to the Equator are visible above this line. The satellites are pinpoint, while stars have created small trails due to Earth's rotation. A geostationary orbit, also referred to as a geosynchronous equatorial orbitGeostationary orbit and Geosynchronous (equatorial) orbit are used somewhat interchangeably in sources. (GEO), is a circular geosynchronous orbit above Earth's equator and following the direction of Earth's rotation. An object in such an orbit has an orbital period equal to the Earth's rotational period, one sidereal day, and so to ground observers it appears motionless, in a fixed position in the sky. The concept of a geostationary orbit was popularised by the science fiction writer Arthur C. Clarke in the 1940s as a way to revolutionise telecommunications, and the first satellite to be placed in this kind of orbit was launched in 1963. Communications satellites are often placed in a geostationary orbit so that Earth-based satellite antennas (located on Earth) do not have to rotate to track them but can be pointed permanently at the position in the sky where the satellites are located. Weather satellites are also placed in this orbit for real-time monitoring and data collection, and navigation satellites to provide a known calibration point and enhance GPS accuracy. Geostationary satellites are launched via a temporary orbit, and placed in a slot above a particular point on the Earth's surface. The orbit requires some stationkeeping to keep its position, and modern retired satellites are placed in a higher graveyard orbit to avoid collisions.  History  Syncom 2, the first geosynchronous satellite The first appearance of a geostationary orbit in popular literature was in October 1942, in the first Venus Equilateral story by George O. Smith,\\"(Korvus's message is sent) to a small, squat building at the outskirts of Northern Landing. It was hurled at the sky. ... It ... arrived at the relay station tired and worn, ... when it reached a space station only five hundred miles above the city of North Landing.\\" but Smith did not go into details. British science fiction author Arthur C. Clarke popularised and expanded the concept in a 1945 paper entitled Extra- Terrestrial Relays ‚Äì Can Rocket Stations Give Worldwide Radio Coverage?, published in Wireless World magazine. Clarke acknowledged the connection in his introduction to The Complete Venus Equilateral.\\"It is therefore quite possible that these stories influenced me subconsciously when ... I worked out the principles of synchronous communications satellites ...\\", The orbit, which Clarke first described as useful for broadcast and relay communications satellites, is sometimes called the Clarke Orbit. Similarly, the collection of artificial satellites in this orbit is known as the Clarke Belt. In technical terminology the orbit is referred to as either a geostationary or geosynchronous equatorial orbit, with the terms used somewhat interchangeably. The first geostationary satellite was designed by Harold Rosen while he was working at Hughes Aircraft in 1959. Inspired by Sputnik 1, he wanted to use a geostationary satellite to globalise communications. Telecommunications between the US and Europe was then possible between just 136 people at a time, and reliant on high frequency radios and an undersea cable. Conventional wisdom at the time was that it would require too much rocket power to place a satellite in a geostationary orbit and it would not survive long enough to justify the expense, so early efforts were put towards constellations of satellites in low or medium Earth orbit. The first of these were the passive Echo balloon satellites in 1960, followed by Telstar 1 in 1962. Although these projects had difficulties with signal strength and tracking, that could be solved through geostationary satellites, the concept was seen as impractical, so Hughes often withheld funds and support. By 1961, Rosen and his team had produced a cylindrical prototype with a diameter of , height of , weighing , light and small enough to be placed into orbit. It was spin stabilised with a dipole antenna producing a pancake shaped waveform. In August 1961, they were contracted to begin building the real satellite. They lost Syncom 1 to electronics failure, but Syncom 2 was successfully placed into a geosynchronous orbit in 1963. Although its inclined orbit still required moving antennas, it was able to relay TV transmissions, and allowed for US President John F. Kennedy to phone Nigerian prime minister Abubakar Tafawa Balewa from a ship on August 23, 1963. The first satellite placed in a geostationary orbit was Syncom 3, which was launched by a Delta D rocket in 1964. With its increased bandwidth, this satellite was able to transmit live coverage of the Summer Olympics from Japan to America. Geostationary orbits have been in common use ever since, in particular for satellite television. Today there are hundreds of geostationary satellites providing remote sensing and communications. Although most populated land locations on the planet now have terrestrial communications facilities (microwave, fiber-optic), with telephone access covering 96% of the population and internet access 90%, some rural and remote areas in developed countries are still reliant on satellite communications.  Uses  Most commercial communications satellites, broadcast satellites and SBAS satellites operate in geostationary orbits. = Communications = Geostationary communication satellites are useful because they are visible from a large area of the earth's surface, extending 81¬∞ away in both latitude and longitude. They appear stationary in the sky, which eliminates the need for ground stations to have movable antennas. This means that Earth-based observers can erect small, cheap and stationary antennas that are always directed at the desired satellite. However, latency becomes significant as it takes about 240ms for a signal to pass from a ground based transmitter on the equator to the satellite and back again. This delay presents problems for latency-sensitive applications such as voice communication, so geostationary communication satellites are primarily used for unidirectional entertainment and applications where low latency alternatives are not available. Geostationary satellites are directly overhead at the equator and appear lower in the sky to an observer nearer the poles. As the observer's latitude increases, communication becomes more difficult due to factors such as atmospheric refraction, Earth's thermal emission, line-of- sight obstructions, and signal reflections from the ground or nearby structures. At latitudes above about 81¬∞, geostationary satellites are below the horizon and cannot be seen at all. Because of this, some Russian communication satellites have used elliptical Molniya and Tundra orbits, which have excellent visibility at high latitudes. = Meteorology = A worldwide network of operational geostationary meteorological satellites is used to provide visible and infrared images of Earth's surface and atmosphere for weather observation, oceanography, and atmospheric tracking. As of 2019 there are 19 satellites in either operation or stand-by. These satellite systems include: * the United States' GOES series, operated by NOAA * the Meteosat series, launched by the European Space Agency and operated by the European Weather Satellite Organization, EUMETSAT * the Republic of Korea COMS-1 and GK-2A multi mission satellites. * the Russian Elektro-L satellites * the Japanese Himawari series * Chinese Fengyun series * India's INSAT series These satellites typically captures images in the visual and infrared spectrum with a spatial resolution between 0.5 and 4 square kilometres. The coverage is typically 70¬∞, and in some cases less. Geostationary satellite imagery has been used for tracking volcanic ash, measuring cloud top temperatures and water vapour, oceanography, measuring land temperature and vegetation coverage, facilitating cyclone path prediction, and providing real time cloud coverage and other tracking data. Some information has been incorporated into meteorological prediction models, but due to their wide field of view, full- time monitoring and lower resolution, geostationary weather satellite images are primarily used for short-term and real-time forecasting. =Navigation= Service areas of satellite-based augmentation systems (SBAS). Geostationary satellites can be used to augment GNSS systems by relaying clock, ephemeris and ionospheric error corrections (calculated from ground stations of a known position) and providing an additional reference signal. This improves position accuracy from approximately 5m to 1m or less. Past and current navigation systems that use geostationary satellites include: * The Wide Area Augmentation System (WAAS), operated by the United States Federal Aviation Administration (FAA); * The European Geostationary Navigation Overlay Service (EGNOS), operated by the ESSP (on behalf of EU's GSA); * The Multi-functional Satellite Augmentation System (MSAS), operated by Japan's Ministry of Land, Infrastructure and Transport Japan Civil Aviation Bureau (JCAB); * The GPS Aided Geo Augmented Navigation (GAGAN) system being operated by India. * The commercial StarFire navigation system, operated by John Deere and C-Nav Positioning Solutions (Oceaneering); * The commercial Starfix DGPS System and OmniSTAR system, operated by Fugro. Implementation =Launch= Geostationary satellites are launched to the east into a prograde orbit that matches the rotation rate of the equator. The smallest inclination that a satellite can be launched into is that of the launch site's latitude, so launching the satellite from close to the equator limits the amount of inclination change needed later. Additionally, launching from close to the equator allows the speed of the Earth's rotation to give the satellite a boost. A launch site should have water or deserts to the east, so any failed rockets do not fall on a populated area. Most launch vehicles place geostationary satellites directly into a geostationary transfer orbit (GTO), an elliptical orbit with an apogee at GEO height and a low perigee. On-board satellite propulsion is then used to raise the perigee, circularise and reach GEO. = Orbit allocation = Satellites in geostationary orbit must all occupy a single ring above the equator. The requirement to space these satellites apart, to avoid harmful radio-frequency interference during operations, means that there are a limited number of orbital slots available, and thus only a limited number of satellites can be operated in geostationary orbit. This has led to conflict between different countries wishing access to the same orbital slots (countries near the same longitude but differing latitudes) and radio frequencies. These disputes are addressed through the International Telecommunication Union's allocation mechanism under the Radio Regulations. In the 1976 Bogot√° Declaration, eight countries located on the Earth's equator claimed sovereignty over the geostationary orbits above their territory, but the claims gained no international recognition. =Statite proposal= A statite is a hypothetical satellite that uses radiation pressure from the sun against a solar sail to modify its orbit. It would hold its location over the dark side of the Earth at a latitude of approximately 30 degrees. A statite is stationary relative to the Earth and Sun system rather than compared to surface of the Earth, and could ease congestion in the geostationary ring.  Retired satellites  Geostationary satellites require some station keeping to keep their position, and once they run out of thruster fuel they are generally retired. The transponders and other onboard systems often outlive the thruster fuel and by allowing the satellite to move naturally into an inclined geosynchronous orbit some satellites can remain in use, or else be elevated to a graveyard orbit. This process is becoming increasingly regulated and satellites must have a 90% chance of moving over 200 km above the geostationary belt at end of life. = Space debris = A computer-generated image of space debris. Two debris fields are shown: around geostationary space and low Earth orbit. Space debris at geostationary orbits typically has a lower collision speed than at LEO since all GEO satellites orbit in the same plane, altitude and speed; however, the presence of satellites in eccentric orbits allows for collisions at up to 4 km/s. Although a collision is comparatively unlikely, GEO satellites have a limited ability to avoid any debris. Debris less than 10 cm in diameter cannot be seen from the Earth, making it difficult to assess their prevalence. Despite efforts to reduce risk, spacecraft collisions have occurred. The European Space Agency telecom satellite Olympus-1 was struck by a meteoroid on August 11, 1993 and eventually moved to a graveyard orbit,\\"The Olympus failure\\" ESA press release, August 26, 1993. and in 2006 the Russian Express-AM11 communications satellite was struck by an unknown object and rendered inoperable,\\"Notification for Express-AM11 satellite users in connection with the spacecraft failure\\" Russian Satellite Communications Company, April 19, 2006. although its engineers had enough contact time with the satellite to send it into a graveyard orbit. In 2017 both AMC-9 and Telkom-1 broke apart from an unknown cause. Properties A typical geostationary orbit has the following properties: * Inclination: 0¬∞ * Period: 1436 minutes (one sidereal day) * Eccentricity: 0 * Argument of perigee: undefined * Semi-major axis: 42,164 km =Inclination= An inclination of zero ensures that the orbit remains over the equator at all times, making it stationary with respect to latitude from the point of view of a ground observer (and in the ECEF reference frame). =Period= The orbital period is equal to exactly one sidereal day. This means that the satellite will return to the same point above the Earth's surface every (sidereal) day, regardless of other orbital properties. For a geostationary orbit in particular, it ensures that it holds the same longitude over time. This orbital period, T, is directly related to the semi-major axis of the orbit through the formula: : T = 2\\\\pi\\\\sqrt{a^3 \\\\over \\\\mu} where: : is the length of the orbit's semi-major axis : \\\\mu is the standard gravitational parameter of the central body =Eccentricity= The eccentricity is zero, which produces a circular orbit. This ensures that the satellite does not move closer or further away from the Earth, which would cause it to track backwards and forwards across the sky. = Orbital stability = A geostationary orbit can be achieved only at an altitude very close to and directly above the equator. This equates to an orbital speed of and an orbital period of 1,436 minutes, one sidereal day. This ensures that the satellite will match the Earth's rotational period and has a stationary footprint on the ground. All geostationary satellites have to be located on this ring. A combination of lunar gravity, solar gravity, and the flattening of the Earth at its poles causes a precession motion of the orbital plane of any geostationary object, with an orbital period of about 53 years and an initial inclination gradient of about 0.85¬∞ per year, achieving a maximal inclination of 15¬∞ after 26.5 years. To correct for this perturbation, regular orbital stationkeeping maneuvers are necessary, amounting to a delta-v of approximately 50 m/s per year. A second effect to be taken into account is the longitudinal drift, caused by the asymmetry of the Earth ‚Äì the equator is slightly elliptical. There are two stable equilibrium points (at 75.3¬∞E and 108¬∞W) and two corresponding unstable points (at 165.3¬∞E and 14.7¬∞W). Any geostationary object placed between the equilibrium points would (without any action) be slowly accelerated towards the stable equilibrium position, causing a periodic longitude variation. The correction of this effect requires station-keeping maneuvers with a maximal delta-v of about 2 m/s per year, depending on the desired longitude. Solar wind and radiation pressure also exert small forces on satellites: over time, these cause them to slowly drift away from their prescribed orbits. In the absence of servicing missions from the Earth or a renewable propulsion method, the consumption of thruster propellant for station-keeping places a limitation on the lifetime of the satellite. Hall-effect thrusters, which are currently in use, have the potential to prolong the service life of a satellite by providing high- efficiency electric propulsion. = Derivation of geostationary altitude = Comparison of geostationary Earth orbit with GPS, GLONASS, Galileo and Compass (medium Earth orbit) satellite navigation system orbits with the International Space Station, Hubble Space Telescope and Iridium constellation orbits, and the nominal size of the Earth.Orbital periods and speeds are calculated using the relations 4œÄ2R3 = T2GM and V2R = GM, where R = radius of orbit in metres, T = orbital period in seconds, V = orbital speed in m/s, G = gravitational constant ‚âà 6.673 Nm2/kg2, M = mass of Earth ‚âà 5.98 kg. The Moon's orbit is around 9 times larger (in radius and length) than geostationary orbit.The Moon's orbit is not perfectly circular, and is approximately 8.6 times further away from the Earth than the geostationary ring when the Moon is at perigee (363 104 km √∑ 42 164 km) and 9.6 times further away when the Moon is at apogee (405,696 km √∑ 42,164 km). For circular orbits around a body, the centripetal force required to maintain the orbit (Fc) is equal to the gravitational force acting on the satellite (Fg): : F_c = F_g From Isaac Newton's Universal law of gravitation, :F_g = G \\\\frac{M_E m_s}{r^2}, where Fg is the gravitational force acting between two objects, ME is the mass of the Earth, , ms is the mass of the satellite, r is the distance between the centers of their masses, and G is the gravitational constant, . The magnitude of the acceleration (a) of a body moving in a circle is given by: :a = \\\\frac{v^2}{r} where v is the magnitude of the velocity (i.e. the speed) of the satellite. From Newton's Second law of Motion, the centripetal force Fc is given by: :F_c = m_s\\\\frac{v^2}{r}. As Fc = Fg, :m_s\\\\frac{v^2}{r} = G \\\\frac{M_E m_s}{r^2}, so that :{v^2} = G \\\\frac{M_E}{r} Replacing v with the equation for the speed of an object moving around a circle produces: :\\\\left (\\\\frac{2\\\\pi r}{T}\\\\right)^2 = G \\\\frac{M_E}{r} where T is the orbital period (i.e. one sidereal day), and is equal to .Edited by P. Kenneth Seidelmann, \\"Explanatory Supplement to the Astronomical Almanac\\", University Science Books,1992, p. 700. This gives an equation for r: : r = \\\\sqrt[3]{\\\\frac{G{M_E}T^2}{4\\\\pi^2}} The product GME is known with much greater precision than either factor alone; it is known as the geocentric gravitational constant Œº = . Hence : \\\\mathbf r = \\\\sqrt[3]{\\\\frac{ \\\\boldsymbol{\\\\mu} \\\\mathbf T^2}{\\\\mathbf 4\\\\boldsymbol{\\\\pi}^2}} The resulting orbital radius is . Subtracting the Earth's equatorial radius, , gives the altitude of . The orbital speed is calculated by multiplying the angular speed by the orbital radius: : v = \\\\omega r \\\\quad \\\\approx 3074.6~\\\\text{m/s} =Mars= By the same method, we can determine the orbital altitude for any similar pair of bodies, including the areostationary orbit of an object in relation to Mars, if it is assumed that it is spherical (which it is not). The gravitational constant GM (Œº) for Mars has the value of 42,830 km3s‚àí2, its equatorial radius is 3389.50 km and the known rotational period (T) of the planet is 1.02595676 Earth days (88,642.66 seconds). Using these values, Mars' orbital altitude is equal to 17,039 km.  See also  * List of orbits * List of satellites in geosynchronous orbit * Orbital stationkeeping * Space elevator, which ultimately reaches a geostationary orbit Notes  References  External links * How to get a satellite to geostationary orbit * Orbital Mechanics (Rocket and Space Technology) * List of satellites in geostationary orbit * Clarke Belt Snapshot Calculator * 3D Real Time Satellite Tracking * Geostationary satellite orbit overview * Daily animation of the Earth, made by geostationary satellite 'Electro L' photos Satellite shoots 48 images of the planet every day. * Orbital Mechanics for Engineering Students Category:Astrodynamics Category:Earth orbits * ","title":"Geostationary orbit"},{"id":"41211","text":"In fiber optics, a graded index is an optical fiber whose core has a refractive index that decreases with increasing radial distance from the optical axis of the fiber. Because parts of the core closer to the fiber axis have a higher refractive index than the parts near the cladding, light rays follow sinusoidal paths down the fiber. The most common refractive index profile for a graded-index fiber is very nearly parabolic. The parabolic profile results in continual refocusing of the rays in the core, and minimizes modal dispersion. Multi-mode optical fiber can be built with either graded index or step index. The advantage of the multi-mode graded index compared to the multi-mode step index is the considerable decrease in modal dispersion. Modal dispersion can be further decreased by selecting a smaller core size (less than 5-10Œºm) and forming a single mode step index fiber. This type of fiber is normalized by the International Telecommunications Union ITU-T at recommendation G.651.1. Pulse dispersion Pulse dispersion in a graded index optical fiber is given by \\\\mathrm{Pulse~dispersion} = \\\\frac{k \\\\delta n\\\\ n_1\\\\ l}{c} \\\\,\\\\\\\\!, where \\\\delta n\\\\,\\\\\\\\! is the difference in refractive indices of core and cladding, n_1\\\\,\\\\\\\\! is the refractive index of the cladding, l\\\\,\\\\\\\\! is the length of the fiber taken for observing the pulse dispersion, c \\\\approx 3\\\\times 10^8~\\\\mathrm{m/s}\\\\,\\\\\\\\! is the speed of light, and k\\\\,\\\\\\\\! is the constant of graded index profile. References * Category:Optical fiber ","title":"Graded-index fiber"},{"id":"41212","text":"In telecommunication engineering, and in particular teletraffic engineering, the quality of voice service is specified by two measures: the grade of service (GoS) and the quality of service (QoS). Grade of service is the probability of a call in a circuit group being blocked or delayed for more than a specified interval, expressed as a vulgar fraction or decimal fraction. This is always with reference to the busy hour when the traffic intensity is the greatest. Grade of service may be viewed independently from the perspective of incoming versus outgoing calls, and is not necessarily equal in each direction or between different source-destination pairs. \\"Grade of Service\\" sometimes means a measure of inbound call center traffic to verify adherence to conditions to measure the success of customers served. On the other hand, the quality of service which a single circuit is designed or conditioned to provide, e.g. voice grade or program grade is called the quality of service. Quality criteria for such circuits may include equalization for amplitude over a specified band of frequencies, or in the case of digital data transported via analogue circuits, may include equalization for phase. Criteria for mobile quality of service in cellular telephone circuits include the probability of abnormal termination of the call. What is Grade of Service and how is it measured? When a user attempts to make a telephone call, the routing equipment handling the call has to determine whether to accept the call, reroute the call to alternative equipment, or reject the call entirely. Rejected calls occur as a result of heavy traffic loads (congestion) on the system and can result in the call either being delayed or lost. If a call is delayed, the user simply has to wait for the traffic to decrease, however if a call is lost then it is removed from the system.Kennedy I., Lost Call Theory, Lecture Notes, ELEN5007 - Teletraffic Engineering, School of Electrical and Information Engineering, University of the Witwatersrand, 2005 The Grade of Service is one aspect of the quality a customer can expect to experience when making a telephone call.Peuhkuri M., IP Quality of Service, Helsinki University of Technology, Laboratory of Telecommunications Technology, 1999. In a Loss System, the Grade of Service is described as that proportion of calls that are lost due to congestion in the busy hour.Farr R.E., Telecommunications Traffic, Tariffs and Costs - An Introduction For Managers, Peter Peregrinus, 1988. For a Lost Call system, the Grade of Service can be measured using Equation 1.Flood, J.E., Telecommunications Switching, Traffic and Networks, Chapter 4: Telecommunications Traffic, New York: Prentice-Hall, 1998. :\\\\mbox{Grade of Service}=\\\\frac{\\\\mbox{number of blocked calls}}{\\\\mbox{total offered calls}}\\\\qquad(1) For a delayed call system, the Grade of Service is measured using three separate terms: *The mean delay t_d - Describes the average time a user spends waiting for a connection if their call is delayed. *The mean delay t_o - Describes the average time a user spends waiting for a connection whether or not their call is delayed. *The probability that a user may be delayed longer than time t while waiting for a connection. Time t is chosen by the telecommunications service provider so that they can measure whether their services conform to a set Grade of Service. * Where and when is Grade of Service measured? The Grade of Service can be measured using different sections of a network. When a call is routed from one end to another, it will pass through several exchanges. If the Grade of Service is calculated based on the number of calls rejected by the final circuit group, then the Grade of Service is determined by the final circuit group blocking criteria. If the Grade of Service is calculated based on the number of rejected calls between exchanges, then the Grade of Service is determined by the exchange-to-exchange blocking criteria. The Grade of Service should be calculated using both the access networks and the core networks as it is these networks that allow a user to complete an end-to-end connection. Furthermore, the Grade of Service should be calculated from the average of the busy hour traffic intensities of the 30 busiest traffic days of the year. This will cater for most scenarios as the traffic intensity will seldom exceed the reference level. The grade of service is a measure of the ability of a user to access a trunk system during the busiest hour. The busy is based upon customer demand at the busiest hour during a week month or year. Class of Service Different telecommunications applications require different Qualities of Service. For example, if a telecommunications service provider decides to offer different qualities of voice connection, then a premium voice connection will require a better connection quality compared to an ordinary voice connection. Thus different Qualities of Service are appropriate, depending on the intended use. To help telecommunications service providers to market their different services, each service is placed into a specific class. Each Class of Service determines the level of service required. To identify the Class of Service for a specific service, the network‚Äôs switches and routers examine the call based on several factors. Such factors can include: *The type of service and priority due to precedence *The identity of the initiating party *The identity of the recipient party Quality of Service in broadband networks In broadband networks, the Quality of Service is measured using two criteria. The first criterion is the probability of packet losses or delays in already accepted calls. The second criterion refers to the probability that a new incoming call will be rejected or blocked. To avoid the former, broadband networks limit the number of active calls so that packets from established calls will not be lost due to new calls arriving. As in circuit-switched networks, the Grade of Service can be calculated for individual switches or for the whole network.Ritter, M., Phuoc, P., Multi-Rate Models for Dimensioning and Performance Evaluation of ATM Networks, COST 242, Institute of Computer Science, University of W√ºrzburg, June 1994 Maintaining a Grade of Service The telecommunications provider is usually aware of the required Grade of Service for a particular product. To achieve and maintain a given Grade of Service, the operator must ensure that sufficient telecommunications circuits or routes are available to meet a specific level of demand. It should also be kept in mind that too many circuits will create a situation where the operator is providing excess capacity which may never be used, or at the very least may be severely underutilized. This adds costs which must be borne by other parts of the network. To determine the correct number of circuits that are required, telecommunications service providers make use of Traffic Tables. An example of a Traffic Table can be viewed in Figure 1. It follows that in order for a telecommunications network to continue to offer a given Grade of Service, the number of circuits provided in a circuit group must increase (non-linearly) if the traffic intensity increases. Erlang's lost call assumptions To calculate the Grade of Service of a specified group of circuits or routes, Agner Krarup Erlang used a set of assumptions that relied on the network losing calls when all circuits in a group were busy. These assumptions are: *All traffic through the network is pure-chance traffic, i.e. all call arrivals and terminations are independent random events *There is statistical equilibrium, i.e., the average number of calls does not change *Full availability of the network, i.e., every outlet from a switch is accessible from every inlet *Any call that encounters congestion is immediately lost. From these assumptions Erlang developed the Erlang-B formula which describes the probability of congestion in a circuit group. The probability of congestion gives the Grade of Service experienced. Calculating the Grade of Service To determine the Grade of Service of a network when the traffic load and number of circuits are known, telecommunications network operators make use of Equation 2, which is the Erlang-B equation. :\\\\mbox{Grade of Service}=\\\\frac{\\\\left(\\\\frac{A^N}{N!}\\\\right)}{\\\\left(\\\\sum_{k=0}^N\\\\frac{A^k}{k!}\\\\right)}\\\\qquad(2) A = Expected traffic intensity in Erlangs, N = Number of circuits in group. This equation allows operators to determine whether each of their circuit groups meet the required Grade of Service, simply by monitoring the reference traffic intensity. (For delay networks, the Erlang-C formula allows network operators to determine the probability of delay depending on peak traffic and the number of circuits.) References * Category:Telecommunications engineering Category:Teletraffic ","title":"Grade of service"},{"id":"41214","text":"In ISO/IEC 646 (commonly known as ASCII) and related standards including ISO 8859 and Unicode, a graphic character is any character intended to be written, printed, or otherwise displayed in a form that can be read by humans. In other words, it is any encoded character that is associated with one or more glyphs. ISO/IEC 646 In ISO 646, graphic characters are contained in rows 2 through 7 of the code table. However, two of the characters in these rows, namely the space character SP at row 2 column 0 and the delete character DEL (also called the rubout character) at row 7 column 15, require special mention. The space is considered to be both a graphic character and a control character in ISO 646. It can have a visible form, and also a control function (moving the print head). The delete character is strictly a control character, not a graphic character. This is true not only in ISO 646, but also in all related standards including Unicode. However, many modern character sets deviate from ISO 646, and as a result a graphic character might occupy the position originally reserved for the delete character. Unicode In Unicode, Graphic characters are those with General Category Letter, Mark, Number, Punctuation, Symbol or Zs=space. Other code points (General categories Control, Zl=line separator, Zp=paragraph separator) are Format, Control, Private Use, Surrogate, Noncharacter or Reserved (unassigned).https://www.unicode.org/versions/Unicode5.2.0/ch02.pdf#G25564 Chapter 2, table 2.3  Spacing and non-spacing characters  Most graphic characters are spacing characters, which means that each instance of a spacing character has to occupy some area in a graphic representation. For a teletype or a typewriter this implies moving of the carriage after typing of a character. In the context of text mode display, each spacing character occupies one rectangular character box of equal sizes. Or maybe two adjacent ones, for non-alphabetic characters of East Asian languages. If a text is rendered using proportional fonts, widths of character boxes are not equal, but are positive. There exists also non-spacing graphic characters. Most of non-spacing characters are modifiers, also called combining characters in Unicode, such as diacritical marks. Although non-spacing graphic characters are uncommon in traditional code pages, there are many such in Unicode. A combining character has its distinct glyph, but it applies to a character box of another character, a spacing one. In some historical systems such as line printers this was implemented as overstrike. Note that not all modifiers are non-spacing ‚Äì there exists Spacing Modifier Letters Unicode block. See also * encoded character * ASCII  References  Category:Character encoding ","title":"Graphic character"},{"id":"41215","text":"A typical earthing electrode (left of gray pipe), consisting of a conductive rod driven into the ground, at a home in Australia.To keep impedance low, ground wires should avoid the unnecessary bends or loops shown in this picture. Most electrical codes specify that the insulation on protective earthing conductors must be a distinctive color (or color combination) not used for any other purpose. In electrical engineering, ground or earth is the reference point in an electrical circuit from which voltages are measured, a common return path for electric current, or a direct physical connection to the earth. Electrical circuits may be connected to ground (earth) for several reasons. Exposed metal parts of electrical equipment are connected to ground, so that failures of internal insulation will trigger protective mechanisms such as fuses or circuit breakers in the circuit to remove power from the device. This ensures that exposed parts can never have a dangerous voltage with respect to ground for more than the amount of time required for the fuse or circuit breaker to open the circuit; otherwise a grounded person who touched the parts could receive an electric shock. It is crucial to minimize the impedance of the equipment ground conductor so that fault current is maximized in a fault condition. This is because the larger the amount of fault current, the quicker the fault will be cleared by an inverse-time over-current device. In electric power distribution systems, a protective earth (PE) conductor is an essential part of the safety provided by the earthing system. Connection to ground also limits the build-up of static electricity when handling flammable products or electrostatic-sensitive devices. In some telegraph and power transmission circuits, the earth itself can be used as one conductor of the circuit, saving the cost of installing a separate return conductor (see single-wire earth return). For measurement purposes, the Earth serves as a (reasonably) constant potential reference against which other potentials can be measured. An electrical ground system should have an appropriate current-carrying capability to serve as an adequate zero-voltage reference level. In electronic circuit theory, a \\"ground\\" is usually idealized as an infinite source or sink for charge, which can absorb an unlimited amount of current without changing its potential. Where a real ground connection has a significant resistance, the approximation of zero potential is no longer valid. Stray voltages or earth potential rise effects will occur, which may create noise in signals or produce an electric shock hazard if large enough. The use of the term ground (or earth) is so common in electrical and electronics applications that circuits in portable electronic devices such as cell phones and media players as well as circuits in vehicles may be spoken of as having a \\"ground\\" connection without any actual connection to the Earth, despite \\"common\\" being a more appropriate term for such a connection. This is usually a large conductor attached to one side of the power supply (such as the \\"ground plane\\" on a printed circuit board) which serves as the common return path for current from many different components in the circuit.  History  Long-distance electromagnetic telegraph systems from 1820 onwards An 'electrochemical telegraph' created by physician, anatomist and inventor Samuel Thomas von S√∂mmering in 1809, based on an earlier, less robust design of 1804 by Catalan polymath and scientist Francisco Salva Campillo, both employed multiple wires (up to 35) to represent almost all Latin letters and numerals. Messages could be conveyed electrically up to a few kilometers (in von S√∂mmering's design), with each of the telegraph receiver's wires immersed in a separate glass tube of acid. An electric current was sequentially applied by the sender through the various wires representing each digit of a message; at the recipient's end the currents electrolysed the acid in the tubes in sequence, releasing streams of hydrogen bubbles next to each associated letter or numeral. The telegraph receiver's operator would watch the bubbles and could then record the transmitted message. ‚ÄîJones, R. Victor Samuel Thomas von S√∂mmering's \\"Space Multiplexed\\" Electrochemical Telegraph (1808-10) , Harvard University website. Attributed to \\"Semaphore to Satellite\\" , International Telecommunication Union, Geneva 1965. Retrieved 2009-05-01 used two or more wires to carry the signal and return currents. It was discovered by German scientist Carl August Steinheil in 1836‚Äì1837, that the ground could be used as the return path to complete the circuit, making the return wire unnecessary. Steinheil was not the first to do this, but he was not aware of earlier experimental work, and he was the first to do it on an in-service telegraph, thus making the principle known to telegraph engineers generally. However, there were problems with this system, exemplified by the transcontinental telegraph line constructed in 1861 by the Western Union Company between St. Joseph, Missouri, and Sacramento, California. During dry weather, the ground connection often developed a high resistance, requiring water to be poured on the ground rod to enable the telegraph to work or phones to ring. In the late nineteenth century, when telephony began to replace telegraphy, it was found that the currents in the earth induced by power systems, electric railways, other telephone and telegraph circuits, and natural sources including lightning caused unacceptable interference to the audio signals, and the two- wire or 'metallic circuit' system was reintroduced around 1883.Casson, Herbert N., The History of the Telephone, public domain copy at manybooks.net: '\\"At last\\", said the delighted manager [J. J. Carty, Boston, Mass.], \\"we have a perfectly quiet line.\\"'  Building wiring installations  Electrical power distribution systems are often connected to ground to limit the voltage that can appear on distribution circuits. A distribution system insulated from ground may attain a high potential due to transient voltages caused by arcing, static electricity, or accidental contact with higher potential circuits. A ground connection of the system dissipates such potentials and limits the rise in voltage of the grounded system. In a mains electricity (AC power) wiring installation, the term ground conductor typically refers to three different conductors or conductor systems as listed below: Equipment earthing conductors provide an electrical connection between the physical ground (earth) and the grounding/bonding system, which connects (bonds) the normally non-current- carrying metallic parts of equipment. According to the U.S. National Electrical Code (NEC), the reason for doing this is to limit the voltage imposed by lightning, line surges, and contact with higher voltage lines. Equipment bonding conductors or equipment ground conductors (EGC) provide a low impedance path between normally non-current-carrying metallic parts of equipment and one of the conductors of that electrical system's source. If any exposed metal part should become energized (fault), such as by a frayed or damaged insulator, it creates a short circuit, causing the overcurrent device (circuit breaker or fuse) to open, clearing (disconnecting) the fault. It is important to note this action occurs regardless of whether there is a connection to the physical ground (earth); the earth itself has no role in this fault-clearing processJensen Transformers. Bill Whitlock, 2005. Understanding, Finding, & Eliminating Ground Loops In Audio & Video Systems. Retrieved February 18, 2010. since current must return to its source; however, the sources are very frequently connected to the physical ground (earth). (see Kirchhoff's circuit laws). By bonding (interconnecting) all exposed non- current carrying metal objects together and to other metallic objects such as pipes or structural steel, they should remain near the same voltage potential, thus reducing the chance of a shock. This is especially important in bathrooms where one may be in contact with several different metallic systems such as supply and drain pipes and appliance frames. When a system needs to be connected to the physical ground (earth), the equipment bonding conductor also becomes the equipment earthing conductor (see above). Metal water pipe used as grounding electrode A ' ('GEC) is used to connect the system grounded (\\"neutral\\") conductor, or the equipment to a grounding electrode, or a point on the grounding electrode system. This is called \\"system grounding\\" and most electrical systems are required to be grounded. The U.S. NEC and the UK's BS 7671 list systems that are required to be grounded. Retrieved December 18, 2014 According to the NEC, the purpose of connecting an electrical system to the physical ground (earth) is to limit the voltage imposed by lightning events and contact with higher voltage lines, and also for voltage stabilization. In the past, water supply pipes were used as grounding electrodes, but due to the increased use of plastic pipes, which are poor conductors, the use of an actual grounding electrode is required. This type of ground applies to radio antennas and to lightning protection systems. Permanently installed electrical equipment, unless not required to, has permanently connected grounding conductors. Portable electrical devices with metal cases may have them connected to earth ground by a pin on the attachment plug (see Domestic AC power plugs and sockets). The size of power grounding conductors is usually regulated by local or national wiring regulations. = Bonding = Strictly speaking, the terms grounding or earthing are meant to refer to an electrical connection to ground/earth. Bonding is the practice of intentionally electrically connecting metallic items not designed to carry electricity. This brings all the bonded items to the same electrical potential as a protection from electrical shock. The bonded items can then be connected to ground to eliminate foreign voltages.IEEE Std 1100-1992, IEEE Recommended Practice for Powering and Grounding Sensitive Electronic Equipment, Chapter 2: Definitions = Earthing systems = In electricity supply systems, an earthing (grounding) system defines the electrical potential of the conductors relative to that of the Earth's conductive surface. The choice of earthing system has implications for the safety and electromagnetic compatibility of the power supply. Regulations for earthing systems vary considerably between different countries. A functional earth connection serves more than protecting against electrical shock, as such a connection may carry current during the normal operation of a device. Such devices include surge suppression, electromagnetic-compatibility filters, some types of antennas, and various measurement instruments. Generally the protective earth system is also used as a functional earth, though this requires care. = Impedance grounding = Distribution power systems may be solidly grounded, with one circuit conductor directly connected to an earth grounding electrode system. Alternatively, some amount of electrical impedance may be connected between the distribution system and ground, to limit the current that can flow to earth. The impedance may be a resistor, or an inductor (coil). In a high-impedance grounded system, the fault current is limited to a few amperes (exact values depend on the voltage class of the system); a low-impedance grounded system will permit several hundred amperes to flow on a fault. A large solidly grounded distribution system may have thousands of amperes of ground fault current. In a polyphase AC system, an artificial neutral grounding system may be used. Although no phase conductor is directly connected to ground, a specially constructed transformer (a \\"zig zag\\" transformer) blocks the power frequency current from flowing to earth, but allows any leakage or transient current to flow to ground. Low-resistance grounding systems use a neutral grounding resistor (NGR) to limit the fault current to 25 A or greater. Low resistance grounding systems will have a time rating (say, 10 seconds) that indicates how long the resistor can carry the fault current before overheating. A ground fault protection relay must trip the breaker to protect the circuit before overheating of the resistor occurs. High-resistance grounding (HRG) systems use an NGR to limit the fault current to 25 A or less. They have a continuous rating, and are designed to operate with a single-ground fault. This means that the system will not immediately trip on the first ground fault. If a second ground fault occurs, a ground fault protection relay must trip the breaker to protect the circuit. On an HRG system, a sensing resistor is used to continuously monitor system continuity. If an open-circuit is detected (e.g., due to a broken weld on the NGR), the monitoring device will sense voltage through the sensing resistor and trip the breaker. Without a sensing resistor, the system could continue to operate without ground protection (since an open circuit condition would mask the ground fault) and transient overvoltages could occur.Beltz, R.; Cutler-Hammer, Atlanta, Georgia; Peacock, I.; Vilcheck, W. (2000). \\"Application Considerations for High Resistance Ground Retrofits in Pulp and Paper Mills\\". Pulp and Paper Industry Technical Conference, 2000. =Ungrounded systems= Where the danger of electric shock is high, special ungrounded power systems may be used to minimize possible leakage current to ground. Examples of such installations include patient care areas in hospitals, where medical equipment is directly connected to a patient and must not permit any power-line current to pass into the patient's body. Medical systems include monitoring devices to warn of any increase of leakage current. On wet construction sites or in shipyards, isolation transformers may be provided so that a fault in a power tool or its cable does not expose users to shock hazard. Circuits used to feed sensitive audio/video production equipment or measurement instruments may be fed from an isolated ungrounded technical power system to limit the injection of noise from the power system.  Power transmission  In single-wire earth return (SWER) AC electrical distribution systems, costs are saved by using just a single high voltage conductor for the power grid, while routing the AC return current through the earth. This system is mostly used in rural areas where large earth currents will not otherwise cause hazards. Some high-voltage direct-current (HVDC) power transmission systems use the ground as second conductor. This is especially common in schemes with submarine cables, as sea water is a good conductor. Buried grounding electrodes are used to make the connection to the earth. The site of these electrodes must be chosen carefully to prevent electrochemical corrosion on underground structures. A particular concern in design of electrical substations is earth potential rise. When very large fault currents are injected into the earth, the area around the point of injection may rise to a high potential with respect to distant points. This is due to the limited finite conductivity of the layers of soil in the earth. The gradient of the voltage (changing voltage within a distance) may be so high that two points on the ground may be at significantly different potentials, creating a hazard to anyone standing on the ground in the area. Pipes, rails, or communication wires entering a substation may see different ground potentials inside and outside the substation, creating a dangerous touch voltage. This problem is alleviated by creating a low-impedance equipotential bonding plane within the substation installed in accordance with IEEE 80. This plane eliminates voltage gradients and ensures that any fault is cleared within three voltage cycles.  Electronics  - align = \\"center\\"  Image:Signal Ground.svg width = \\"25\\"  Image:Chassis Ground.svg width = \\"25\\"  Image:Earth Ground.svg - align = \\"center\\"  Signal ground   Chassis ground   Earth ground Signal grounds serve as return paths for signals and power (at extra low voltages, less than about 50 V) within equipment, and on the signal interconnections between equipment. Many electronic designs feature a single return that acts as a reference for all signals. Power and signal grounds often get connected, usually through the metal case of the equipment. Designers of printed circuit boards must take care in the layout of electronic systems so that high-power or rapidly switching currents in one part of a system do not inject noise into low-level sensitive parts of a system due to some common impedance in the grounding traces of the layout. = Circuit ground versus earth = Voltage is defined as a difference of electric potentials. To measure the potential at a single point using a voltmeter, a reference point must be specified to measure against. In engineering jargon, this common reference point is commonly called \\"ground\\" and considered to have zero potential. This signal ground may be connected to a power ground. A system where the system ground is not connected to another circuit or to earth (though there may still be AC coupling) is often referred to as a floating ground or double-insulated. = Functional grounds = Some devices require a connection to the mass of earth to function correctly, as distinct from any purely protective role. Such a connection is known as a functional earth- for example some long wavelength antenna structures require a functional earth connection, which generally should not be indiscriminately connected to the supply protective earth, as the introduction of transmitted radio frequencies into the electrical distribution network is both illegal and potentially dangerous. Because of this separation, a purely functional ground should not normally be relied upon to perform a protective function. To avoid accidents, such functional grounds are normally wired in white or cream cable, and not green or green/yellow. = Separating low signal ground from a noisy ground = In television stations, recording studios, and other installations where signal quality is critical, a special signal ground known as a \\"technical ground\\" (or \\"technical earth\\", \\"special earth\\", and \\"audio earth\\") is often installed, to prevent ground loops. This is basically the same thing as an AC power ground, but no general appliance ground wires are allowed any connection to it, as they may carry electrical interference. For example, only audio equipment is connected to the technical ground in a recording studio.Swallow D 2011, Live Audio, The Art of Mixing, Chap 4. Power and Electricity, pp. 35-39 In most cases, the studio's metal equipment racks are all joined together with heavy copper cables (or flattened copper tubing or busbars) and similar connections are made to the technical ground. Great care is taken that no general chassis grounded appliances are placed on the racks, as a single AC ground connection to the technical ground will destroy its effectiveness. For particularly demanding applications, the main technical ground may consist of a heavy copper pipe, if necessary fitted by drilling through several concrete floors, such that all technical grounds may be connected by the shortest possible path to a grounding rod in the basement.  Radio antennas  Certain types of radio antennas (or their feedlines) require a connection to ground. Since the radio frequencies of the current in radio antennas are far higher than the 50/60 Hz frequency of the power line, radio grounding systems use different principles from AC power grounding. The \\"third wire\\" safety grounds in AC utility building wiring were not designed for and cannot be used for this purpose. The long utility ground wires have high impedance at certain frequencies. In the case of a transmitter, the RF current flowing through the ground wires can radiate radio frequency interference and induce hazardous voltages on grounded metal parts of other appliances, so separate ground systems are used. Monopole antennas operating at lower frequencies, below 20 MHz, use the Earth as part of the antenna, as a conductive plane to reflect the radio waves. These include the T and inverted L antenna, umbrella antenna and the mast radiator used by AM radio stations. The feedline from the transmitter is connected between the antenna and ground, so it requires a grounding (Earthing) system under the antenna to make contact with the soil to collect the return current. In lower power transmitters and radio receivers, the ground connection can be as simple as one or more metal rods or stakes driven into the earth, or an electrical connection to a building's metal water piping which extends into the earth. However, in transmitting antennas the ground system carries the full output current of the transmitter, so the resistance of the ground contact can be a major loss of transmitter power. The ground system functions as a capacitor plate, to receive the displacement current from the antenna and return it to the ground side of the transmitter's feedline, so it must be located directly under the antenna. Medium to high power transmitters usually have an extensive ground system consisting of cables buried in the earth under the antenna, to lower resistance. Since for the omnidirectional antennas used on these bands the Earth currents travel radially toward the ground point from all directions, the grounding system usually consists of a radial pattern of buried cables extending outward under the antenna in all directions, connected together to the ground side of the transmitter's feedline at a terminal next to the base of the antenna. The transmitter power lost in the ground resistance, and so the efficiency of the antenna, depends on the soil conductivity. This varies widely; marshy ground or ponds, particularly salt water, provide the lowest resistance ground. The power loss per square meter in the ground is proportional to the square of the transmitter current density flowing in the earth. The current density, and power dissipated, increases the closer one gets to the ground terminal at the base of the antenna, so the radial ground system can be thought of as providing a higher conductivity medium, copper, for the ground current to flow through, in the parts of the ground carrying high current density, to reduce power losses. = Design = A standard ground system widely used for mast radiator broadcasting antennas operating in the MF and LF bands consists of 120 equally-spaced buried radial ground wires extending out one quarter of a wavelength (.25\\\\lambda, 90 electrical degrees) from the antenna. No. 8 to 10 gauge soft-drawn copper wire is typically used, buried 4 to 10 inches deep. For AM broadcast band antennas this requires a circular land area extending from the mast . This is usually planted with grass, which is kept mowed short as tall grass can increase power loss in certain circumstances. If the land area available is too limited for such long radials, they can in many cases be replaced by a greater number of shorter radials, or a smaller number of longer radials. In transmitting antennas a second cause of power wastage is dielectric power losses of the electric field (displacement current) of the antenna passing through the earth to reach the ground wires. For antennas near a half-wavelength high (180 electrical degrees) the antenna has a voltage maximum (antinode) near its base, which results in strong electric fields in the earth above the ground wires near the mast where the displacement current enters the ground. To reduce this loss these antennas often use a conductive copper ground screen under the antenna connected to the buried ground wires, either laying on the ground or elevated a few feet, to shield the ground from the electric field. In a few cases where rocky or sandy soil has too high a resistance for a buried ground, a counterpoise is used. This is a radial network of wires similar to that in a buried ground system, but laying on the surface or suspended a few feet above the ground. It acts as a capacitor plate, capacitively coupling the feedline to conductive layers of the earth. = Electrically short antennas = At lower frequencies the resistance of the ground system is a more critical factor because of the small radiation resistance of the antenna. In the LF and VLF bands, construction height limitations require that electrically short antennas be used, shorter than the fundamental resonant length of one quarter of a wavelength (\\\\lambda/4). A quarter wave monopole has a radiation resistance of around 25 to 36 ohms, but below \\\\lambda/4 the resistance decreases with the square of the ratio of height to wavelength. The power fed to an antenna is split between the radiation resistance, which represents power emitted as radio waves, the desired function of the antenna, and the ohmic resistance of the ground system, which results in power wasted as heat. As the wavelength gets longer in relation to antenna height, the radiation resistance of the antenna decreases so the ground resistance constitutes a larger proportion of the input resistance of the antenna and consumes more of the transmitter power. Antennas in the VLF band often have a resistance of less than one ohm, and even with extremely low resistance ground systems 50% to 90% of the transmitter power may be wasted in the ground system.  Lightning protection systems  Busbars are used for ground conductors in high-current circuits. Lightning protection systems are designed to mitigate the effects of lightning through connection to extensive grounding systems that provide a large surface area connection to earth. The large area is required to dissipate the high current of a lightning strike without damaging the system conductors by excess heat. Since lightning strikes are pulses of energy with very high frequency components, grounding systems for lightning protection tend to use short straight runs of conductors to reduce the self-inductance and skin effect.  Ground (earth) mat  In an electrical substation a ground (earth) mat is a mesh of conductive material installed at places where a person would stand to operate a switch or other apparatus; it is bonded to the local supporting metal structure and to the handle of the switchgear, so that the operator will not be exposed to a high differential voltage due to a fault in the substation. In the vicinity of electrostatic sensitive devices, a ground (earth) mat or grounding (earthing) mat is used to ground static electricity generated by people and moving equipment. There are two types used in static control: Static Dissipative Mats, and Conductive Mats. A static dissipative mat that rests on a conductive surface (commonly the case in military facilities) are typically made of 3 layers (3-ply) with static dissipative vinyl layers surrounding a conductive substrate which is electrically attached to ground (earth). For commercial uses, static dissipative rubber mats are traditionally used that are made of 2 layers (2-ply) with a tough solder resistant top static dissipative layer that makes them last longer than the vinyl mats, and a conductive rubber bottom. Conductive mats are made of carbon and used only on floors for the purpose of drawing static electricity to ground as quickly as possible. Normally conductive mats are made with cushioning for standing and are referred to as \\"anti-fatigue\\" mats. 3 ply static dissipative vinyl grounding mat shown at macro scale For a static dissipative mat to be reliably grounded it must be attached to a path to ground. Normally, both the mat and the wrist strap are connected to ground by using a common point ground system (CPGS). In computer repair shops and electronics manufacturing workers must be grounded before working on devices sensitive to voltages capable of being generated by humans. For that reason static dissipative mats can be and are also used on production assembly floors as \\"floor runner\\" along the assembly line to draw static generated by people walking up and down.  Isolation  Isolation is a mechanism that defeats grounding. It is frequently used with low-power consumer devices, and when electronics engineers, hobbyists, or repairmen are working on circuits that would normally be operated using the power line voltage. Isolation can be accomplished by simply placing a \\"1:1 wire ratio\\" transformer with an equal number of turns between the device and the regular power service, but applies to any type of transformer using two or more coils electrically insulated from each other. For an isolated device, touching a single powered conductor does not cause a severe shock, because there is no path back to the other conductor through the ground. However, shocks and electrocution may still occur if both poles of the transformer are contacted by bare skin. Previously it was suggested that repairmen \\"work with one hand behind their back\\" to avoid touching two parts of the device under test at the same time, thereby preventing a circuit from crossing through the chest and interrupting cardiac rhythms/ causing cardiac arrest. Generally every AC power line transformer acts as an isolation transformer, and every step up or down has the potential to form an isolated circuit. However, this isolation would prevent failed devices from blowing fuses when shorted to their ground conductor. The isolation that could be created by each transformer is defeated by always having one leg of the transformers grounded, on both sides of the input and output transformer coils. Power lines also typically ground one specific wire at every pole, to ensure current equalization from pole to pole if a short to ground is occurring. In the past, grounded appliances have been designed with internal isolation to a degree that allowed the simple disconnection of ground by cheater plugs without apparent problem (a dangerous practice, since the safety of the resulting floating equipment relies on the insulation in its power transformer). Modern appliances however often include power entry modules which are designed with deliberate capacitive coupling between the AC power lines and chassis, to suppress electromagnetic interference. This results in a significant leakage current from the power lines to ground. If the ground is disconnected by a cheater plug or by accident, the resulting leakage current can cause mild shocks, even without any fault in the equipment. Even small leakage currents are a significant concern in medical settings, as the accidental disconnection of ground can introduce these currents into sensitive parts of the human body. As a result, medical power supplies are designed to have low capacitance. Class II appliances and power supplies (such as cell phone chargers) do not provide any ground connection, and are designed to isolate the output from input. Safety is ensured by double-insulation, so that two failures of insulation are required to cause a shock.  See also  * Appliance classes * Ground constants * Ring ground * Ground loop (electricity) * Ground wire (transmission line) * Isolated ground * Phantom circuit * Floating ground * Soil resistivity * Ufer Ground * Virtual ground  Notes   References  * Federal Standard 1037C in support of MIL-STD-188  External links  * Circuit Grounds and Grounding Practices * Electrical Safety chapter from Lessons In Electric Circuits Vol 1 DC book and series. * Grounding for Low- and High- Frequency Circuits (PDF) ‚Äî Analog Devices Application Note * An IC Amplifier User‚Äôs Guide to Decoupling, Grounding, and Making Things Go Right for a Change (PDF) ‚Äî Analog Devices Application Note * The Electromagnetic Telegraph, by J. B. Calvert * Electrical safety for high resistance grounding systems Category:Electric power Category:Electrical safety Category:Electrical wiring Category:Power engineering Category:Electric power distribution ","title":"Ground (electricity)"},{"id":"41216","text":"In telecommunication, ground constants are the electrical parameters of earth: electrical conductivity, œÉ, electrical permittivity, Œµ, and magnetic permeability, Œº. The values of these parameters vary with the local chemical composition and density of the Earth. For a propagating electromagnetic wave, such as a surface wave propagating along the surface of the Earth, these parameters vary with frequency and direction. See also *Ground References * Category:Telecommunications engineering ","title":"Ground constants"},{"id":"41217","text":"Ground loop may refer to: * Ground loop (electricity), an unwanted electric current that flows in a conductor connecting two points inadvertently having different potentials * Ground loop (aviation), the rapid circular rotation of an aircraft in the horizontal plane while on the ground * Ground-coupled heat exchanger, an underground heat exchanger loop that can capture or dissipate heat to or from the ground ","title":"Ground loop"},{"id":"41218","text":"In electrical engineering, a ground plane is an electrically conductive surface, usually connected to electrical ground. The term has two different meanings in separate areas of electrical engineering. In antenna theory, a ground plane is a conducting surface large in comparison to the wavelength, such as the Earth, which is connected to the transmitter's ground wire and serves as a reflecting surface for radio waves. In printed circuit boards, a ground plane is a large area of copper foil on the board which is connected to the power supply ground terminal and serves as a return path for current from different components on the board. Radio antenna theory  In telecommunication, a ground plane is a flat or nearly flat horizontal conducting surface that serves as part of an antenna, to reflect the radio waves from the other antenna elements. The plane does not necessarily have to be connected to ground. Ground plane shape and size play major roles in determining its radiation characteristics including gain. For a monopole antenna, the Earth acts as a ground plane to reflect radio waves directed downwards, making them seem to come from an image antenna. To function as a ground plane, the conducting surface must be at least a quarter of the wavelength (Œª/4) of the radio waves in diameter. In lower frequency antennas, such as the mast radiators used for broadcast antennas, the Earth itself (or a body of water such as a salt marsh or ocean) is used as a ground plane. For higher frequency antennas, in the VHF or UHF range, the ground plane can be smaller, and metal disks, screens and wires are used as ground planes. At upper VHF and UHF, the metal skin of a car or aircraft can serve as a ground plane for whip antennas projecting from it. In microstrip antennas and printed monopole antennas an area of copper foil on the opposite side of a printed circuit board serves as a ground plane. The ground plane doesn't have to be a continuous surface. In the ground plane antenna style whip antenna, the \\"plane\\" consists of several wires Œª/4 long radiating from the base of a quarter-wave whip antenna. The radio waves from an antenna element that reflect off a ground plane appear to come from a mirror image of the antenna located on the other side of the ground plane. In a monopole antenna, the radiation pattern of the monopole plus the virtual \\"image antenna\\" make it appear as a two element center-fed dipole antenna. So a monopole mounted over an ideal ground plane has a radiation pattern identical to a dipole antenna. The feedline from the transmitter or receiver is connected between the bottom end of the monopole element and the ground plane. The ground plane must have good conductivity; any resistance in the ground plane is in series with the antenna, and serves to dissipate power from the transmitter.  Printed circuit boards  The large light areas on this printed circuit board are the ground plane A ground plane on a printed circuit board (PCB) is a large area or layer of copper foil connected to the circuit's ground point, usually one terminal of the power supply. It serves as the return path for current from many different components. A ground plane is often made as large as possible, covering most of the area of the PCB which is not occupied by circuit traces. In multilayer PCBs, it is often a separate layer covering the entire board. This serves to make circuit layout easier, allowing the designer to ground any component without having to run additional traces; component leads needing grounding are routed directly through a hole in the board to the ground plane on another layer. The large area of copper also conducts the large return currents from many components without significant voltage drops, ensuring that the ground connection of all the components are at the same reference potential. In digital and radio frequency PCBs, the major reason for using large ground planes is to reduce electrical noise and interference through ground loops and to prevent crosstalk between adjacent circuit traces. When digital circuits switch state, large current pulses flow from the active devices (transistors or integrated circuits) through the ground circuit. If the power supply and ground traces have significant impedance, the voltage drop across them may create noise voltage pulses that disturb other parts of the circuit (ground bounce). The large conducting area of the ground plane has much lower impedance than a circuit trace, so the current pulses cause less disturbance. In addition, a ground plane under printed circuit traces can reduce crosstalk between adjacent traces. When two traces run parallel, an electrical signal in one can be coupled into the other through electromagnetic induction by magnetic field lines from one linking the other; this is called crosstalk. When a ground plane layer is present underneath, it forms a transmission line with the trace. The oppositely-directed return currents flow through the ground plane directly beneath the trace. This confines most of the electromagnetic fields to the area near the trace and consequently reduces crosstalk. A power plane is often used in addition to a ground plane in a multilayer circuit board, to distribute DC power to the active devices. The two facing areas of copper create a large parallel plate decoupling capacitor that prevents noise from being coupled from one circuit to another through the power supply. Ground planes are sometimes split and then connected by a thin trace. This allows the separation of analog and digital sections of a board or the inputs and outputs of amplifiers. The thin trace has low enough impedance to keep the two sides very close to the same potential while keeping the ground currents of one side from coupling into the other side, causing ground loop.  See also  * * List of electronics topics * Power plane * Microstrip and Stripline * Line-of-sight propagation * Radio electronics and Radio propagation * Printed circuit board milling * Copper pour * Antenna tuner * Salisbury screen References  * Groundplane antenna model FA-2 from the book PRACTICAL ANTENNA DESIGN second edition, Philippine copyright, 1990, 1994 by Elpidio C. Latorilla * John Whitmore, sci.electronics > What is a PCB with a Ground plane?. August 11, 1992. * Amateur Quarter Wave Ground Plane Antenna Calculator. Computer Support Group, Inc., 2006. * What is a Ground Plane? Criterion Cellular, 2006. Category:Antennas Category:Telecommunications infrastructure ","title":"Ground plane"},{"id":"41220","text":"In telecommunication, a group alerting and dispatching system is a service feature that (a) enables a controlling telephone to place a call to a specified number of telephones simultaneously, (b) enables the call to be recorded, (c) if any of the called lines is busy, enables the equipment to camp on until the busy line is free, and (d) rings the free line and plays the recorded message. Category:Telephony ","title":"Group alerting and dispatching system"},{"id":"41223","text":"A guided ray (also bound ray or trapped ray) is a ray of light in a multi-mode optical fiber, which is confined by the core. For step index fiber, light entering the fiber will be guided if it falls within the acceptance cone of the fiber, that is if it makes an angle with the fiber axis that is less than the acceptance angle, :\\\\theta < \\\\arcsin \\\\left( \\\\sqrt{n_o^2 - n_c^2} \\\\right) , where :Œ∏ is the angle the ray makes with the fiber axis, before entering the fiber, :no is the refractive index along the central axis (core) of the fiber, and :nc is the refractive index of the cladding. The quantity \\\\sin \\\\theta is the numerical aperture of the fiber. The quantity 2 \\\\theta is sometimes called the total acceptance angle of the fiber. This result can be derived from Snell's law by considering the critical angle. Light that enters the core with an angle below the acceptance angle strikes the core-cladding boundary at an angle above the critical angle, and experiences total internal reflection. This repeats on every bounce within the fiber core, and so the light is confined to the core. The confinement of light by the fiber can also be described in terms of bound modes or guided modes. This treatment is necessary when considering singlemode fiber, since the ray model does not accurately describe the propagation of light in this type of fiber. See also *Numerical aperture *Acceptance angle (solar concentrator), same construct for another use References :* Federal Standard 1037C Category:Fiber optics ","title":"Guided ray"},{"id":"41224","text":"In telecommunication, a Hagelbarger code is a convolutional code that enables error bursts to be corrected provided that there are relatively long error- free intervals between the error bursts. In the Hagelbarger code, inserted parity check bits are spread out in time so that an error burst is not likely to affect more than one of the groups in which parity is checked. Category:Error detection and correction ","title":"Hagelbarger code"},{"id":"41225","text":"In a facsimile system the halftone characteristic is either: # the relationship between the density of the recorded copy and the density of the original, or # the relationship between the amplitude of the facsimile signal to either the density of the object or the density of the recorded copy when only a portion of the system is under consideration. In an FM facsimile system, an appropriate parameter other than the amplitude is used. See also *Halftone References Category:Fax ","title":"Halftone characteristic"},{"id":"41227","text":"In information theory, the Hamming distance between two strings of equal length is the number of positions at which the corresponding symbols are different. In other words, it measures the minimum number of substitutions required to change one string into the other, or the minimum number of errors that could have transformed one string into the other. In a more general context, the Hamming distance is one of several string metrics for measuring the edit distance between two sequences. It is named after the American mathematician Richard Hamming. A major application is in coding theory, more specifically to block codes, in which the equal-length strings are vectors over a finite field. Definition The Hamming distance between two equal- length strings of symbols is the number of positions at which the corresponding symbols are different. Examples The symbols may be letters, bits, or decimal digits, among other possibilities. For example, the Hamming distance between: * \\"kain\\" and \\"kain\\" is 3. * \\"krin\\" and \\"krin\\" is 3. * \\"kin\\" and \\"kin\\" is 4. * 10101 and 10101 is 2. * 2396 and 2396 is 3. Properties For a fixed length n, the Hamming distance is a metric on the set of the words of length n (also known as a Hamming space), as it fulfills the conditions of non-negativity, symmetry, the Hamming distance of two words is 0 if and only if the two words are identical, and it satisfies the triangle inequality as well: Indeed, if we fix three words a, b and c, then whenever there is a difference between the ith letter of a and the ith letter of c, then there must be a difference between the ith letter of a and ith letter of b, or between the ith letter of b and the ith letter of c. Hence the Hamming distance between a and c is not larger than the sum of the Hamming distances between a and b and between b and c. The Hamming distance between two words a and b can also be seen as the Hamming weight of a ‚àí b for an appropriate choice of the ‚àí operator, much as the difference between two integers can be seen as a distance from zero on the number line. For binary strings a and b the Hamming distance is equal to the number of ones (population count) in a XOR b. The metric space of length-n binary strings, with the Hamming distance, is known as the Hamming cube; it is equivalent as a metric space to the set of distances between vertices in a hypercube graph. One can also view a binary string of length n as a vector in \\\\mathbb{R}^{n} by treating each symbol in the string as a real coordinate; with this embedding, the strings form the vertices of an n-dimensional hypercube, and the Hamming distance of the strings is equivalent to the Manhattan distance between the vertices.  Error detection and error correction  The minimum Hamming distance is used to define some essential notions in coding theory, such as error detecting and error correcting codes. In particular, a code C is said to be k error detecting if, and only if, the minimum Hamming distance between any two of its codewords is at least k+1. For example, consider the code consisting of two codewords \\"000\\" and \\"111\\". The hamming distance between these two words is 3, and therefore it is k=2 error detecting. Which means that if one bit is flipped or two bits are flipped, the error can be detected. If three bits are flipped, then \\"000\\" becomes \\"111\\" and the error can not be detected. A code C is said to be k-errors correcting if, for every word w in the underlying Hamming space H, there exists at most one codeword c (from C) such that the Hamming distance between w and c is at most k. In other words, a code is k-errors correcting if, and only if, the minimum Hamming distance between any two of its codewords is at least 2k+1. This is more easily understood geometrically as any closed balls of radius k centered on distinct codewords being disjoint. These balls are also called Hamming spheres in this context. For example, consider the same 3 bit code consisting of two codewords \\"000\\" and \\"111\\". The Hamming space consists of 8 words 000, 001, 010, 011, 100, 101, 110 and 111. The codeword \\"000\\" and the single bit error words \\"001\\",\\"010\\",\\"100\\" are all less than or equal to the Hamming distance of 1 to \\"000\\". Likewise, codeword \\"111\\" and its single bit error words \\"110\\",\\"101\\" and \\"011\\" are all within 1 Hamming distance of the original \\"111\\". In this code, a single bit error is always within 1 Hamming distance of the original codes, and the code can be 1-error correcting, that is k=1. The minimum Hamming distance between \\"000\\" and \\"111\\" is 3, which satisfies 2k+1 = 3. Thus a code with minimum Hamming distance d between its codewords can detect at most d-1 errors and can correct ‚åä(d-1)/2‚åã errors. The latter number is also called the packing radius or the error-correcting capability of the code. History and applications The Hamming distance is named after Richard Hamming, who introduced the concept in his fundamental paper on Hamming codes, Error detecting and error correcting codes, in 1950. Hamming weight analysis of bits is used in several disciplines including information theory, coding theory, and cryptography. It is used in telecommunication to count the number of flipped bits in a fixed-length binary word as an estimate of error, and therefore is sometimes called the signal distance. For q-ary strings over an alphabet of size q ‚â• 2 the Hamming distance is applied in case of the q-ary symmetric channel, while the Lee distance is used for phase-shift keying or more generally channels susceptible to synchronization errors because the Lee distance accounts for errors of ¬±1. If q = 2 or q = 3 both distances coincide because any pair of elements from \\\\mathbb{Z}/2\\\\mathbb{Z} or \\\\mathbb{Z}/3\\\\mathbb{Z} differ by 1, but the distances are different for larger q. The Hamming distance is also used in systematics as a measure of genetic distance. However, for comparing strings of different lengths, or strings where not just substitutions but also insertions or deletions have to be expected, a more sophisticated metric like the Levenshtein distance is more appropriate. In processor interconnects, the dynamic energy consumption depends on the number of transitions. With level-signaling scheme, the number of transitions depends on Hamming distance between consecutively transmitted buses.\\"A Survey of Encoding Techniques for Reducing Data-Movement Energy\\", JSA, 2018 Hence, by reducing this Hamming distance, the data-movement energy can be reduced.  Algorithm example  The following function, written in Python 3.7, returns the Hamming distance between two strings: def hamming_distance(string1, string2): dist_counter = 0 for n in range(len(string1)): if string1[n] != string2[n]: dist_counter += 1 return dist_counter The function \`hamming_distance()\`, implemented in Python 2.3+, computes the Hamming distance between two strings (or other iterable objects) of equal length by creating a sequence of Boolean values indicating mismatches and matches between corresponding positions in the two inputs and then summing the sequence with False and True values being interpreted as zero and one. def hamming_distance(s1, s2) -> int: \\"\\"\\"Return the Hamming distance between equal-length sequences.\\"\\"\\" if len(s1) != len(s2): raise ValueError(\\"Undefined for sequences of unequal length.\\") return sum(el1 != el2 for el1, el2 in zip(s1, s2)) where the zip() function merges two equal-length collections in pairs. The following C function will compute the Hamming distance of two integers (considered as binary values, that is, as sequences of bits). The running time of this procedure is proportional to the Hamming distance rather than to the number of bits in the inputs. It computes the bitwise exclusive or of the two inputs, and then finds the Hamming weight of the result (the number of nonzero bits) using an algorithm of that repeatedly finds and clears the lowest-order nonzero bit. Some compilers support the __builtin_popcount function which can calculate this using specialized processor hardware where available. int hamming_distance(unsigned x, unsigned y) { int dist = 0; // Count the number of bits set for (unsigned val = x ^ y; val > 0; val = val >> 1) { // If A bit is set, so increment the count if (val & 1) dist++; // Clear (delete) val's lowest-order bit } // Return the number of differing bits return dist; } A faster alternative is to use the population count (popcount) assembly instruction. Certain compilers such as GCC and Clang make it available via an intrinsic function: // Hamming distance for 32-bit integers int hamming_distance32(unsigned int x, unsigned int y) { return __builtin_popcount(x ^ y); } // Hamming distance for 64-bit integers int hamming_distance64(unsigned long long x, unsigned long long y) { return __builtin_popcountll(x ^ y); } See also * Closest string * Damerau‚ÄìLevenshtein distance * Euclidean distance * Gap-Hamming problem * Gray code * Jaccard index * Levenshtein distance * Mahalanobis distance * S√∏rensen similarity index * Sparse distributed memory * Word ladder References Further reading  Category:String similarity measures Category:Coding theory Category:Articles with example Python (programming language) code Category:Articles with example C++ code Category:Metric geometry Category:Cubes Category:Similarity and distance measures ","title":"Hamming distance"},{"id":"41229","text":"In telecommunications, a handshake is an automated process of negotiation between two participants (example \\"Alice and Bob\\") through the exchange of information that establishes the protocols of a communication link at the start of the communication, before full communication begins. The handshaking process usually takes place in order to establish rules for communication when a computer attempts to communicate with another device. Signals are usually exchanged between two devices to establish a communication link. For example, when a computer communicates with another device such as a modem, the two devices will signal each other that they are switched on and ready to work, as well as to agree to which protocols are being used. Handshaking can negotiate parameters that are acceptable to equipment and systems at both ends of the communication channel, including information transfer rate, coding alphabet, parity, interrupt procedure, and other protocol or hardware features. Handshaking is a technique of communication between two entities. However, within TCP/IP RFCs, the term \\"handshake\\" is most commonly used to reference the TCP three-way handshake. For example, the term \\"handshake\\" is not present in RFCs covering FTP or SMTP. One exception is Transport Layer Security, TLS, setup, FTP RFC 4217. In place of the term \\"handshake\\", FTP RFC 3659 substitutes the term \\"conversation\\" for the passing of commands.TCP RFC 793, 2581SMTP RFC 821,5321, 2821, 1869,6531, 2822FTP 959, 3659 (conversation), 2228,4217 (TLS handshake),5797 A simple handshaking protocol might only involve the receiver sending a message meaning \\"I received your last message and I am ready for you to send me another one.\\" A more complex handshaking protocol might allow the sender to ask the receiver if it is ready to receive or for the receiver to reply with a negative acknowledgement meaning \\"I did not receive your last message correctly, please resend it\\" (e.g., if the data was corrupted en route). Handshaking facilitates connecting relatively heterogeneous systems or equipment over a communication channel without the need for human intervention to set parameters.  Example  = TCP three-way handshake = Example of three way handshaking Establishing a normal TCP connection requires three separate steps: :# The first host (Alice) sends the second host (Bob) a \\"synchronize\\" (SYN) message with its own sequence number x, which Bob receives. :# Bob replies with a synchronize-acknowledgment (SYN- ACK) message with its own sequence number y and acknowledgement number x + 1, which Alice receives. :# Alice replies with an acknowledgment (ACK) message with acknowledgement number y + 1, which Bob receives and to which he doesn't need to reply. : In this setup, the synchronize messages act as service requests from one server to the other, while the acknowledgement messages return to the requesting server to let it know the message was received. The reason for the client and server not using a default sequence number such as 0 for establishing the connection is to protect against two incarnations of the same connection reusing the same sequence number too soon, which means a segment from an earlier incarnation of a connection might interfere with a later incarnation of the connection. = SMTP = The Simple Mail Transfer Protocol (SMTP) is the key Internet standard for email transmission. It includes handshaking to negotiate authentication, encryption and maximum message size. = TLS handshake = When a Transport Layer Security (SSL or TLS) connection starts, the record encapsulates a \\"control\\" protocol‚Äîthe handshake messaging protocol (content type 22). This protocol is used to exchange all the information required by both sides for the exchange of the actual application data by TLS. It defines the messages formatting or containing this information and the order of their exchange. These may vary according to the demands of the client and server‚Äîi.e., there are several possible procedures to set up the connection. This initial exchange results in a successful TLS connection (both parties ready to transfer application data with TLS) or an alert message (as specified below). The protocol is used to negotiate the secure attributes of a session. (RFC 5246, p. 37) = WPA2 wireless = The WPA2 standard for wireless uses a four-way handshake defined in IEEE 802.11i-2004. = Dial-up access modems = One classic example of handshaking is that of dial-up modems, which typically negotiate communication parameters for a brief period when a connection is first established, and there after use those parameters to provide optimal information transfer over the channel as a function of its quality and capacity. The \\"squealing\\" (which is actually a sound that changes in pitch 100 times every second) noises made by some modems with speaker output immediately after a connection is established are in fact the sounds of modems at both ends engaging in a handshaking procedure; once the procedure is completed, the speaker might be silenced, depending on the settings of operating system or the application controlling the modem. = Serial \\"Hardware Handshaking\\" = This frequently used term describes the use of RTS and CTS signals over a serial interconnection. It is, however, not quite correct; it's not a true form of handshaking, and is better described as flow control. This flow control mechanism is described in the article on RS-232.  References  Category:Data transmission Category:Network architecture Category:Network protocols de:Datenflusssteuerung ","title":"Handshaking"},{"id":"41230","text":"In information handling, the U.S. Federal Standard 1037C (Glossary of Telecommunication Terms) defines a hard copy as a permanent reproduction, or copy, in the form of a physical object, of any media suitable for direct use by a person (in particular paper), of displayed or transmitted data. Examples of hard copy include teleprinter pages, continuous printed tapes, computer printouts, and radio photo prints. On the other hand, physical objects such as magnetic tapes diskettes, or non-printed punched paper tapes are not defined as hard copy by 1037C.Hard copy as defined in Federal Standard 1037C. A file which can be viewed on a screen without printing it out is sometimes called a soft copy. The U.S. Federal Standard 1037C defines \\"soft copy\\" as \\"a nonpermanent display image, for example, a cathode ray tube display.\\"\\"Soft copy\\", as defined in Federal Standard 1037C. The term \\"hard copy\\" predates the age of the digital computer. In the process of producing printed books and newspapers, hard copy refers to a manuscript or typewritten document that has been edited and proofread, and is ready for typesetting, or being read on-air in a radio or television broadcast. This traditional meaning has been all but forgotten in the wake of the information revolution.hard copy as defined by Merriam-Webster Online. Use in computer security One often-overlooked application for printers is in the field of IT security. Copies of various system and server activity logs are typically stored on the local filesystem, where a remote attacker ‚Äì having achieved their primary goals ‚Äì can then alter or delete the contents of the logs, in an attempt to \\"cover their tracks\\" or otherwise thwart the efforts of system administrators and security experts. However, if the log entries are simultaneously output to a printer, line-by- line, a local hard-copy record of system activity is created ‚Äì and this cannot be remotely altered or otherwise manipulated. Dot-matrix printers are ideal for this task, as they can sequentially print each log entry, one entry at a time, as they are added to the log. The usual dot-matrix printer support for continuous stationery also prevents incriminating pages from being surreptitiously removed or altered without evidence of tampering.  \\"Dead- tree\\" dysphemism The hacker's Jargon File defines a dead-tree version to be a paper version of an on-line document, where \\"dead trees\\" refer to paper.jargon File, article \\"dead-tree version\\" It is a dysphemism for hard copy. A saying from the Jargon File is that \\"You can't grep dead trees\\",Jargon File, article \\"Documentation\\" from the Unix command \`grep\` meaning to search the contents of text files. This means that an advantage of keeping documents in digital form rather than on paper is that they can be more easily searched for specific contents. A yet another usage of this imagery, cited in Jargon File is \\"tree-killer\\" , which may refer either to a printer or a person who wastes paper, for example marketing people who generate much \\"content-free\\" documentation.Jargon File, article \\"tree-killer\\" Dead-tree edition refers to a printed paper version of a written work, as opposed to digital alternatives such as a web page. References  External links  Category:Information technology de:Hardcopy ","title":"Hard copy"},{"id":"41231","text":"These rectangles constitute the hard (factory originated) sectoring of a DVD- RAM disc Hard sectoring in a magnetic or optical data storage device is a form of sectoring which uses a physical mark or hole in the recording medium to reference sector locations. In older 8- and 5-inch floppy disks, hard sectoring was implemented by punching sector holes in the disk to mark the start of each sector. These were equally spaced holes, at a common radius. This was in addition to the index hole, situated between two sector holes, to mark the start of the entire track of sectors. When the index or sector hole was recognized by an optical sensor, a sector signal was generated. Timing electronics or software would use the faster timing of the index hole between sector holes, to generate an index signal. Data read and write is faster in this technique than soft sectoring as no operations are to be performed regarding the starting and ending points of tracks. Storage formats using hard sectoring *32 sector 8-inch floppy disks *10 sector and 16 sector 5-inch floppy disks *Numerous magneto-optical formats *DVD-RAM References * Category:Rotating disc computer storage media ","title":"Hard sectoring"},{"id":"41233","text":"In the Integrated Services Digital Network (ISDN), a high-speed communication channel comprising multiple aggregated low-speed channels to accommodate bandwidth-intensive applications such as file transfer, videoconferencing, and high-quality audio. An H channel is formed of multiple bearer B channels bonded together in a primary rate access (PRA) or primary rate interface (PRI) frame in support of applications with bandwidth requirements that exceed the B channel rate of 64 kbit/s. The channels, once bonded, remain so end-to-end, from transmitter to receiver, through the ISDN network. The feature is known variously as multirate ISDN, Nx64, channel aggregation, and bonding. H channels are implemented as: * H0 = 384 kbit/s(6 B channels) * H10 = 1472 kbit/s(23 B channels) * H11 = 1536 kbit/s(24 B channels) * H12 = 1920 kbit/s(30 B channels) ‚Äì International (E-carrier) only.  See also  * D channel * B channel Category:Integrated Services Digital Network ","title":"H channel"},{"id":"41234","text":"Frequency mixer symbol used in schematic diagrams A heterodyne is a signal frequency that is created by combining or mixing two other frequencies using a signal processing technique called heterodyning, which was invented by Canadian inventor-engineer Reginald Fessenden. Heterodyning is used to shift one frequency range into another, new frequency range, and is also involved in the processes of modulation and demodulation. The two input frequencies are combined in a nonlinear signal-processing device such as a vacuum tube, transistor, or diode, usually called a mixer. In the most common application, two signals at frequencies and are mixed, creating two new signals, one at the sum of the two frequencies , and the other at the difference between the two frequencies . The new signal frequencies are called heterodynes. Typically, only one of the heterodynes is required and the other signal is filtered out of the output of the mixer. Heterodyne frequencies are related to the phenomenon of \\"beats\\" in acoustics. A major application of the heterodyne process is in the superheterodyne radio receiver circuit, which is used in virtually all modern radio receivers. History Fessenden's heterodyne radio receiver circuit. The incoming radio frequency and local oscillator frequency mix in the crystal diode detector. In 1901, Reginald Fessenden demonstrated a direct-conversion heterodyne receiver or beat receiver as a method of making continuous wave radiotelegraphy signals audible.Discussion of A History of Some Foundations of Modern Radio-Electronic Technology, Comments by Lloyd Espenschied, Proceedings of the IRE, July, 1959 (Vol. 47, No. 7), pp. 1254, 1256. Critique. \\". . . the roots of our modern technology trace back generally to sources other than the Hammond Laboratory.\\" Comment. Many of the roots that nourished the work of the Hammond group and its contemporaries were recorded in our paper: the pioneering work of Wilson and Evans, Tesla, Shoemaker, in basic radiodynamics; . . . of Tesla and Fessenden leading to the development of basic intermediate frequency circuitry. Fessenden's receiver did not see much application because of its local oscillator's stability problem. A stable yet inexpensive local oscillator was not available until Lee de Forest invented the triode vacuum tube oscillator., stating \\"Fessenden's circuit was ahead of its time, however, as there simply was no technology available then with which to build the required local oscillator with the necessary frequency stability.\\" Figure 7.10 shows a simplified 1907 heterodyne detector. In a 1905 patent, Fessenden stated that the frequency stability of his local oscillator was one part per thousand. In radio telegraphy, the characters of text messages are translated into the short duration dots and long duration dashes of Morse code that are broadcast as radio signals. Radio telegraphy was much like ordinary telegraphy. One of the problems was building high power transmitters with the technology of the day. Early transmitters were spark gap transmitters. A mechanical device would make sparks at a fixed but audible rate; the sparks would put energy into a resonant circuit that would then ring at the desired transmission frequency (which might be 100 kHz). This ringing would quickly decay, so the output of the transmitter would be a succession of damped waves. When these damped waves were received by a simple detector, the operator would hear an audible buzzing sound that could be transcribed back into alpha-numeric characters. With the development of the arc converter radio transmitter in 1904, continuous wave (CW) modulation began to be used for radiotelegraphy. CW Morse code signals are not amplitude modulated, but rather consist of bursts of sinusoidal carrier frequency. When CW signals are received by an AM receiver, the operator does not hear a sound. The direct- conversion (heterodyne) detector was invented to make continuous wave radio- frequency signals audible. The \\"heterodyne\\" or \\"beat\\" receiver has a local oscillator that produces a radio signal adjusted to be close in frequency to the incoming signal being received. When the two signals are mixed, a \\"beat\\" frequency equal to the difference between the two frequencies is created. By adjusting the local oscillator frequency correctly, the beat frequency is in the audio range, and can be heard as a tone in the receiver's earphones whenever the transmitter signal is present. Thus the Morse code \\"dots\\" and \\"dashes\\" are audible as beeping sounds. This technique is still used in radio telegraphy, the local oscillator now being called the beat frequency oscillator or BFO. Fessenden coined the word heterodyne from the Greek roots hetero- \\"different\\", and dyn- \\"power\\" (cf. Œ¥œçŒΩŒ±ŒºŒπœÇ or dunamis).Tapan K. Sarkar, History of wireless, page 372 =Superheterodyne receiver= Block diagram of a typical superheterodyne receiver. Red parts are those that handle the incoming radio frequency (RF) signal; green are parts that operate at the intermediate frequency (IF), while blue parts operate at the modulation (audio) frequency. An important and widely used application of the heterodyne technique is in the superheterodyne receiver (superhet), which was invented by U.S. engineer Edwin Howard Armstrong in 1918. In the typical superhet, the incoming radio frequency signal from the antenna is mixed (heterodyned) with a signal from a local oscillator (LO) to produce a lower fixed frequency signal called the intermediate frequency (IF) signal. The IF signal is amplified and filtered and then applied to a detector that extracts the audio signal; the audio is ultimately sent to the receiver's loudspeaker. The superheterodyne receiver has several advantages over previous receiver designs. One advantage is easier tuning; only the RF filter and the LO are tuned by the operator; the fixed-frequency IF is tuned (\\"aligned\\") at the factory and is not adjusted. In older designs such as the tuned radio frequency receiver (TRF), all of the receiver stages had to be simultaneously tuned. In addition, since the IF filters are fixed-tuned, the receiver's selectivity is the same across the receiver's entire frequency band. Another advantage is that the IF signal can be at a much lower frequency than the incoming radio signal, and that allows each stage of the IF amplifier to provide more gain. To first order, an amplifying device has a fixed gain-bandwidth product. If the device has a gain-bandwidth product of 60 MHz, then it can provide a voltage gain of 3 at an RF of 20 MHz or a voltage gain of 30 at an IF of 2 MHz. At a lower IF, it would take fewer gain devices to achieve the same gain. The regenerative radio receiver obtained more gain out of one gain device by using positive feedback, but it required careful adjustment by the operator; that adjustment also changed the selectivity of the regenerative receiver. The superheterodyne provides a large, stable gain and constant selectivity without troublesome adjustment. The superior superheterodyne system replaced the earlier TRF and regenerative receiver designs, and since the 1930s most commercial radio receivers have been superheterodynes. Applications Heterodyning, also called frequency conversion, is used very widely in communications engineering to generate new frequencies and move information from one frequency channel to another. Besides its use in the superheterodyne circuit found in almost all radio and television receivers, it is used in radio transmitters, modems, satellite communications and set-top boxes, radar, radio telescopes, telemetry systems, cell phones, cable television converter boxes and headends, microwave relays, metal detectors, atomic clocks, and military electronic countermeasure (jamming) systems. =Up and down converters= In large scale telecommunication networks such as telephone network trunks, microwave relay networks, cable television systems, and communication satellite links, large bandwidth capacity links are shared by many individual communication channels by using heterodyning to move the frequency of the individual signals up to different frequencies, which share the channel. This is called frequency division multiplexing (FDM). For example, a coaxial cable used by a cable television system can carry 500 television channels at the same time because each one is given a different frequency, so they don't interfere with one another. At the cable source or headend, electronic upconverters convert each incoming television channel to a new, higher frequency. They do this by mixing the television signal frequency, fCH with a local oscillator at a much higher frequency , creating a heterodyne at the sum , which is added to the cable. At the consumer's home, the cable set top box has a downconverter that mixes the incoming signal at frequency with the same local oscillator frequency creating the difference heterodyne frequency, converting the television channel back to its original frequency: . Each channel is moved to a different higher frequency. The original lower basic frequency of the signal is called the baseband, while the higher channel it is moved to is called the passband. =Analog videotape recording= Many analog videotape systems rely on a downconverted color subcarrier to record color information in their limited bandwidth. These systems are referred to as \\"heterodyne systems\\" or \\"color- under systems\\". For instance, for NTSC video systems, the VHS (and S-VHS) recording system converts the color subcarrier from the NTSC standard 3.58 MHz to ~629 kHz.Videotape formats using tape ; Retrieved 2007-01-01 PAL VHS color subcarrier is similarly downconverted (but from 4.43 MHz). The now-obsolete 3/4\\" U-matic systems use a heterodyned ~688 kHz subcarrier for NTSC recordings (as does Sony's Betamax, which is at its basis a 1/2‚Ä≥ consumer version of U-matic), while PAL U-matic decks came in two mutually incompatible varieties, with different subcarrier frequencies, known as Hi-Band and Low-Band. Other videotape formats with heterodyne color systems include Video-8 and Hi8. The heterodyne system in these cases is used to convert quadrature phase-encoded and amplitude modulated sine waves from the broadcast frequencies to frequencies recordable in less than 1 MHz bandwidth. On playback, the recorded color information is heterodyned back to the standard subcarrier frequencies for display on televisions and for interchange with other standard video equipment. Some U-matic (3/4‚Ä≥) decks feature 7-pin mini-DIN connectors to allow dubbing of tapes without conversion, as do some industrial VHS, S-VHS, and Hi8 recorders. =Music synthesis= The theremin, an electronic musical instrument, traditionally uses the heterodyne principle to produce a variable audio frequency in response to the movement of the musician's hands in the vicinity of one or more antennas, which act as capacitor plates. The output of a fixed radio frequency oscillator is mixed with that of an oscillator whose frequency is affected by the variable capacitance between the antenna and the musician's hand as it is moved near the pitch control antenna. The difference between the two oscillator frequencies produces a tone in the audio range. The ring modulator is a type of frequency mixer incorporated into some synthesizers or used as a stand-alone audio effect. =Optical heterodyning= Optical heterodyne detection (an area of active research) is an extension of the heterodyning technique to higher (visible) frequencies. This technique could greatly improve optical modulators, increasing the density of information carried by optical fibers. It is also being applied in the creation of more accurate atomic clocks based on directly measuring the frequency of a laser beam. See NIST subtopic 9.07.9-4.R for a description of research on one system to do this.Contract Details: Robust Nanopopous Ceramic Microsensor PlatformContract Details: High Pulsed Power Varactor Multipliers for Imaging Since optical frequencies are far beyond the manipulation capacity of any feasible electronic circuit, all visible frequency photon detectors are inherently energy detectors not oscillating electric field detectors. However, since energy detection is inherently \\"square-law\\" detection, it intrinsically mixes any optical frequencies present on the detector. Thus, sensitive detection of specific optical frequencies necessitates optical heterodyne detection, in which two different (close-by) wavelengths of light illuminate the detector so that the oscillating electrical output corresponds to the difference between their frequencies. This allows extremely narrow band detection (much narrower than any possible color filter can achieve) as well as precision measurements of phase and frequency of a light signal relative to a reference light source, as in a laser Doppler vibrometer. This phase sensitive detection has been applied for Doppler measurements of wind speed, and imaging through dense media. The high sensitivity against background light is especially useful for lidar. In optical Kerr effect (OKE) spectroscopy, optical heterodyning of the OKE signal and a small part of the probe signal produces a mixed signal consisting of probe, heterodyne OKE-probe and homodyne OKE signal. The probe and homodyne OKE signals can be filtered out, leaving the heterodyne frequency signal for detection. Heterodyne detection is often used in interferometry but usually confined to single point detection rather than widefield interferometry, however, widefield heterodyne interferometry is possible using a special camera. Using this technique which a reference signal extracted from a single pixel it is possible to build a highly stable widefield heterodyne interferometer by removing the piston phase component caused by microphonics or vibrations of the optical components or object. Mathematical principle Heterodyning is based on the trigonometric identity: :\\\\sin \\\\theta_1 \\\\sin \\\\theta_2 = \\\\frac{1}{2}\\\\cos(\\\\theta_1 - \\\\theta_2) - \\\\frac{1}{2}\\\\cos(\\\\theta_1 + \\\\theta_2) The product on the left hand side represents the multiplication (\\"mixing\\") of a sine wave with another sine wave. The right hand side shows that the resulting signal is the difference of two sinusoidal terms, one at the sum of the two original frequencies, and one at the difference, which can be considered to be separate signals. Using this trigonometric identity, the result of multiplying two sine wave signals \\\\sin (2 \\\\pi f_1 t)\\\\, and \\\\sin (2 \\\\pi f_2 t)\\\\, at different frequencies f_1 and f_2 can be calculated: :\\\\sin (2 \\\\pi f_1 t)\\\\sin (2 \\\\pi f_2 t) = \\\\frac{1}{2}\\\\cos [2 \\\\pi (f_1 - f_2) t] - \\\\frac{1}{2}\\\\cos [2 \\\\pi (f_1 + f_2) t] \\\\, The result is the sum of two sinusoidal signals, one at the sum and one at the difference of the original frequencies. =Mixer= The two signals combine in a device called a mixer. As seen in the previous section, an ideal mixer would be a device that multiplies the two signals. Some widely used mixer circuits, such as the Gilbert cell, operate in this way, but they are limited to lower frequencies. However, any nonlinear electronic component also multiplies signals applied to it, producing heterodyne frequencies in its output‚Äîso a variety of nonlinear components serve as mixers. A nonlinear component is one in which the output current or voltage is a nonlinear function of its input. Most circuit elements in communications circuits are designed to be linear. This means they obey the superposition principle; if F(v) is the output of a linear element with an input of v: :F(v_1 + v_2) = F(v_1) + F(v_2) \\\\, So if two sine wave signals at frequencies and are applied to a linear device, the output is simply the sum of the outputs when the two signals are applied separately with no product terms. Thus, the function F must be nonlinear to create mixer products. A perfect multiplier only produces mixer products at the sum and difference frequencies , but more general nonlinear functions produce higher order mixer products: for integers and . Some mixer designs, such as double-balanced mixers, suppress some high order undesired products, while other designs, such as harmonic mixers exploit high order differences. Examples of nonlinear components that are used as mixers are vacuum tubes and transistors biased near cutoff (class C), and diodes. Ferromagnetic core inductors driven into saturation can also be used at lower frequencies. In nonlinear optics, crystals that have nonlinear characteristics are used to mix laser light beams to create optical heterodyne frequencies. =Output of a mixer= To demonstrate mathematically how a nonlinear component can multiply signals and generate heterodyne frequencies, the nonlinear function F can be expanded in a power series (MacLaurin series): :F(v) = \\\\alpha_1 v + \\\\alpha_2 v^2 + \\\\alpha_3 v^3 + \\\\cdots \\\\, To simplify the math, the higher order terms above are indicated by an ellipsis (\\". . .\\") and only the first terms are shown. Applying the two sine waves at frequencies and to this device: :v_\\\\text{out} = F(A_1 \\\\sin \\\\omega_1 t + A_2 \\\\sin \\\\omega_2 t)\\\\, :v_\\\\text{out} = \\\\alpha_1 (A_1 \\\\sin \\\\omega_1 t + A_2 \\\\sin \\\\omega_2 t) + \\\\alpha_2(A_1 \\\\sin \\\\omega_1 t + A_2 \\\\sin \\\\omega_2 t)^2 + \\\\cdots \\\\, :v_\\\\text{out} = \\\\alpha_1 (A_1 \\\\sin \\\\omega_1 t + A_2 \\\\sin \\\\omega_2 t) + \\\\alpha_2(A_1^2 \\\\sin^2 \\\\omega_1 t + 2 A_1 A_2 \\\\sin \\\\omega_1 t \\\\sin \\\\omega_2 t + A_2^2 \\\\sin^2 \\\\omega_2 t) + \\\\cdots \\\\, It can be seen that the second term above contains a product of the two sine waves. Simplifying with trigonometric identities: : \\\\begin{align} v_\\\\text{out} = {} & \\\\alpha_1 (A_1 \\\\sin \\\\omega_1 t + A_2 \\\\sin \\\\omega_2 t)  & {} + \\\\alpha_2\\\\left( \\\\frac{A_1^2}{2} [1 - \\\\cos 2 \\\\omega_1 t] + A_1 A_2 [\\\\cos (\\\\omega_1 t - \\\\omega_2 t) - \\\\cos (\\\\omega_1 t + \\\\omega_2 t) ] + \\\\frac{A_2^2}{2} [1 - \\\\cos 2 \\\\omega_2 t] \\\\right) + \\\\cdots \\\\end{align} :v_\\\\text{out} = \\\\alpha_2 A_1 A_2 \\\\cos (\\\\omega_1 - \\\\omega_2 )t - \\\\alpha_2 A_1 A_2 \\\\cos (\\\\omega_1 + \\\\omega_2 ) t + \\\\cdots \\\\, So the output contains sinusoidal terms with frequencies at the sum and difference of the two original frequencies. It also contains terms at the original frequencies and at multiples of the original frequencies , , , , etc.; the latter are called harmonics, as well as more complicated terms at frequencies of , called intermodulation products. These unwanted frequencies, along with the unwanted heterodyne frequency, must be filtered out of the mixer output by an electronic filter to leave the desired frequency. See also * Electroencephalography * Homodyne * Transverter * Intermodulation ‚Äì a problem with strong higher-order terms produced in some non-linear mixers Notes References  External links  Category:Frequency mixers Category:Signal processing ","title":"Heterodyne"},{"id":"41236","text":"Heuristic routing is a system used to describe how deliveries are made when problems in a network topology arise. Heuristic is an adjective used in relation to methods of learning, discovery, or problem solving. Routing is the process of selecting paths to specific destinations. Heuristic routing is used for traffic in the telecommunications networks and transport networks of the world. Heuristic routing is achieved using specific algorithms to determine a better, although not always optimal, path to a destination. When an interruption in a network topology occurs, the software running on the networking electronics can calculate another route to the desired destination via an alternate available path. According to : > The heuristic approach to problem solving consists of applying human > intelligence, experience, common sense and certain rules of thumb (or > heuristics) to develop an acceptable, but not necessarily an optimum, > solution to a problem. Of course, determining what constitutes an acceptable > solution is part of the task of deciding which approach to use; but broadly > defined, an acceptable solution is one that is both reasonably good (close > to optimum) and derived within reasonable effort, time, and cost > constraints. Often the effort (manpower, computer, and other resources) > required, the time limits on when the solution is needed, and the cost to > compile, process, and analyze all the data required for deterministic or > other complicated procedures preclude their usefulness or favor the faster, > simpler heuristic approach. Thus, the heuristic approach is generally used > when deterministic techniques or are not available, economical, or > practical. Heuristic routing allows a measure of route optimization in telecommunications networks based on recent empirical knowledge of the state of the network. Data, such as time delay, may be extracted from incoming messages, during specified periods and over different routes, and used to determine the optimum routing for transmitting data back to the sources. IP routing The IP routing protocols in use today are based on one of two algorithms: distance vector or link state. Distance vector algorithms broadcast routing information to all neighboring routers. Link state routing protocols build a topographical map of the entire network based on updates from neighbor routers, and then use the Dijkstra algorithm to compute the shortest path to each destination. Metrics used are based on the number of hops, delay, throughput, traffic, and reliability. =Distance vector algorithms= *RIP uses number of hops, or gateways traversed, as its metric *IGRP uses bandwidth, delay, hop count, link reliability, load, and MTU *EIGRP uses the (DUAL) Diffusing Update Algorithm *BGP uses the distance vector algorithm =Link state algorithms= *OSPF uses the Dijkstra algorithm. See also *Heuristic (computer science) *Ford‚ÄìFulkerson algorithm *Bellman‚ÄìFord algorithm *Turn restriction routing References  * Category:Heuristic algorithms Category:Routing ","title":"Heuristic routing"},{"id":"41237","text":"Hierarchical routing is a method of routing in networks that is based on hierarchical addressing. Background Most Transmission Control Protocol/Internet Protocol (TCP/IP) routing is based on a two-level hierarchical routing in which an IP address is divided into a network portion and a host portion. Gateways use only the network portion until an IP datagram reaches a gateway that can deliver it directly. Additional levels of hierarchical routing are introduced by the addition of subnetworks. Description Hierarchical routing is the procedure of arranging routers in a hierarchical manner. A good example would be to consider a corporate intranet. Most corporate intranets consist of a high speed backbone network. Connected to this backbone are routers which are in turn connected to a particular workgroup. These workgroups occupy a unique LAN. The reason this is a good arrangement is because even though there might be dozens of different workgroups, the span (maximum hop count to get from one host to any other host on the network) is 2. Even if the workgroups divided their LAN network into smaller partitions, the span could only increase to 4 in this particular example. Considering alternative solutions with every router connected to every other router, or if every router was connected to 2 routers, shows the convenience of hierarchical routing. It decreases the complexity of network topology, increases routing efficiency, and causes much less congestion because of fewer routing advertisements. With hierarchical routing, only core routers connected to the backbone are aware of all routes. Routers that lie within a LAN only know about routes in the LAN. Unrecognized destinations are passed to the default route. References * External links *http://www.isi.edu/nsnam/ns/doc-stable/node310.html Category:Routing ","title":"Hierarchical routing"},{"id":"41239","text":"High-performance equipment describes telecommunications equipment that :(a) has the performance characteristics required for use in trunks or links, :(b) is designed primarily for use in global and tactical systems, and :(c) sufficiently withstands electromagnetic interference when operating in a variety of network or point-to-point circuits. Note: Requirements for global and tactical high-performance equipment may differ. Category:Telecommunications equipment ","title":"High-performance equipment"},{"id":"41240","text":"A hop is a type of jump. Hop or hops may also refer to: Arts, entertainment, and media * Hop (film), a 2011 film * Hop! Channel, an Israeli TV channel * Hop, the Bellhop, a 1919 silent comedy film * House of Payne, or HOP, an American sitcom * Lindy Hop, a swing dance of the 1920s and 1930s * Sock hop, an informal gathering which includes dancing Places * Hop, a Viking settlement in Vinland * Hop River in Connecticut, United States * Hop River State Park Trail, also called the Hop River Trail, a rail trail in Connecticut Plants * Humulus lupulus, the hop plant ** Hops, its flower, used to prepare beer and other food  Science and medicine  * HOP (gene), encoding the homeodomain-only protein * Hop (protein), the Hsp70-Hsp90 organizing protein * Hubble Origins Probe, or HOP, a proposed orbital telescope Technology * Hop (networking), a portion of a route * Hop (software), a web broker and programming language * Hop (telecommunications) * Hindsight optimization, or Hop, an artificial intelligence technique * High Octet Preset, or HOP, a C1 control character * Spike (application), an email app formerly known as Hop Transport * HOP!, a French airline * HOP card, a smart card used on public transit in Auckland, New Zealand * Hop Fastpass, a smart card for public transit fares in Portland, Oregon, United States * Heritage Operations Processing System, a tool for management of historic railways * Hope (Derbyshire) railway station, in England * Hope (Flintshire) railway station, in Wales * \\"The Hop\\", the brand for public transport in Sydney and New South Wales * \\"The Hop (streetcar)\\", streetcar system in Milwaukee Other uses * Hop (unit), a small Korean unit of volume * Croatian Liberation Movement (Croatian: ') * Heritage of Pride, or HOP, the organizer of the annual gay pride march in New York City * Higher-Order Perl, or HOP, a Perl programming book * Hillsboro Hops, a minor league baseball team in the USA * Opium, a narcotic drug * Hop, a character from Pok√©mon Sword and Shield See also * Hopper (disambiguation) * Hopping (disambiguation) * Hopps * Hip hop ","title":"Hop"},{"id":"41242","text":"Horn or horns primarily refers to: *Horn (acoustic), a conical or bell shaped aperture used to guide sound ** Horn (instrument), collective name for tube- shaped wind musical instruments *Horn (anatomy), a pointed, bony projection on the head of various animals, either the \\"true\\" horn, or other horn-like growths ** Horn (substance), a colloquial reference to keratin, the substance that, apart from other functions, is the main component of the tissue that sheaths the bony core of horns and hoofs of various animals Horn or horns may also refer to: Audio *Horn loudspeaker *Vehicle horn **Train horn *Ear trumpet = Musical instruments = :*Animal horn used as an instrument, e.g. Swedish cowhorn, Shofar, Vuvuzela :*Long straight instruments like Alphorn, Steerhorn, Tibetan horn :*Coiled brass instruments: ::*Natural horn, Post horn and their derivatives: :::*French horn, German horn and Vienna horn (\\"horn\\" in classical music) ::*The Saxhorn, including :::Baritone horn in B‚ô≠, Alto horn in E‚ô≠, and Flugel horn in B‚ô≠(soprano) :* Other horn shaped instruments include: ::* Basset horn, a clarinet pitched in F (less often in G) ::* Crumhorn, a Renaissance capped-reed instrument ::* English horn, an oboe pitched in F ::* Hornpipe (instrument), a single-reed instrument Personal name *Horn (surname) *Freyja, also known as H√∂rn, a Norse goddess of love, beauty, fertility, war and death Places *Horn (Chinese constellation), part of the European constellation Virgo *Cape Horn, the southernmost point of the continent of South America named (indirectly) after the Dutch town of Hoorn **Cabo de Hornos, Chile, a Chilean commune located near Cape Horn *Golden Horn, a historic inlet of the Bosphorus dividing the city of Istanbul *Horn (district), a district of the state of Lower Austria in Austria *Horn of Africa, a peninsula in Northeast Africa that juts into the Arabian Sea; comprises Djibouti, Eritrea, Ethiopia and Somalia *Horn, Austria, a small town in the Waldviertel in Lower Austria, Austria and the capital of the Horn District *Horn, Germany, a municipality in the district of Rhein-Hunsr√ºck in Rhineland-Palatinate, Germany *Horn, Hamburg, a quarter in the borough Hamburg-Mitte, in the eastern part of Hamburg, Germany *Horn (Netherlands), a town in the Dutch province of Limburg, and a separate municipality until 1991 *Horn, Oppland, a ferry docking point on the east side of lake Randsfjorden, Norway *Horn, Rutland, a civil parish in the county of Rutland in the East Midlands of England *Horn, Sweden, a locality situated in Kinda Municipality, √ñsterg√∂tland County, Sweden *Horn, Switzerland, a municipality in the district of Arbon in the canton of Thurgau in Switzerland, an exclave of Thurgau *Horn, Nebraska, a community in the United States *Horn Island, Queensland, one of the Torres Strait Islands *Horn River, a river in the Northwest Territories, Canada *Horn (Schwarzbach), a river in eastern France and southwestern Germany *The Horns (Colorado), a summit on Cheyenne Mountain Literature *Horns (novel), a dark fantasy novel written in 2010 by Joe Hill *Horns (film), a 2013 film adaptation of Hill's novel Music *Horn (album), an album by Pharaoh Overlord *\\"The Horns\\" (DJ Katch song), 2015 song Slang *Corna, also called the \\"devil horns\\", a hand gesture with a vulgar meaning *Telephone, also known as \\"the horn\\" *Two-way radio, also known as \\"the horn\\" *Texas Longhorns, the sports teams of the University of Texas in Austin; sometimes shortened to \\"Horns\\" Other uses *The Horns, Bull's Green, pub in Hertfordshire, England *Drinking horn, an animal horn that has been used as a drinking vessel in various cultures since antiquity *Cream horn, a pastry made with flaky or puff pastry, and whipped cream. Also can be done with meringue and it is called meringue horn *Horn (diacritic), a diacritic mark used to indicate that a normally rounded vowel such as o or u is to be pronounced unrounded *Sign of the horns, or the horns, a hand gesture *Horn Cable Television, a television channel in Somalia *The knob-like appendage attached to the pommel of a saddle *Horn antenna, a type of antenna shaped like a horn and also called \\"horn\\" *Glacial horn, a pyramid-shaped peak sculpted by glacial erosion *Control horn, a device that helps control the control surfaces of an aircraft *Horn (video game), a mobile game developed by Phosphor Games Studio See also Hoorn (disambiguation) *Horner (disambiguation) ","title":"Horn"}]`),I={name:"App",components:{PoemCard:q},data(){return{visibleCount:3,poemsData:A}},computed:{visiblePoems(){return this.poemsData.slice(0,this.visibleCount)},hasMorePoems(){return this.visibleCount<this.poemsData.length}},methods:{loadMore(){this.visibleCount+=3}}},D={class:"card-container"};function E(s,e,o,d,m,i){const u=g("PoemCard");return a(),n(c,null,[e[1]||(e[1]=t("section",null,[t("div",{class:"top-Banner"},[t("div",{class:"top-Banner-Title"},[t("div",{class:"top-Banner-Title-Text"},"üéâ your wikipediaü•≥")])])],-1)),t("section",null,[t("div",D,[(a(!0),n(c,null,y(i.visiblePoems,(r,f)=>(a(),b(u,{key:f,poem:r},null,8,["poem"]))),128))]),i.hasMorePoems?(a(),n("button",{key:0,class:"load-more-button",onClick:e[0]||(e[0]=(...r)=>i.loadMore&&i.loadMore(...r))},"See more")):w("",!0)])],64)}const F=h(I,[["render",E]]),z=JSON.parse('{"title":"","description":"","frontmatter":{"page":true},"headers":[],"relativePath":"glossary/62.md","filePath":"glossary/62.md"}'),P={name:"glossary/62.md"},R=Object.assign(P,{setup(s){return(e,o)=>(a(),n("div",null,[v(F)]))}});export{z as __pageData,R as default};
